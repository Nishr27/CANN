{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CANN for Mooney-Rivlin material.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMJ6x+ZGjQ5KjSllncjgc72",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nishr27/CANN/blob/main/CANN_for_Mooney_Rivlin_material.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXC1YvLfDGXd"
      },
      "source": [
        "#Generating Training and Test Data for CANN\n",
        "\n",
        "We start by preparing data according to the Mooney-Rivlin model using the following equation, for generating the strain energy function:\n",
        "\n",
        "- psi = ci0*(I - 3)**i + c0i*(II - 3)**i\n",
        "we have the material parameters given as per the Table 1 in the research paper Linka et al.\n",
        "\n",
        "We write the functions that are used throughout the program. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgvoRLNMGNoa"
      },
      "source": [
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.preprocessing as StandardScaler"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPk0qeSLntuM"
      },
      "source": [
        "def deformation_gradient(batch_size):\n",
        "  \"\"\"\n",
        "  Returns the Deformation Gradients generated for three types of loading: Uniaxial Tension Loading, Equi-Biaxial Loading and Pure Shear Loading\n",
        "\n",
        "  \"\"\"\n",
        "  # Generating random stretch values between 1 to 7\n",
        "  stretch = tf.random.uniform(shape=[batch_size], minval=1, maxval=7, dtype=tf.float32, seed=42)\n",
        "  #stretch = tf.Variable(np.linspace(1.2, 7.0, num=batch_size, endpoint=True, dtype=np.float32))\n",
        "  sqrt_stretch = tf.math.sqrt(stretch)\n",
        "  stretch_sqr = tf.math.square(stretch)\n",
        "\n",
        "  # Deformation Gradient for Uniform Tension Loading\n",
        "  uniform_tension = tf.Variable(tf.zeros(shape=[batch_size, 3, 3]))\n",
        "  for i in range(0, batch_size):\n",
        "    uniform_tension[i, 0, 0].assign(stretch[i])\n",
        "    uniform_tension[i, 1, 1].assign(1/sqrt_stretch[i])\n",
        "    uniform_tension[i, 2, 2].assign(1/sqrt_stretch[i])\n",
        "  \n",
        "  # Deformation Gradient for Equi-Biaxial Loading\n",
        "  eq_biaxial = tf.Variable(tf.zeros(shape=[batch_size, 3, 3]))\n",
        "  for i in range(0, batch_size):\n",
        "    eq_biaxial[i, 0, 0].assign(stretch[i])\n",
        "    eq_biaxial[i, 1, 1].assign(stretch[i])\n",
        "    eq_biaxial[i, 2, 2].assign(1/stretch_sqr[i])\n",
        "  \n",
        "  # Deformation Gradient for Pure Shear Loading\n",
        "  pure_shear = tf.Variable(tf.eye(3, batch_shape=[batch_size], dtype=tf.float32))\n",
        "  for i in range(0, batch_size):\n",
        "    pure_shear[i, 0, 0].assign(stretch[i])\n",
        "    pure_shear[i, 1, 1].assign(1/stretch[i])\n",
        "  \n",
        "  return uniform_tension, eq_biaxial, pure_shear, stretch  "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRWii-tSEUA8"
      },
      "source": [
        "def strain_energy(first_inv, second_inv):\n",
        "  \"\"\" \n",
        "  This function provides the strain energy function based on the Mooney-Rivlin rule, given the first and second strain invariants (Ic and IIc).\n",
        "  We also define the material constants ci0 and c0i here.\n",
        "  This can then be used for training the CANN using the invariants as inputs and the energy function as the label for a certain pair of invariants.\n",
        "\n",
        "  \"\"\"\n",
        "  # Material Constants\n",
        "  ci0 = tf.constant([1.6e-1, -1.4e-3, 3.9e-5])\n",
        "  c0i = tf.constant([1.5e-2, -2.0e-6, 1.0e-10])\n",
        "  \n",
        "  # Getting the batch size for the data\n",
        "  batch_size = first_inv.shape[0]\n",
        "\n",
        "  # Initializing the psi function with zeros\n",
        "  psi = tf.Variable(tf.zeros(batch_size))\n",
        "\n",
        "  # Calculation of strain energy function\n",
        "  for i in range(0, batch_size):\n",
        "    sum = 0\n",
        "    \n",
        "    for j in range(0, 3):\n",
        "      sum = sum + ci0[j] * ((first_inv[i] - 3)**(j+1)) + c0i[j] * ((second_inv[i] - 3)**(j+1))\n",
        "\n",
        "    psi[i].assign(sum)\n",
        "\n",
        "  # Return the calculated energy function\n",
        "  return psi"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWN613gDJ4NW"
      },
      "source": [
        "def right_Cauchy_Green_tensor(def_gradient):\n",
        "  \"\"\"\n",
        "  Function formulates the right Cauchy-Green Tensor from the Deformation Gradient\n",
        "  \n",
        "  \"\"\"\n",
        "  # Right Cauchy-Green Tensor C from Deformation Gradient\n",
        "  C = tf.linalg.matmul(def_gradient, def_gradient, transpose_a=True)\n",
        "\n",
        "  return C"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5FG5hesQVTf"
      },
      "source": [
        "def strain_invariants(C):\n",
        "  \"\"\" \n",
        "  This function calculates the strain/stress invariants given the right Cauchy-Green Tensor.\n",
        "  \n",
        "  \"\"\"\n",
        "  # First Strain Invariant\n",
        "  first_inv = tf.linalg.trace(C)\n",
        "\n",
        "  # Second Strain Invariant\n",
        "  second_inv = 0.5*((tf.math.square(first_inv)) - tf.linalg.trace(tf.linalg.matmul(C, C, transpose_a=True)))\n",
        "\n",
        "  return first_inv, second_inv  "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7uUzq53SgG0"
      },
      "source": [
        "def second_Piola_Kirchhoff_stress(psi, C):\n",
        "  \"\"\"\n",
        "  This function calculate the second Piola-Kirchhoff stress by taking the Gradient of the strain energy w.r.t right Cauchy Green Tensor\n",
        "  \n",
        "  \"\"\"\n",
        "  with tf.GradientTape() as tape:\n",
        "    tape.watch(C)\n",
        "    I = tf.linalg.trace(C)\n",
        "    II = 0.5*( (tf.linalg.trace(C)**2) - (tf.linalg.trace(tf.linalg.matmul(C, C, transpose_a=True))) )\n",
        "    psi = 1.6e-1*(I - 3) + 1.5e-2*(II - 3) + (-1.4e-3)*((I - 3)**2) + (-2.0e-6)*((II - 3)**2) + (3.9e-5)*((I - 3)**3) + (1.0e-10)*((II - 3)**3)\n",
        "\n",
        "  return 2*tape.gradient(psi, C)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ3VYEcOnqKF"
      },
      "source": [
        "def first_Piola_Kirchhoff_stress(S, def_grad):\n",
        "  \"\"\"\n",
        "  This function returns the first Piola-Kirchhoff (nominal) stress by multiplying the Deformation Gradient and the second Piola-Kirchhoff stress\n",
        "  \"\"\"\n",
        "  return tf.linalg.matmul(def_grad, S)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owlp1BwCEnVh"
      },
      "source": [
        "def standard_scaling(first_inv, second_inv):\n",
        "  from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "  first_inv_scaled = scaler.fit_transform(first_inv)\n",
        "  second_inv_scaled = scaler.transform(second_inv)\n",
        "\n",
        "  return first_inv_scaled, second_inv_scaled"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jzr5AsDryc-e"
      },
      "source": [
        "def split_train_test(first_inv, second_inv, psi):\n",
        "  \"\"\" \n",
        "  Splitting the Strain invariant data into Training and Test Sets with a Test size of 0.2\n",
        "  \"\"\"\n",
        "  np.random.seed(42)\n",
        "  shuffled_indices = np.random.permutation(first_inv.shape[0])\n",
        "  test_set_size = int(first_inv.shape[0] * 0.2)\n",
        "  test_indices = shuffled_indices[:test_set_size]\n",
        "  train_indices = shuffled_indices[test_set_size:]\n",
        "\n",
        "  return tf.gather(first_inv, train_indices), tf.gather(first_inv, test_indices), tf.gather(second_inv, train_indices), tf.gather(second_inv, test_indices), tf.gather(psi, train_indices), tf.gather(psi, test_indices)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEcaW3uC5_rs"
      },
      "source": [
        "def CANN_model():\n",
        "  \"\"\"\n",
        "  ANN Model \n",
        "  \n",
        "  \"\"\"  \n",
        "  I = keras.layers.Input(shape=[1], name=\"I\")\n",
        "  II = keras.layers.Input(shape=[1],name=\"II\")\n",
        "  concat = keras.layers.concatenate([I, II])\n",
        "  hidden0 = keras.layers.Dense(10, activation=\"relu\")(concat)\n",
        "  Psi = keras.layers.Dense(1, activation=\"relu\", name=\"Psi\")(hidden0)\n",
        "\n",
        "  model = keras.models.Model(inputs=[I, II], outputs=[Psi])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIJe8d7WmFZ3"
      },
      "source": [
        "#Body of the Main Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jBgU1-q_mPb"
      },
      "source": [
        "**Generating the Deformation gradient values for the three load cases**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUiThq52l1FS",
        "outputId": "8afc7e3a-567a-4b02-85bf-9b88ff84f6f4"
      },
      "source": [
        "# Setting the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Generating deformation gradients for the various load cases: Uniaxial Tension (UT), Equi-biaxial Tension (EBT) and Pure Shear (PS)\n",
        "# Also returning the stretches \n",
        "UT, EBT, PS, stretch = deformation_gradient(15)\n",
        "\n",
        "# Checking the examples generated\n",
        "print(\"Examples of the Deformation Gradients generated are: \\n\\n UT = \", UT[0], \"\\n\\n EBT = \", EBT[0], \"\\n\\n PS = \", PS[0], \"\\n\\n Stretch = \", stretch)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples of the Deformation Gradients generated are: \n",
            "\n",
            " UT =  tf.Tensor(\n",
            "[[3.4978168 0.        0.       ]\n",
            " [0.        0.5346893 0.       ]\n",
            " [0.        0.        0.5346893]], shape=(3, 3), dtype=float32) \n",
            "\n",
            " EBT =  tf.Tensor(\n",
            "[[3.4978168  0.         0.        ]\n",
            " [0.         3.4978168  0.        ]\n",
            " [0.         0.         0.08173459]], shape=(3, 3), dtype=float32) \n",
            "\n",
            " PS =  tf.Tensor(\n",
            "[[3.4978168 0.        0.       ]\n",
            " [0.        0.2858926 0.       ]\n",
            " [0.        0.        1.       ]], shape=(3, 3), dtype=float32) \n",
            "\n",
            " Stretch =  tf.Tensor(\n",
            "[3.4978168 2.6114898 3.878099  3.187428  6.7282686 6.651188  4.689004\n",
            " 3.1505287 4.5616145 2.2930658 1.4647102 4.475279  2.7508237 2.603082\n",
            " 3.2207475], shape=(15,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpSqRCzWqQXe"
      },
      "source": [
        "**Calculating the strain invariants from the generated deformation gradients**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUfnBHXMLtrw",
        "outputId": "9aa07d54-5ab1-46dd-c3b1-ac4d8be36acd"
      },
      "source": [
        "# Right Cauchy-Green Tensor from the Deformation Gradient\n",
        "C_ut = right_Cauchy_Green_tensor(UT)\n",
        "C_ebt = right_Cauchy_Green_tensor(EBT)\n",
        "C_ps = right_Cauchy_Green_tensor(PS)\n",
        "\n",
        "print(\"Right Cauchy Green Tensors: \\n\\n UT = \", C_ut[0], \"\\n\\n EBT = \", C_ebt[0], \"\\n\\n PS = \", C_ps[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Right Cauchy Green Tensors: \n",
            "\n",
            " UT =  tf.Tensor(\n",
            "[[12.234722    0.          0.        ]\n",
            " [ 0.          0.28589267  0.        ]\n",
            " [ 0.          0.          0.28589267]], shape=(3, 3), dtype=float32) \n",
            "\n",
            " EBT =  tf.Tensor(\n",
            "[[1.2234722e+01 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 1.2234722e+01 0.0000000e+00]\n",
            " [0.0000000e+00 0.0000000e+00 6.6805431e-03]], shape=(3, 3), dtype=float32) \n",
            "\n",
            " PS =  tf.Tensor(\n",
            "[[12.234722    0.          0.        ]\n",
            " [ 0.          0.08173458  0.        ]\n",
            " [ 0.          0.          1.        ]], shape=(3, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5nxCoFg_07w",
        "outputId": "50c55a65-a0b2-4b68-b5af-a42274c9f1a2"
      },
      "source": [
        "# Strain Invariants for the three cases\n",
        "I_ut, II_ut = strain_invariants(C_ut) \n",
        "I_ebt, II_ebt = strain_invariants(C_ebt)\n",
        "I_ps, II_ps = strain_invariants(C_ps)\n",
        "\n",
        "# Examples of the strain invariants \n",
        "print(\"Strain Invariants for Uniaxial Tension: \\n\\n First Invariant = \", I_ut, \"\\n\\n Second Invariant = \", II_ut, \"\\n\\n\")\n",
        "print(\"Strain Invariants for Equi-Biaxial Tension: \\n\\n First Invariant = \", I_ebt, \"\\n\\n Second Invariant = \", II_ebt, \"\\n\\n\")\n",
        "print(\"Strain Invariants for Pure Shear: \\n\\n First Invariant = \", I_ps, \"\\n\\n Second Invariant = \", II_ps, \"\\n\\n\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Strain Invariants for Uniaxial Tension: \n",
            "\n",
            " First Invariant =  tf.Tensor(\n",
            "[12.806507   7.5857253 15.555368  10.787162  45.566856  44.538998\n",
            " 22.413286  10.560644  21.246769   6.130345   3.5108337 20.47502\n",
            "  8.294086   7.544356  10.994188 ], shape=(15,), dtype=float32) \n",
            "\n",
            " Second Invariant =  tf.Tensor(\n",
            "[ 7.0773544  5.36961    7.8226776  6.473278  13.478882  13.324951\n",
            "  9.423492   6.4017982  9.17131    4.776308   3.3955388  9.000488\n",
            "  5.6338005  5.3537426  6.5378914], shape=(15,), dtype=float32) \n",
            "\n",
            "\n",
            "Strain Invariants for Equi-Biaxial Tension: \n",
            "\n",
            " First Invariant =  tf.Tensor(\n",
            "[24.476126  13.661259  30.083725  20.329082  90.53969   88.47711\n",
            " 43.975582  19.861813  41.61896   10.55247    4.5080185 40.058735\n",
            " 15.151527  13.573851  20.755722 ], shape=(15,), dtype=float32) \n",
            "\n",
            " Second Invariant =  tf.Tensor(\n",
            "[ 149.85193    46.804012  226.32411   103.416306 2049.381    1957.0724\n",
            "  483.50842    98.72363   433.08252    28.028513    5.534875  401.22556\n",
            "   57.524277   46.209812  107.796364], shape=(15,), dtype=float32) \n",
            "\n",
            "\n",
            "Strain Invariants for Pure Shear: \n",
            "\n",
            " First Invariant =  tf.Tensor(\n",
            "[13.316457   7.9665093 16.106144  11.258125  46.29169   45.260906\n",
            " 23.03224   11.026578  21.856384   6.4483314  3.6114948 21.07805\n",
            "  8.699183   7.9236145 11.469617 ], shape=(15,), dtype=float32) \n",
            "\n",
            " Second Invariant =  tf.Tensor(\n",
            "[13.316452   7.966511  16.106155  11.2581215 46.291748  45.260925\n",
            " 23.032257  11.026577  21.856384   6.448331   3.6114948 21.078064\n",
            "  8.699184   7.9236145 11.469616 ], shape=(15,), dtype=float32) \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yKeZFMBBDLR"
      },
      "source": [
        "**Calculating the Strain Energy Function from the Strain Invariants**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTTY2yRjDFTt",
        "outputId": "5fe3825b-d4c7-4230-f8d2-6e247509e7a6"
      },
      "source": [
        "# Strain Invariants for the three cases\n",
        "psi_ut = strain_energy(I_ut, II_ut)\n",
        "psi_ebt = strain_energy(I_ebt, II_ebt)\n",
        "psi_ps = strain_energy(I_ps, II_ps)\n",
        "\n",
        "print(\"Strain Energy Functions for UT, EBT and PS are: \\n\\n UT = \", psi_ut[0], \"\\n\\n EBT = \", psi_ebt[0], \"\\n\\n PS = \", psi_ps[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Strain Energy Functions for UT, EBT and PS are: \n",
            "\n",
            " UT =  tf.Tensor(1.5323132, shape=(), dtype=float32) \n",
            "\n",
            " EBT =  tf.Tensor(5.336738, shape=(), dtype=float32) \n",
            "\n",
            " PS =  tf.Tensor(1.698987, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90NyM20q3yDb"
      },
      "source": [
        "# Neural Network Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRsm3CLoh5-8"
      },
      "source": [
        "**Preparing Training and Test sets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "u40Ecslt12ng",
        "outputId": "0fee85bf-8cb3-441d-c901-716786790806"
      },
      "source": [
        "# Plotting the Invariant plane (I-II plane)\n",
        "plt.scatter(I_ut[:5], II_ut[:5], color=\"blue\", marker=\"s\", label=\"UT\")\n",
        "plt.scatter(I_ebt[:5], II_ebt[:5], color=\"cyan\", marker=\"o\", label=\"EBT\")\n",
        "plt.scatter(I_ps[:5], II_ps[:5], color=\"red\", marker=\"x\", label=\"PS\")\n",
        "plt.xlabel(\"Ic\")\n",
        "plt.ylabel(\"IIc\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "kBByENmgRnm7",
        "outputId": "e3defa26-2978-42f0-987b-34e562d7612e"
      },
      "source": [
        "plt.scatter(I_ut, psi_ut, label=\"I\")\n",
        "plt.scatter(II_ut, psi_ut, label=\"II\")\n",
        "plt.legend()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fbc0207a7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAASnUlEQVR4nO3df4zcdZ3H8deLZbldhGOhbAzswm2NpoZApd4GNRhPabQgoD1iGshx0YtJ/9BTUK8eXEjV5hL0mnjInV7SoKcXOWAPy6I9sUdKzR2XUN2yuOWHzalB2QVlqbZS2Nrt8r4/Zna7u8zsfqfMd76fmXk+kqb7/cww886X8OKzn+/nhyNCAIB0nVR0AQCApRHUAJA4ghoAEkdQA0DiCGoASNzJeXzo2WefHQMDA3l8NAC0pL17974QEb2VXsslqAcGBjQyMpLHRwNAS7L9y2qvMfQBAIkjqAEgcQQ1ACQulzHqSqanpzU+Pq4jR4406itr0tXVpf7+fnV2dhZdCgAs0LCgHh8f1+mnn66BgQHZbtTXZhIROnDggMbHx7Vy5cqiywGABRoW1EeOHEkypCXJtlasWKHJycmiS1na2JC0a4t0aFw6o19au1lavaHoqoC2Nzw6oa079+vZg1M6t6dbm9at0vo1fXX7/IYFtaQkQ3pWyrVJKoX09z4pTU+Vrg89U7qWCGugQMOjE7p5+z5NTc9IkiYOTunm7fskqW5hzcPEZrFry/GQnjU9VWoHUJitO/fPhfSsqekZbd25v27f0VZBfdpppxVdwok7NF5bO4CGePbgVE3tJ6KtgrqpndFfWzuAhji3p7um9hORbFAPj07o0i8+pJU3/acu/eJDGh6dKLqkYq3dLHUu+hff2V1qB1CYTetWqbuzY0Fbd2eHNq1bVbfvaOjDxKwaMTjfdGYfGDLrA0jKbCa1zKyPrJYanG/LoF48Le+abQQ00GBLTcFbv6Yv12xKMqgbMTjfNJiWBxSu6N/ykxyjbsTgfNNgWh5QuEZMwVtKkkHdiMH5psG0PKBwRf+Wn2RQr1/Tp1uvuUh9Pd2ypL6ebt16zUWv+VeMw4cP16fARmJaHlC4on/LX3aM2vYqSffMa3qDpM0RcVtuVSn/wfmmsXbzwjFqiWl5QINtWrdqwRi11Njf8pcN6ojYL+liSbLdIWlC0n0514VZTMsDCteIKXhLqXXWx1pJP4+Iqmd7IQerNxDMQMGK/C2/1jHqayXdVekF2xttj9geSX67UABoIpmD2vYpkj4g6T8qvR4R2yJiMCIGe3srnngOADgBtfSor5D0aET8Jq9iAACvVktQX6cqwx7NYnab06effloXXnhhwdUAQDaZgtr26yS9V9L2fMsBACyWadZHRLwkaUXOtSzE+YAAICnRTZnYiAgAjktyCTkbEQHAcWkGNRsRAcCcNIOajYgAYE6aQc35gAAwJ82gXr1Buvp26YzzJLn099W3v+YHibPbnA4MDOjxxx+vQ6EAkL80Z31IbEQEAGVp9qgBAHMaGtQR0civq0nKtQFobw0L6q6uLh04cCDJQIwIHThwQF1dXUWXAgCv0rAx6v7+fo2PjyvVvaq7urrU38/0PwDpaVhQd3Z2auXKlY36OgBoGTxMBIDEEdQAkDiCGgASR1ADQOIIagBIHEENAInLemZij+17bf/U9lO235F3YQCAkqzzqL8i6QcR8SHbp0g6NceaAADzLBvUts+Q9C5JH5GkiDgq6Wi+ZQEAZmUZ+lgpaVLSv9oetX2H7dctfpPtjbZHbI+kukwcAJpRlqA+WdJbJf1LRKyR9JKkmxa/KSK2RcRgRAz29vbWuUwAaF9Zgnpc0nhE7Clf36tScAMAGmDZoI6IX0t6xvaqctNaSU/mWhUAYE7WWR+fkHRnecbHLyT9VX4lAQDmyxTUEfGYpMGcawEAVMDKRABIHEENAIkjqAEgcQQ1ACSOoAaAxBHUAJA4ghoAEkdQA0DiCGoASBxBDQCJI6gBIHEENQAkjqAGgMQR1ACQOIIaABJHUANA4ghqAEgcQQ0Aict0FJftpyW9KGlG0rGI4FguAGiQrIfbStJ7IuKF3CoBAFTE0AcAJC5rUIek/7K91/bGSm+wvdH2iO2RycnJ+lUIAG0ua1C/MyLeKukKSR+3/a7Fb4iIbRExGBGDvb29dS0SANpZpqCOiIny389Luk/SJXkWBQA4btmgtv0626fP/izpfZIez7swAEBJllkfr5d0n+3Z9/97RPwg16oAAHOWDeqI+IWktzSgFgBABUzPA4DEEdQAkDiCGgASR1ADQOIIagBIHEENAIkjqAEgcQQ1ACSOoAaAxBHUAJA4ghoAEkdQA0DiCGoASBxBDQCJI6gBIHEENQAkjqAGgMQR1ACQuMxBbbvD9qjtHXkWBABYqJYe9Q2SnsqrEABAZZmC2na/pCsl3ZFvOQCAxbL2qG+T9FlJr1R7g+2Ntkdsj0xOTtalOABAhqC2fZWk5yNi71Lvi4htETEYEYO9vb11KxAA2l2WHvWlkj5g+2lJd0u6zPa3c60KADBn2aCOiJsjoj8iBiRdK+mhiLg+98oAAJKYRw0AyTu5ljdHxA8l/TCXSgAAFdGjBoDEEdQAkDiCGgASR1ADQOIIagBIHEENAIkjqAEgcQQ1ACSOoAaAxBHUAJA4ghoAEkdQA0DiCGoASBxBDQCJI6gBIHEENQAkjqAGgMRlOYW8y/aPbP/E9hO2v9CIwgAAJVmO4vqDpMsi4rDtTkkP234gIh7JuTYAgDIEdUSEpMPly87yn8izqOSNDUm7tkiHxqUz+qW1m6XVG4ququUNj05o6879evbglM7t6damdau0fk1f0WUBuct0uK3tDkl7Jb1R0lcjYk+uVaVsbEj63iel6anS9aFnStcSYZ2j4dEJ3bx9n6amZyRJEwendPP2fZJEWKPlZXqYGBEzEXGxpH5Jl9i+cPF7bG+0PWJ7ZHJyst51pmPXluMhPWt6qtSO3GzduX8upGdNTc9o6879BVUENE5Nsz4i4qCk3ZIur/DatogYjIjB3t7eetWXnkPjtbWjLp49OFVTO9BKlh36sN0raToiDtrulvReSV/KvbIUjQ1JPkmKmVe/dkZ/4+tpMUuNQZ/b062JCqF8bk93o8sEGi5Lj/ocSbttj0n6saQHI2JHvmUlaHZsulJId3aXHijihM2OQU8cnFLo+Bj08OiEJGnTulXq7uxY8M90d3Zo07pVBVQLNFaWWR9jktY0oJa0VRqbliR3SFffzoPE12ipMej1a/rmetbM+kA7yjTrA6o+Bh2vENJ1kGUMen5gA+2EoM6q+0xp6revbmdsumaVxqIZgwaqY6+PLMaGpKOHX91+Uidj0zWqNhb9njf3MgYNVEFQZ7FrizRz9NXtf3Q6wx41qjYWvfunk7r1movU19MtS+rr6dat11zEUAcghj6yqTY+PfW7xtbRApYai2YMGqiMHnUW1cahGZ+uWbUxZ8aigeoI6izWbi7NlZ6PudMnhPnQQO0Y+shidhyaHfNeM+ZDA7VzaRfT+hocHIyRkZG6fy4AtCrbeyNisNJrDH0AQOIIagBIHEENAIkjqAEgcQQ1ACSOoAaAxBHUAJA4ghoAEkdQA0Dilg1q2+fZ3m37SdtP2L6hEYUBAEqy7PVxTNJnIuJR26dL2mv7wYh4MufaAADKdrjtc5KeK//8ou2nJPVJaq2gHhtq6U2XKh1/xUZIQHOoafc82wMqnUi+p8JrGyVtlKTzzz+/DqU10NiQ9L1PHj9l/NAzpWupJcJ69vir2ZNVZo+/kkRYA00g88NE26dJ+o6kGyPi94tfj4htETEYEYO9vb31rDF/u7YcD+lZ01Ol9hZQ7firrTv3F1QRgFpkCmrbnSqF9J0RsT3fkgpQ7aitau1NZqnjrwCkL8usD0v6uqSnIuLL+ZdUgBY/aovjr4DmlqVHfamkv5R0me3Hyn/en3NdjdXiR21x/BXQ3LLM+nhYkhtQS3Fa/Kgtjr8CmhtHcQFAAjiKCwCaGEENAIkjqAEgcTWtTGwJTbJUnCXfAGa1V1A3yVJxlnwDmK+9hj6aZKk4S74BzNdeQd0kS8VZ8g1gvvYK6iZZKs6SbwDztVdQN8lScZZ8A5ivvR4mNslScZZ8A5iv9YO60nS8Tz3e0BJOZKrd+jV9BDMASa0e1GND0v0fl2aOlq4PPVO6lhrSix4endDnv/uEDk5Nz7Ux1Q5ArVp7jHrHjcdDetbMUemBv839q28Z3qdP3fPYgpCexVQ7ALVo3aAeG5KOvlT5tanf5vrVw6MTuvORX2mpfQmZagcgq9YN6gIXsWzduX/JkJaYagcgu9YN6qUWsXSfletXL9dbZqodgFq0blAvtYjlii/l+tVL9ZbPPLVTt15zEQ8SAWSW5XDbb9h+3nZj57S9VpUWt8jS4Edzn/FRacGKJV3/9vM1uvl9hDSAmmSZnvdNSf8s6d/yLaXOClzcwoIVAPWU6cxE2wOSdkTEhVk+lDMTAaA2DTkz0fZG2yO2RyYnJ+v1sQDQ9uq2MjEitknaJpV61PX63MzqeHILp6sASElrLCGv48ktnK4CIDWtMT2vjie3cLoKgNQs26O2fZekd0s62/a4pM9FxNfzLiyzHZ8u9aAryXByyy3D+3TXnmc0E6EOWzNVHq6y5BtAUZYN6oi4rhGFnJAdn5ZGlvh/xjInt9wyvE/ffuRXc9fVQlpiyTeA4jT30Mfeb1Z/LcPJLXftqdITX4Ql3wCK1NxBHTPVX7v69mUfJC7Vg+7r6ZbLf7PkG0CRmnvWhzsqh7U7Ms32qDYm3WHrf2+6rB4VAsBr1tw96j/9SG3ti1z3tvNqageAIjRfj3rxwpaVfyY9/XCpZ+2OUkhf9eVMi1b+fv1FkrRg1sd1bztvrh0AUpBpr49a5bbXx+KFLVLpoeGi8ejFi1ak0gNBxpoBpKohe300RMaFLSxaAdBKmiuoqy1gWdRebXEKi1YANKPmCupqC1gWtVdbnMKiFQDNqLmCutKpLRUWtlQ6YYVFKwCaVXPN+sh4agsnrABoJc016wMAWlTrzPoAgDZEUANA4ghqAEgcQQ0AiUtn1sfYkF5+YLO6pn6tZ19ZoTtOuV4XX7mRmRoA2l4aPeqxIR27/xM6deo5naRQ/0kv6LPTX9PD931Nw6MTRVcHAIXKFNS2L7e93/bPbN9U9yp2bdHJM0cWNJ3qo7pRd7M/B4C2t2xQ2+6Q9FVJV0i6QNJ1ti+oaxVV9vA41wfYnwNA28vSo75E0s8i4hcRcVTS3ZI+WNcqquzh8WysYH8OAG0vS1D3SZp/Cux4uW0B2xttj9gemZycrK2KtZt1rKNrQdPLcYpu07XszwGg7dXtYWJEbIuIwYgY7O3tre0fXr1BJ3/wn/Ry9zl6Rdb4K2frHzo/pnf++ceY9QGg7WWZnjchaf4hgv3ltvpavUGnljdX6pf0+bp/AQA0pyw96h9LepPtlbZPkXStpO/mWxYAYNayPeqIOGb7ryXtlNQh6RsR8UTulQEAJGVcmRgR35f0/ZxrAQBUkMbKRABAVQQ1ACQulxNebE9K+mXdPzh9Z0t6oegiEsc9Whr3Z2mtfH/+JCIqzm3OJajble2RakfpoIR7tDTuz9La9f4w9AEAiSOoASBxBHV9bSu6gCbAPVoa92dpbXl/GKMGgMTRowaAxBHUAJA4gvoE2f6G7edtPz6v7SzbD9r+v/LfZxZZY5Fsn2d7t+0nbT9h+4ZyO/dIku0u2z+y/ZPy/flCuX2l7T3lY+/uKW+E1rZsd9getb2jfN2W94egPnHflHT5orabJO2KiDdJ2lW+blfHJH0mIi6Q9HZJHy8f4cY9KvmDpMsi4i2SLpZ0ue23S/qSpH+MiDdK+p2kjxZYYwpukPTUvOu2vD8E9QmKiP+W9NtFzR+U9K3yz9+StL6hRSUkIp6LiEfLP7+o0n9sfeIeSZKi5HD5srP8JyRdJunecnvb3h9Jst0v6UpJd5SvrTa9PwR1fb0+Ip4r//xrSa8vsphU2B6QtEbSHnGP5pR/rX9M0vOSHpT0c0kHI+JY+S0Vj71rI7dJ+qykV8rXK9Sm94egzkmU5j22/dxH26dJ+o6kGyPi9/Nfa/d7FBEzEXGxSocaXSLpzQWXlAzbV0l6PiL2Fl1LCjLtR43MfmP7nIh4zvY5KvWU2pbtTpVC+s6I2F5u5h4tEhEHbe+W9A5JPbZPLvca8zn2rjlcKukDtt8vqUvSH0v6itr0/tCjrq/vSvpw+ecPS7q/wFoKVR5P/LqkpyLiy/Ne4h5Jst1ru6f8c7ek96o0jr9b0ofKb2vb+xMRN0dEf0QMqHT830MR8Rdq0/vDysQTZPsuSe9WadvF30j6nKRhSUOSzldpm9cNEbH4gWNbsP1OSf8jaZ+OjzH+nUrj1G1/j2yvVulhWIdKHaahiNhi+w2S7pZ0lqRRSddHxB+Kq7R4tt8t6W8i4qp2vT8ENQAkjqEPAEgcQQ0AiSOoASBxBDUAJI6gBoDEEdQAkDiCGgAS9//3g/casubIngAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mu8IJJTAFciI"
      },
      "source": [
        "I_ut_scaled, II_ut_scaled = standard_scaling(I_ut.numpy().reshape(-1,1), II_ut.numpy().reshape(-1,1))\n",
        "\n",
        "I_ebt_scaled, II_ebt_scaled = standard_scaling(I_ebt.numpy().reshape(-1,1), II_ebt.numpy().reshape(-1,1))\n",
        "\n",
        "I_ps_scaled, II_ps_scaled = standard_scaling(I_ps.numpy().reshape(-1, 1), II_ps.numpy().reshape(-1,1))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19PET9_FuwIT"
      },
      "source": [
        "I_ut_train, I_ut_test, II_ut_train, II_ut_test, psi_ut_train, psi_ut_test = split_train_test(I_ut_scaled, II_ut_scaled, psi_ut)\n",
        "\n",
        "I_ebt_train, I_ebt_test, II_ebt_train, II_ebt_test, psi_ebt_train, psi_ebt_test = split_train_test(I_ebt, II_ebt, psi_ebt)\n",
        "\n",
        "I_ps_train, I_ps_test, II_ps_train, II_ps_test, psi_ps_train, psi_ps_test = split_train_test(I_ps, II_ps, psi_ps)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-rt8LdryPsR"
      },
      "source": [
        "**Building the Neural Network Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8uSd0di3ohR"
      },
      "source": [
        "model = CANN_model()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "UGYkusXg6p5r",
        "outputId": "47abee8b-fceb-4676-af75-2e82ac54d234"
      },
      "source": [
        "# Checking the construction of the Neural Network\n",
        "# Activation functions used in all layers are \"ReLU\"\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAApIAAAGVCAIAAADCB4YUAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nOzdaVhT19o38BVIIMzgAFIsyqAoiqJFC3GuLa1yABEQWrHHetoCagFFCzgiItXaAxxaqHWi16u9KpPFEe1FLVqP1KNVBPGpAoqIEyDIjATY74f9NE8OQwghZGcn/98ns/bOyr23WbnZ07o5FEURAAAAYAMNpgMAAAAAaSFtAwAAsAbSNgAAAGsgbQMAALAGV/xFfn5+fHw8U6EAgGQZGRmD7yQ+Pj4/P3/w/QCAYqxfv97FxUX08r+Oth89epSZmanwkNTX77///vvvvzMdxZCrrKzE92qQ5LgP8/Pz1eFbp8zUZ0RkZmZWVlYyHQW7ZWZmPnr0SLyF23MlufxFD9Lw9fUlarDD09PT/fz8VH4zhxS9D+XVm7OzM/47GKQ+I4LD4axbt27ZsmVMB8JiHA6nWwuubQMAALAG0jYAAABrIG0DAACwBtI2AAAAayBtAwAAsAbSNvucPXvWyMjo1KlTTAciZ0FBQZy/BAQEiC/Kzc2NiorKysqytramV1ixYoX4Cq6urgYGBpqampMmTbpx44ZiA/8vXV1dCQkJAoFAvPHkyZN79uzp7OwUtWRnZ4s2dsSIEQoPE9gHAx8Dn4a0zT4qXLRt2LBhOTk5d+/ePXTokKhx+/btSUlJmzZt8vb2vn//vo2NzfDhw48ePXrmzBnROj///HNGRoa7u3txcfH06dOZiJ0QQkpKSubOnbt+/fqWlhbxdg8PDz6fv3DhwpcvX9Itnp6elZWVly5dWrx4MRORAvtg4GPg05C22cfNza2+vt7d3X2oP6i1tbXbH49DTUdH57333hs/fry2tjbdsnv37mPHjqWnpxsYGIhWS0pK0tDQCAwMrK+vV2R4kt26dSsyMjI4ONjR0bHn0tDQ0KlTpy5evLijo4MQwuFwLCws5syZM27cOIVHCqyEgY+BT0Pahj4dOnSoqqqKwQBKS0u3bt26Y8cOPp8v3i4QCMLCwh4/frxhwwamYutp6tSpWVlZy5cvF/30dBMdHV1QUJCYmKjgwAAGBAN/QBQ/8JG2Weby5cuWlpYcDuebb74hhKSkpOjp6enq6p44cWLRokWGhoajR4/+8ccf6ZWTkpL4fL6pqWlQUJC5uTmfzxcIBFevXqWXhoSEaGlpjRo1in65Zs0aPT09DodTU1NDCAkLCwsPDy8rK+NwOLa2toSQc+fOGRoa7tq1S2Ebm5SURFGUh4dHz0WxsbHjx48/ePBgbm5ur++lKCo+Pn7ixIna2tomJiZLliz5888/6UWSdxohpLOzc9u2bZaWljo6OlOmTElLS5PL5piYmMybNy8xMVGFz3bCEMHAp2HgE6Rt1pk9e/aVK1dEL1evXr1u3brW1lYDA4O0tLSysjJra+tPPvlEKBQSQkJCQlauXNnS0hIaGlpeXn7jxo2Ojo533nmHnuE2KSlJfNLB5OTkHTt2iF4mJia6u7vb2NhQFFVaWkoIoW+s6OrqUtjGnjlzxs7OTldXt+ciHR2d77//XkND45NPPmlubu65QnR0dFRU1ObNm6uqqi5duvTo0aM5c+Y8f/6c9LfTCCGRkZFffvllQkLC06dP3d3dP/jgg+vXr8tli6ZNm/b48eNbt27JpTdQHxj4NAx8grStMgQCgaGh4ciRI/39/ZubmysqKkSLuFwu/benvb19SkpKY2NjamqqDB/h5ubW0NCwdetW+UUtSXNz84MHD2xsbPpawcXFZd26deXl5ZGRkd0Wtba2xsfHL126NCAgwMjIyMHBYd++fTU1Nfv37xdfrded1tbWlpKS4uXl5e3tbWxsvGXLFh6PJ9se64m+oFVUVCSX3gAw8MWpycBH2lY1WlpahBDR34/dODk56erqis4aKbOqqiqKonr9i1skNjbWzs4uOTn58uXL4u3FxcVNTU1OTk6ilhkzZmhpaYnOE3YjvtPu3r3b0tIyefJkepGOjs6oUaPktcfozaH/9geQIwx8ojYDH2lb7Whra1dXVzMdRf/a2toIIX3d5UHj8/mpqakcDmfVqlWtra2idvpxC319ffGVjY2NGxsb+/1c+szbli1bRI9XPnz4sNtzHTLT0dEhf20agCJh4EvGooGPtK1ehELhy5cvR48ezXQg/aO/6OIzFfTKxcVl/fr1JSUlO3fuFDUaGxsTQrqNVSk3fOTIkYSQhIQESkx+fr4Mm9BTe3s7+WvTABQGA7/fz2XRwEfaVi95eXkURTk7O9MvuVxuX2fVGGdqasrhcKR5QHPnzp0TJky4efOmqGXy5Mn6+vrit5NcvXq1vb39jTfe6Le3119/nc/nFxQUyBa2ZPTmmJmZDUXnAH3BwO+3NxYNfKRt1dfV1VVXV9fR0VFYWBgWFmZpably5Up6ka2tbW1tbXZ2tlAorK6ufvjwofgbhw0b9uTJk/Ly8sbGRqFQmJOTo8jnQHR1da2trSsrK/tdkz5jpqmpKd4SHh5+/Pjxo0ePNjQ0FBUVBQcHm5ubBwYGStPbRx999OOPP6akpDQ0NHR2dlZWVj59+pQQ4u/vb2ZmNpg5FOnNcXBwkLkHAClh4KvswBc/IUA/pkaBovj4+Pj4+AzoLV9//TX9wKWurq6Hh0dycjJ9s8O4cePKysr2799vaGhICBkzZsy9e/coigoMDOTxeBYWFlwu19DQcMmSJWVlZaLeXrx4sWDBAj6fb2Vl9dlnn23cuJEQYmtrW1FRQVHUjRs3xowZo6OjM3v27GfPnp09e9bAwCA2Nnagmynl9yowMNDCwkK8JSQkhMfjtbS00C+PHz9O3186YsSItWvXdnv7xo0bPT09RS+7urr27t07btw4Ho9nYmLi5eV19+5delG/O+3Vq1cRERGWlpZcLnfkyJHe3t7FxcUURXl5eRFCtm3b1mv8+fn5s2bNMjc3p0fWqFGjBALBxYsXxddxc3OzsLDo6uoStYSGhg4fPrzfnSPHsSnDtw7kS4b/TTYOfIqiCCFpaWmS18HAl6znPkTaZpICfkADAwOHDRs2pB/RL5nTdklJCZfLPXLkyJCFNjCdnZ1z5sw5dOiQbG+vqanh8/lfffWVeCPSthpSwC+tMgx8Sta0jYEvruc+xEly1dfvzR3Ko7W19fz58yUlJfQdHLa2tjExMTExMU1NTUyHRjo7O7OzsxsbG/39/WXrITo62tHRMSQkhBBCUdSTJ08uX75Mz2gBIHcY+HKhhAMfaRuUSG1tLV1RYNWqVXRLVFSUr6+vv78/48UD8vLysrKycnJyJD9R2pf4+PiCgoKzZ8/yeDxCyIkTJ+iKAuLljADUEwb+wIgfektz6iY/P3/ChAkcDocQYmpqunPnTvmuL0eZmZlWVlb0ZpqZmS1fvlxhHy2loT5dGRUVRc8nMHbs2IyMjKH7IMkGf0rw/PnzERER8opH8bKzs+Pi4jo6OmTuQcEnyXsOWwx8ORrqk+RKMvAp6U6SS4CBT8nx2va7775LCKmrq5Pygwe6vhzZ2NgYGRkp/nOloSZXGXHPxOAxcm2757DFwJcL9RkRg0zbQKnDtW3FV4oFAMZh4IP6ULW0zXilWABQPAx8UB/ySdsDKsiqyEqx0vjtt9/s7e2NjIz4fL6Dg8P58+cJIR9//DE9La2NjQ09C89HH32kq6trZGR08uRJ0kdl1i+//FJXV9fAwKCqqio8PNzCwuLu3bvS70YAdsHAx8AHBoifMZf52vbp06cNDAxiYmKkXH/z5s2EkF9++aW+vr6qqmrOnDl6enrt7e300sDAQD09vTt37rS1tRUXF8+YMcPAwICeB4CiqOXLl5uZmYl63rt3LyGkurqafunt7U1XihXp9xJXRkZGdHR0bW3tixcvnJ2dRc/SeXt7a2pqPn78WLTmBx98cPLkSfrfGzZs0NbWzszMrKur27Rpk4aGxrVr10SbFhoa+vXXXy9duvR//ud/JHw0rm2DlJTz2jYGvmwDX31GBMG17UHruQ/lc7QtW0FWBVSKlYaPj8/27dtNTEyGDRvm4eHx4sULuk5OcHBwZ2en6HMbGhquXbu2ePFiIkVl1t27d69duzYrK2vChAlDFDYA4zDwMfBB8bhMB0CIMlWKpR+to6cpeOutt8aPH3/48OFNmzZxOJxjx475+/vT89/KsTJrZmYm/ZCMylOTzQTpqfPAJ2ozIvz8/Pz8/JiOQqUoRdru15BWij1z5szevXuLi4sbGhrEf0E4HE5QUND69et/+eWXt99++//9v//3ww8/0ItElVm3bNkiWl80J+2AODs7r1u3bnBboOzy8/MTExPpE4MgG3ofMh2FoqnwwCeEqMOI8PPzCwsLc3FxYToQFuv5Rw8L0vZQVIq9dOnSH3/8sW7duoqKCi8vr6VLlx4+fPi11177+uuvP//8c9FqK1eu3LRp08GDB19//XVDQ8MxY8bQ7aLKrGFhYYOMZPTo0cuWLRtkJ8ovMTFRHTZzSKlb2lbtgU8IUYcR4efn5+Liog5bOnRYmbaHolLsH3/8oaenRwgpKioSCoWrV6+2trYmPU5bmZiY+Pn5HTt2zMDA4JNPPhG1D2llVgAgGPgAfZDPLWlyL8gqr0qxPXsWCoXPnz/Py8ujR6+lpSUhJDc3t62traSkRPTAiUhwcPCrV69Onz7t7u4uapRQmRVAfWDgY+ADA8RvK5fmsYTff/990qRJGhoahJBRo0bt2rWLoigJBVl7rq+wSrHffvstXaW1V8ePH6c7jIiIGDZsmLGxsa+v7zfffEMIsbGxET12QlHUtGnToqKium1Xr5VZ9+zZo6OjQwh5/fXXpak6hwfAQEoKfgCs57DFwKfJZeCrz4ggeABs0HruQ2Wst60klWJFFi9efP/+/aHoGWkbpKQO9bbVZ+Crz4hA2h68nvtQSSc3ZbxSrOg8W2FhIf0HPrPxAKgDDHyAfilp2mZcRERESUnJvXv3Pvroo507dzIdjloICgri/CUgIEB8UW5ublRUVFZWlrW1Nb3CihUrxFdwdXU1MDDQ1NScNGnSjRs3FBv4f+nq6kpISOhW1uLkyZN79uwRz0nZ2dmijR0xYoTCw4TeYeArHgb+gIkfeivDqRslqRS7efNmDQ2N119/XTSp4VBQ2tOV8iXl94o+R5qTk3P37t22tjZR+7Zt29zd3RsaGuiXNjY2w4cPJ4ScPn1a/O05OTmenp7yjXyg7t27N2vWLELI1KlTuy1KTEycN2+eaJrPrq6uysrKS5cuLV68WDStpgQqf5JcrQa+MvzSKgaR4iQ5Br5kPfeh0h1tx8XFvXr1iqKoBw8e+Pj4MBVGbGxsZ2dnRUWF+H2kbCTHgoYKqI2oo6Pz3nvvjR8/Xltbm27ZvXv3sWPH0tPTDQwMRKslJSVpaGgEBgbW19cPaTwDcuvWrcjIyODgYEdHx55LQ0NDp06dunjx4o6ODkIIh8OxsLCYM2fOuHHjFB6pMsLAly8MfIVR/MBXurQN8iXHgoaKr41YWlq6devWHTt28Pl88XaBQBAWFvb48eMNGzYoMh7Jpk6dmpWVtXz5ctFPTzfR0dEFBQXqNmsKMAIDX2EUP/CRtlmAoqj4+Hi6xIKJicmSJUtE0yAPqKChfGsjDqhoo2ySkpIoivLw8Oi5KDY2dvz48QcPHszNze31vRJ2muQKkqSP4oyDZ2JiMm/evMTERPrEF4BkGPg9F2HgE6J817bVipRXGbdt26alpXXkyJGXL18WFhZOnz59xIgRz549o5cOqKChHGsj9lu0UUT6a9sWFhbiLdbW1vb29t1Ws7GxefDgAUVRV65c0dDQGDt2bFNTE9XjEpfknSa5gmRfxRml9Oabb/a8xEWLiooihNy8eVPUEhoaimvb6kbK/022D3xK6mvbGPgS9NyHONpWdq2trfHx8UuXLg0ICDAyMnJwcNi3b19NTc3+/ftl61BetRFlK9oovebm5gcPHkiYN8PFxWXdunXl5eWRkZHdFkm503qtINlvccbBoC9oFRUVyaU3UGEY+H2tgIGPtK3siouLm5qanJycRC0zZszQ0tLqOR2jDBRZG3GgqqqqKIqi59XqS2xsrJ2dXXJy8uXLl8XbB7rTxCtIyrc4Yzf05jx//lwuvYEKw8CXsI6aD3ykbWX38uVLQoi+vr54o7GxcWNjo1z6H9LaiIPR1tZGCOnrLg8an89PTU3lcDirVq1qbW0VtQ9mp4mKM4oer3z48GFLS4tsW9ENPQUmvWkAEmDgS1hHzQc+0rayMzY2JoR0+9rJq6DhUNRGlBf6i97vtFkuLi7r168vKSkRnxxjMDtNVJxR/GJSfn6+DJvQU3t7O/lr0wAkwMCXvJo6D3ykbWU3efJkfX3969evi1quXr3a3t7+xhtv0C8HU9BwKGojyoupqSmHw5HmAc2dO3dOmDDh5s2bopZ+d5oEQ1qckd4cMzOzoegcVAkGfr9rqu3AR9pWdnw+Pzw8/Pjx40ePHm1oaCgqKgoODjY3Nw8MDKRXGGhBQ3nVRpR70cZudHV1ra2tKysr+12TPmOmqakp3iJ5p0nura/ijP7+/mZmZoOZQ5HeHAcHB5l7ADWBgd/vmuo78MVPCOABMAWT8lGcrq6uvXv3jhs3jsfjmZiYeHl53b17V7RU+oKGz549k1dtxGfPnkko2tiNzA+AhYSE8Hi8lpYW+uXx48fp+0tHjBixdu3abm/fuHGj+HMgEnZavxUkey3OSFGUl5cXIWTbtm29xp+fnz9r1ixzc3N6ZI0aNUogEFy8eFF8HTc3NwsLi66uLlELHgBTQ1L+b7J94FOyPgCGgS+u5z5E2maS4n9AGamNKHPaLikp4XK50hQwVozOzs45c+YcOnRItrfX1NTw+fyvvvpKvBFpWw0p/peWqaKosqVtDHxxPfchTpKrHcZrI0rQ2tp6/vz5kpIS+g4OW1vbmJiYmJiYpqYmpkMjnZ2d2dnZjY2N/v7+svUQHR3t6OgYEhJCCKEo6smTJ5cvXy4tLZVrmAC9w8CXjRIOfKRtUCK1tbV0RYFVq1bRLVFRUb6+vv7+/owXD8jLy8vKysrJyZH8RGlf4uPjCwoKzp49y+PxCCEnTpygKwqcOXNG3pECsAwG/oAgbauRTZs2paam1tfXW1lZZWZmMh1Od/v27ROdBTp69KiofdeuXSEhIV988QWDsRFCFi5c+MMPP4imbh6QEydOvHr1Ki8vz8TEhG5ZsmSJ+Dk0uUYK8F8w8AdDCQc+V7a3ARvFxcXFxcUxHYUsXF1dXV1dmY5Cdp6enp6enkxHAWoKA58pQzTwcbQNAADAGkjbAAAArIG0DQAAwBpI2wAAAKzRyy1p6enpio9DPdEz3qn8Dqen409LS+NwOEzHwlbyKmlAq6ysVPlvnWJQFCXDt5r+31ST/wL5fnWBkN4mNwUA5STNnEr98vHxYXo7AGAAus2SxqEoiumQQPW1tbVt3779n//857x58w4cOGBtbc10RACyO3HiRHBwMEVR33777ZIlS5gOB9QLrm2DIvD5/D179vzxxx91dXWTJ0/es2ePMk+1CNCXurq6wMDAJUuWzJ49+/bt28jZoHg42gaFEgqF8fHx27Ztc3JyOnTo0IQJE5iOCEBap06dCgoKoigqJSUFCRuYgqNtUCgejxcREXH9+vX29vZp06bhsBtYoaqqytfX18PDY9asWTjIBmbhaBuY0dHR8c9//nP79u2Ojo6HDx+2t7dnOiKA3mVkZKxevVpPT+/AgQPvvPMO0+GAusPRNjCDy+VGRET88ccfFEU5OjpGRkbSNfsAlMezZ8+WLl3q5+e3dOnSoqIi5GxQBjjaBoZ1dHQkJydv3rzZxsYmNTV1+vTpTEcEQAghGRkZwcHBhoaGBw8efOutt5gOB+B/4WgbGMblckNDQ2/dumViYvLmm29GRka+evWK6aBArT19+tTT09PPz8/b27uwsBA5G5QK0jYoBRsbm19//TU5OTk5OdnJyenatWtMRwTqiKKo/fv3T5gwobi4+MKFC999952+vj7TQQH8F6RtUBYcDufTTz8tLCw0NTUVCASRkZFtbW1MBwVqpLy83NXVdfXq1StXrrx169b8+fOZjgigF0jboFysrKxyc3OTk5NTUlIcHBwuXbrEdESg+uiDbAcHh6dPn165cuVf//qXnp4e00EB9A5pG5QOfdhdVFRkZWW1YMGCwMDA5uZmpoMClXX//v2FCxeuWbNmzZo1f/zxx8yZM5mOCEASpG1QUmPGjPn555+PHTuWmZk5ZcqUX3/9lemIQNV0dXXt379/ypQpNTU1+fn5u3fv1tbWZjoogH4gbYNS8/X1vX379pQpUxYuXBgYGNjU1MR0RKAiSktLFyxYsHbt2rVr116/ft3JyYnpiACkgrQNys7c3Pynn35KS0vLyspycHDIzc1lOiJgt46Ojj179kyePLm+vv7q1au7d+/W0tJiOigAaSFtAzv4+voWFxe/8cYbrq6uH374YV1dHdMRASvdvn1bIBBER0dHRkZeu3Zt2rRpTEcEMDBI28AaZmZmmZmZaWlp586dmzRp0smTJ5mOCNiEPsh2cnLicrk3btyIjo7m8XhMBwUwYEjbwDK+vr537951d3f39PRctmzZixcvmI4IWKCwsPDNN9/csWPHjh07fvvtt4kTJzIdEYCMkLaBfUxMTL777rtTp05duXJl8uTJP/30E9MRgfISCoV79uyZMWOGjo7OzZs3IyIiNDU1mQ4KQHZI28BWf/vb327fvu3h4bF06dJly5bV1NQwHREond9//93R0TEmJiYmJubSpUt2dnZMRwQwWEjbwGLGxsbffffd2bNnf//990mTJmVkZDAdESiLtra2yMjI2bNnDx8+vKCgICIiQkMDP3egCvA9BtZbtGhRUVHRkiVL/Pz83N3dnzx5wnREwLArV65Mmzbt22+/TUlJuXjx4rhx45iOCEBukLZBFRgZGX333Xfnzp0rKiqaPHny/v37mY4ImNHa2hoZGTl37tyxY8fevn37008/5XA4TAcFIE9I26A6XF1d79y58+mnnwYHB7u5uVVWVjIdESjU5cuXHR0dv/vuu5SUlLNnz77++utMRwQgf0jboFJ0dXV379598eLF0tJS+rCboiimg4Ih19LSEhkZOW/ePFtb26KiIhxkgwpD2gYVNHv27IKCgqCgoNWrVy9atKiiooLpiGAInT9/fuLEifv37//222/PnDkzevRopiMCGEJI26CadHR0du/e/dtvvz18+NDBweFf//pXV1cX00GBnNXX1wcGBi5atGjKlCn0lWymIwIYckjboMpcXFxu3rwZHBwcHh4+f/78kpISpiMCucnJyZk8eXJ2dnZ6evqpU6dee+01piMCUASkbVBxfD5/9+7d169fb2xsdHR03LNnDw672e7ly5eBgYGLFy92cXEpLi728fFhOiIAxeHghh1QE0KhMD4+ftu2bU5OTocPH8aEWSx1+vTpoKCgzs7OlJQULy8vpsMBUDQcbYO64PF4ERER165de/Xq1bRp0/bs2dPZ2cl0UDAAVVVVH374obu7u0AgKC4uRs4G9YSjbVA7HR0d//znP7dv3z5t2rTDhw+jGBQrZGRkrFmzhsfjffvttx4eHkyHA8AYHG2D2uFyuREREdevX+/s7Jw+fXp0dLRQKGQ6KOjT8+fPvb29/fz8vLy8/ud//gc5G9QcjrZBfdGH3dHR0XZ2docPH54+fTrTEUF3GRkZwcHBBgYGBw4cePvtt5kOB4B5ONoG9UUfdhcVFRkZGTk7O0dGRra3tzMdFPyvp0+f0uVhvL29i4qKkLMBaDjaBiBdXV0HDx5cv369tbX14cOHnZyc+loNxR/lSML+zMjICAoKMjY2Pnjw4IIFCxQcGIAyw28QANHQ0Pj0008LCwtHjBjh4uISGRn56tWrbut0dXV5eHg8ePCAkQhVz8GDB/fu3duzvby83NXV1d/f38fHp7CwEDkboBscbQP8H4qiDhw4sGHDBktLy8OHD8+cOVO0aO/evZ9//vn06dPz8/O1tLQYDFIF3Lp1a+bMmRRFFRYWTpgwgW4U7XwzM7NDhw7NnTuX2SABlBOOtgH+D4fDoQ+7zc3NXVxcAgMDm5ubCSF3797dsmULIeTWrVvh4eFMh8lu9fX1S5Ys6erqoijqww8/pCete/Dgwdtvv71mzZrVq1ffvn0bORugLzjaBugFRVFHjhwJCwsbNmzY/v37t2zZcv36ddFzYkeOHAkICGA2QpaiKMrb2/v06dP0ztTQ0Ni7d6++vn54ePjYsWMPHz48Y8YMpmMEUGpI2wB9evTo0aeffnr+/HlCiGikcDgcPp//xx9/YJ4WGSQkJISHh4v/7GhqanI4nM2bN2/atAlXHwD6hbQNIMmDBw8mTJjQ7cEwLpdrY2Nz48YNXV1dpgJjo6tXr86ePbujo0O8kcfj2dnZ3bp1C3fpA0gD4wSgTxRFrVq1quefth0dHWVlZf/4xz8YiYqlamtrvb29e7YLhcI7d+58++23ig8JgI2QtgH6tG/fvkuXLvU69WlHR0daWtqhQ4cUHxUbdXV1+fv7V1VVdTvUFi3dsGFDWVmZ4gMDYB2cJAfoXUVFxcSJE1taWiSso6Wl9Z///Gfq1KkKi4qlYmJiduzYIbnS+VtvvZWbm8vhcBQWFQAb4WgboHcNDQ1r1qyZNm0afc2Vz+f3XKezs9PDw6O+vl7h0bHJL7/80mvO5nA4XC6XEKKrq/vuu+8uWrSIftwOACTA0TZAP5qbm/Pz83Nzcy9cuHDjxo3Ozk5tbW3RNGo8Hs/V1fXUqVM4TOzVs2fPHBwc6urq6OrmHA6Hx+O1t7fz+XxnZ+d58+bNnj177ty5uIccQEpI2wAD0NDQcOnSpby8vNzc3KKiInpW7a6uroSEhLCwMKajUzodHR1z587Nz8+n95KOjs7s2bPffvvt+fPnT58+nT7UBoABUfe07evrm5mZyXQUAAAgSTG55UkAACAASURBVFpa2rJly5iOQingr13i7Oy8bt06pqMAdmtubq6qqrKyshrQu/Lz8xMTE9PS0oYoKmYJhcKHDx9aWVlpamr6+fmFhYW5uLgwHRSwkp+fH9MhKBGkbTJ69Gj8EQdMSUxMVIevn5+fn4uLizpsKQwFpG1xuJMcAACANZC2AQAAWANpGwAAgDWQtgEAAFgDaRsAAIA1kLYBWObs2bNGRkanTp1iOhA5CwoK4vwlICBAfFFubm5UVFRWVpa1tTW9wooVK8RXcHV1NTAw0NTUnDRp0o0bNxQb+H+h594RCATijSdPntyzZw89T9xAqd62Z2dni/6jR4wYofAw2Y9Sbz4+Pj4+PkxHAWqKfmJ7oO86ffq0oaHhyZMnhyKkIUIISUtLk7xOYGDgsGHDcnJy7t6929bWJmrftm2bu7t7Q0MD/dLGxmb48OGEkNOnT4u/PScnx9PTU+6RD8i9e/dmzZpFCJk6dWq3RYmJifPmzaurqxtQhyq57V1dXZWVlZcuXVq8ePHw4cOl6Vya74/6wNE2AMu4ubnV19e7u7sP9Qe1trZ2O3Iaajo6Ou+999748eO1tbXplt27dx87diw9Pd3AwEC0WlJSkoaGRmBgoFIVcbl161ZkZGRwcLCjo2PPpaGhoVOnTl28eHGvpUt7parbzuFwLCws5syZM27cOIVHqgqQtgGgd4cOHaqqqmIwgNLS0q1bt+7YsaNb+TWBQBAWFvb48eMNGzYwFVtPU6dOzcrKWr58uehvjm6io6MLCgoSExOl6U2dtx0kQ9oGYJPLly9bWlpyOJxvvvmGEJKSkqKnp6erq3vixIlFixYZGhqOHj36xx9/pFdOSkri8/mmpqZBQUHm5uZ8Pl8gEFy9epVeGhISoqWlNWrUKPrlmjVr9PT0OBxOTU0NISQsLCw8PLysrIzD4dja2hJCzp07Z2houGvXLoVtbFJSEkVRHh4ePRfFxsaOHz/+4MGDubm5vb6Xoqj4+PiJEydqa2ubmJgsWbLkzz//pBdJ3mmEkM7Ozm3btllaWuro6EyZMkVes8+amJjMmzcvMTGRkqIShDpvO/SDyTP0SgDXtoFBsl3bfvToESHk66+/pl9u3ryZEPLLL7/U19dXVVXNmTNHT0+vvb2dXhoYGKinp3fnzp22trbi4uIZM2YYGBhUVFTQS5cvX25mZibqee/evYSQ6upq+qW3t7eNjY1o6enTpw0MDGJiYmTYUiLdtW0LCwvxFmtra3t7+26r2djYPHjwgKKoK1euaGhojB07tqmpiepxfXfbtm1aWlpHjhx5+fJlYWHh9OnTR4wY8ezZM3qp5J22YcMGbW3tzMzMurq6TZs2aWhoXLt2TfqNffPNN3te36VFRUURQm7evNlvJ+qw7aGhobi2LQMcbQOoAoFAYGhoOHLkSH9//+bm5oqKCtEiLpdLH3jZ29unpKQ0NjampqbK8BFubm4NDQ1bt26VX9SSNDc3P3jwwMbGpq8VXFxc1q1bV15eHhkZ2W1Ra2trfHz80qVLAwICjIyMHBwc9u3bV1NTs3//fvHVet1pbW1tKSkpXl5e3t7exsbGW7Zs4fF4su2xnuiruUVFRZJXU+dth34hbQOoFC0tLUKIUCjsdamTk5Ourq7olKkyq6qqoihKV1dXwjqxsbF2dnbJycmXL18Wby8uLm5qanJychK1zJgxQ0tLS3SBoBvxnXb37t2WlpbJkyfTi3R0dEaNGiWvPUZvzvPnzyWvps7bDv1C2gZQL9ra2tXV1UxH0b+2tjZCSF+3ONH4fH5qaiqHw1m1alVra6uo/eXLl4QQfX198ZWNjY0bGxv7/dzm5mZCyJYtW0TPFj98+LClpUW2rehGR0eH/LVpEqjztkO/kLYB1IhQKHz58uXo0aOZDqR/9K98v1OUuLi4rF+/vqSkZOfOnaJGY2NjQki3RCXlho8cOZIQkpCQIH41MT8/X4ZN6Km9vZ38tWkSqPO2Q7+QtgHUSF5eHkVRzs7O9Esul9vX6XTGmZqacjgcaZ5O3rlz54QJE27evClqmTx5sr6+/vXr10UtV69ebW9vf+ONN/rt7fXXX+fz+QUFBbKFLRm9OWZmZpJXU+dth34hbQOouK6urrq6uo6OjsLCwrCwMEtLy5UrV9KLbG1ta2trs7OzhUJhdXX1w4cPxd84bNiwJ0+elJeXNzY2CoXCnJwcRT4Apqura21tXVlZ2e+a9OliTU1N8Zbw8PDjx48fPXq0oaGhqKgoODjY3Nw8MDBQmt4++uijH3/8MSUlpaGhobOzs7Ky8unTp4QQf39/MzOzwUwgSm+Og4OD5N5UftthUBR417oywgNgwCAZHgD7+uuv6SetdXV1PTw8kpOT6Tt9xo0bV1ZWtn//fkNDQ0LImDFj7t27R1FUYGAgj8ezsLDgcrmGhoZLliwpKysT9fbixYsFCxbw+XwrK6vPPvts48aNhBBbW1v6CbEbN26MGTNGR0dn9uzZz549O3v2rIGBQWxsrAxbSmR6ACwkJITH47W0tNAvjx8/Tt9cPWLEiLVr13Z7+8aNG8Ufgurq6tq7d++4ceN4PJ6JiYmXl9fdu3fpRf3utFevXkVERFhaWnK53JEjR3p7excXF1MU5eXlRQjZtm1br/Hn5+fPmjXL3Nyc/mkdNWqUQCC4ePGi+Dpubm4WFhZdXV399qba207DA2CyQdpG2gbGyPbc9oDQE30P6UdIQ7a0XVJSwuVyjxw5MpShDUBnZ+ecOXMOHTok29tramr4fP5XX30lTW+qve00pG3Z4CQ5gIqTrfAUI1pbW8+fP19SUkLfvmRraxsTExMTE9PU1MR0aKSzszM7O7uxsdHf31+2HqKjox0dHUNCQqTpTYW3naKoJ0+eXL58ubS0VK5hqgukbZCzu3fvfvbZZ5MmTTIwMOByuUZGRuPHj3dzc5PX/aigwmpra+lSIqtWraJboqKifH19/f39Ga+ckZeXl5WVlZOTI/lx6r7Ex8cXFBScPXuWx+NJ2ZuqbvuJEyfoUiJnzpyRd6TqgenDfYbhJLl8HTx4kMfjzZ0799y5c3V1dW1tbWVlZceOHRMIBN999x3T0SmdoT5JHhUVRU+mMXbs2IyMjKH7oH6RwZ3kPH/+fEREhBzjUbDs7Oy4uLiOjg4Z3qvO2y4yyO+PikHaZk3abmlpcXFxUebO8/PzNTU133rrLaFQ2G3RuXPnRHNoK5KS7zQFXNtWEvjZhcHA90ccl8EDfRiQIa2iKJfOY2NjOzs7v/jiCy63+/fq3XfffffddwfZvwyUf6cBAAwIrm1L68iRI05OTnw+X09Pb+zYsfS0RNQgCuT11edvv/1mb29vZGTE5/MdHBzOnz9Pequi2Gt9vX4/dDCdE4mlG9vb23/55Zfhw4fPnDlT8p5Ut50GACBPTB/uM0zKk+QJCQmEkC+++OLFixe1tbXffffd8uXLqcEVyOurz4yMjOjo6Nra2hcvXjg7O4sekOhWRbGv+nqSP3SQnUso3Xjv3j1CiLOzc787U912mgQ4SQ4gDXx/xKnFT4YE0qTt9vZ2Y2PjBQsWiFo6OjoSExNbWlr09fX9/f1F7f/5z38IIaKsRieD1tZW+mVycjIhpLS0VEKf3T46Li6O/FUOSDxJtLa26urqij66paVFW1t79erVkj908J1LQE+m+Pbbb0teDTtNHNI2gDTw/RGHa9v9KywsfPnypfilWU1NzdDQ0OvXr8tcIK+vPru9hX5eoudzt9LX15NQxnHwnYujKw71WyxoMFUFVW+n0dLT06VZje3wBCCAXCBt96+hoYH8VVdH3GAK5PXVJyHkzJkze/fuLS4ubmho6KvMg6i+3pYtW0SNopkFJRi6zseOHcvn8+lT5RJgp/Xk5+cnzWpsl5iYmJiYyHQUAKyHW9L699prrxFCampqurUPpkBeX31WVFR4eXmNGjXq6tWr9fX1e/bs6fXtstXXG9LOtbW133333Zqamn//+989l9bW1n788ccEO603Q3cyTXkQnOSEQZBmHKkPpO3+jR07dtiwYT///HO39sEUyOurz6KiIqFQuHr1amtraz6fz+Fwen27bPX1hrRzQkh0dLS2tvb69etbW1u7Lbp9+zb9VBh2GgDAYCBt909bW3vTpk2XLl0KCQl5/PhxV1dXY2PjnTt3BlMgr68+LS0tCSG5ubltbW0lJSXiV3zFqyhqamr2VV9PgsF3Lrl0o6Oj4w8//HD79u05c+acPXu2vr5eKBQ+ePDgwIED//jHP+irwmq40wAA5Inpkx8Mk36WtG+++cbBwYHP5/P5/GnTpiUnJ1ODK5DXV58RERHDhg0zNjb29fX95ptvCCE2NjYVFRXdqij2Wl+v3w8dTOcURUlTurGiomLDhg0ODg76+vqamprGxsbTpk37xz/+8e9//5teQd12mgS4kxxAGvj+iONQ6n3ZwNfXlxCSkZHBdCCgjtLT0/38/NRhDHI4nLS0tGXLljEdCLASvj/icJIcAACANZC2AQAAWANpGwBAktzc3KioqKysLGtraw6Hw+FwVqxYIb6Cq6urgYGBpqbmpEmTbty4wUiQMTEx9vb2hoaG2tratra2n3/+eVNTE73o5MmTe/bs6TlHELAU0jYAQJ+2b9+elJS0adMmb2/v+/fv29jYDB8+/OjRo2fOnBGt8/PPP2dkZLi7uxcXF0+fPp2ROC9cuLB27dry8vKampq4uLjExET6xh1CiIeHB5/PX7hwIT3ZEbAd0jaAKmttbRUIBMrWFVvs3r372LFj6enpBgYGosakpCQNDY3AwMD6+noGY+tGX18/MDBw2LBhBgYGy5Yt8/LyOnfu3KNHj+iloaGhU6dOXbx4cUdHB7NxwuAhbQOoMjkWBVe3+uKlpaVbt27dsWMHn88XbxcIBGFhYY8fP96wYQNTsfV0+vRpTU1N0csRI0aQ/64REB0dXVBQgPllVQDSNoCyo/quUB4SEqKlpTVq1Cj65Zo1a/T09DgcDj0FbLei4ElJSXw+39TUNCgoyNzcnM/nCwQC0QQyA+qKSCy+rhqSkpIoivLw8Oi5KDY2dvz48QcPHszNze31vRL+y/qt7y6Xwu2PHz/W0dGxsrIStZiYmMybN4+umCdDh6BEmHxoXAlIP90KgNxJOd2K5Arly5cvNzMzE628d+9eQkh1dTX9sltR8MDAQD09vTt37rS1tRUXF8+YMcPAwKCiokKGriQUX++JsHC6DGtra3t7+26NNjY2Dx48oCjqypUrGhoaY8eObWpqoigqJyfH09NTtNpgisrLULi9m+bmZgMDg5CQkG7tUVFRhJCbN28OqDdlwMbvz9DB0TaAUmttbY2Pj1+6dGlAQICRkZGDg8O+fftqamr2798vW4dcLpc+CrS3t09JSWlsbExNTZWhHzc3t4aGhq1bt8oWhpJrbm5+8OCBjY1NXyu4uLisW7euvLw8MjKy2yIp/8sEAoGhoeHIkSP9/f2bm5srKioIIW1tbSkpKV5eXt7e3sbGxlu2bOHxeAP9D4qLizM3N4+Nje3WPm7cOEJIUVHRgHoDZYO0DaDUBlqhfECcnJx0dXWlrAuuVqqqqiiKome97UtsbKydnV1ycvLly5fF2wdTVH4whdtpx48fT09PP3/+vPhtdDR6c54/fy59b6CEkLYBlNpgKpRLQ1tbu7q6Wi5dqZK2tjZCiLa2toR1+Hx+amoqh8NZtWqVeNW7wfyXiQq3c/7y8OFD8TvLJDt27Nju3bvz8vLGjh3bc6mOjg75a9OAvZC2AZTaYCqU90soFMqrKxVDZ7h+pyhxcXFZv359SUnJzp07RY2D+S8bTOH2r7/++ujRoxcuXKAr0/fU3t5O/to0YC+kbQCl1m+Fci6XS59flUFeXh5FUc7OzoPvSsWYmppyOBxpnszeuXPnhAkTbt68KWoZTFF52Qq3UxQVERFRVFSUnZ3d7ShfHL05ZmZmA+oclA3SNoBS67dCua2tbW1tbXZ2tlAorK6ufvjwofjbxYuC0ym5q6urrq6uo6OjsLAwLCzM0tJy5cqVMnQlufg62+nq6lpbW1dWVva7Jn2qXPyZ6cEUlefz+X0Vbvf39zczM+t18tQ7d+58+eWXBw4c4PF4HDFfffWV+Gr05jg4OPQbBigzpG0AZbd9+/a4uLiYmJgRI0bMmzdv7NixeXl5enp69NLVq1cvWLDg/ffft7Oz27lzJ30K1MXFhZ4hKzg42NTU1N7efvHixbW1tYSQtrY2BwcHHR2dOXPmjB8//tdffxVdwR1oV6rNzc2tuLhYdNH6p59+srW1LSsrmzFjxmeffSa+prOz8/r168VbJPyXpaSkJCQkEEKmTJly//79AwcOhIeHE0Lee++9kpISQkhiYuK6dev27NkzfPhwc3PzsLCwuro6Qkh7e3tVVdWJEyd6hkpJ9yj2tWvXLCwspkyZIsPeACXCxFNnSgTPbQODpHxuW47o+S8V+Yk0wsLnbktKSrhc7pEjR5gO5H91dnbOmTPn0KFDsr29pqaGz+d/9dVX8o1KMdj4/Rk6ONoGUC+oBCUlW1vbmJiYmJgYUSktBnV2dmZnZzc2Nvr7+8vWQ3R0tKOjY0hIiHwDA8VD2gYA6F1UVJSvr6+/vz/jVUPy8vKysrJycnIkP0rel/j4+IKCgrNnz/J4PLnHBgqGtA2gLjZt2pSamlpfX29lZZWZmcl0OOywa9eukJCQL774gtkwFi5c+MMPP4hmjB+QEydOvHr1Ki8vz8TERO6BgeJxmQ4AABQkLi4uLi6O6SjYx9XV1dXVlekoZOfp6enp6cl0FCA3ONoGAABgDaRtAAAA1kDaBgAAYA2kbQAAANbALWnk999/9/X1ZToKUEf0ZJNq8vVLSEjIyMhgOgoA1uNQ0s2Kp6ri4+OlrK4DwArPnj27efPmokWLmA4EQJ7Wr1/v4uLCdBRKQd3TNoCKSU9P9/Pzw7gGUFW4tg0AAMAaSNsAAACsgbQNAADAGkjbAAAArIG0DQAAwBpI2wAAAKyBtA0AAMAaSNsAAACsgbQNAADAGkjbAAAArIG0DQAAwBpI2wAAAKyBtA0AAMAaSNsAAACsgbQNAADAGkjbAAAArIG0DQAAwBpI2wAAAKyBtA0AAMAaSNsAAACsgbQNAADAGkjbAAAArIG0DQAAwBpI2wAAAKyBtA0AAMAaSNsAAACsgbQNAADAGkjbAAAArIG0DQAAwBpI2wAAAKyBtA0AAMAaSNsAAACswWU6AAAYFKFQ2NTUJHrZ3NxMCKmrqxO1cDgcY2NjBiIDgCHAoSiK6RgAQHbPnz+3sLDo7Ozsa4UFCxZcuHBBkSEBwNDBSXIAdjMzM5s7d66GRu9jmcPhvP/++woOCQCGDtI2AOutWLGir0WamppLly5VZDAAMKSQtgFYz9vbm8vt5T4VTU3N9957b/jw4YoPCQCGCNI2AOsZGhouWrSoZ+amKCogIICRkABgiCBtA6iCgICAnnelaWlp/e1vf2MkHgAYIkjbAKrgb3/7m66urngLj8fz8vLS09NjKiQAGApI2wCqgM/nL126lMfjiVqEQuHy5csZDAkAhgLSNoCK+OCDD4RCoeiloaHhO++8w2A8ADAUkLYBVMTbb789bNgw+t88Hu/999/X0tJiNiQAkDukbQAVweVy33//ffo8uVAo/OCDD5iOCADkD5ObAqiOf//737NnzyaEmJmZPXnypK+p0wCAvTCqAVSHQCCwsLAghHz44YfI2QAqCRXAgBBC8vPzHz16xHQUIAczZsx4/Pjx8OHD09PTmY4F5EAgEIwePZrpKECJ4CQ5EEKIr69vZmYm01EAQHdpaWnLli1jOgpQIjjahv/l4+OTkZHBdBTqgsPhDN3PcWZmpo+Pz1D0PFC+vr6EEHyvZMbhcJgOAZQOrn4BqBolydkAMBSQtgEAAFgDaRsAAIA1kLYBAABYA2kbAACANZC2AQAAWANpG4A1zp49a2RkdOrUKaYDUZDc3NyoqKisrCxra2sOh8PhcFasWCG+gqurq4GBgaam5qRJk27cuMFIkDExMfb29oaGhtra2ra2tp9//nlTUxO96OTJk3v27Ons7GQkMFBVSNsArKFWkyNt3749KSlp06ZN3t7e9+/ft7GxGT58+NGjR8+cOSNa5+eff87IyHB3dy8uLp4+fTojcV64cGHt2rXl5eU1NTVxcXGJiYn00+qEEA8PDz6fv3DhwpcvXzISG6gkpG0A1nBzc6uvr3d3dx/qD2ptbRUIBEP9KRLs3r372LFj6enpBgYGosakpCQNDY3AwMD6+noGY+tGX18/MDBw2LBhBgYGy5Yt8/LyOnfunGiq4NDQ0KlTpy5evLijo4PZOEFlIG0DQHeHDh2qqqpi6tNLS0u3bt26Y8cOPp8v3i4QCMLCwh4/frxhwwamYuvp9OnTmpqaopcjRowghLS0tIhaoqOjCwoKEhMTGQgOVBHSNgA7XL582dLSksPhfPPNN4SQlJQUPT09XV3dEydOLFq0yNDQcPTo0T/++CO9clJSEp/PNzU1DQoKMjc35/P5AoHg6tWr9NKQkBAtLa1Ro0bRL9esWaOnp8fhcGpqagghYWFh4eHhZWVlHA7H1taWEHLu3DlDQ8Ndu3YpZkuTkpIoivLw8Oi5KDY2dvz48QcPHszNze31vRRFxcfHT5w4UVtb28TEZMmSJX/++Se9SPIeI4R0dnZu27bN0tJSR0dnypQpaWlpMgT/+PFjHR0dKysrUYuJicm8efMSExPV6hoHDB2kbQB2mD179pUrV0QvV69evW7dutbWVgMDg7S0tLKyMmtr608++UQoFBJCQkJCVq5c2dLSEhoaWl5efuPGjY6OjnfeeYc+eZuUlCQ+HXpycvKOHTtELxMTE93d3W1sbCiKKi0tJYTQN1V1dXUpZkvPnDljZ2enq6vbc5GOjs7333+voaHxySefNDc391whOjo6Kipq8+bNVVVVly5devTo0Zw5c54/f07622OEkMjIyC+//DIhIeHp06fu7u4ffPDB9evXBxR5S0vLhQsXPvnkEy0tLfH2adOmPX78+NatWwPqDaBXSNsA7CYQCAwNDUeOHOnv79/c3FxRUSFaxOVy6eNOe3v7lJSUxsbG1NRUGT7Czc2toaFh69at8ou6T83NzQ8ePLCxselrBRcXl3Xr1pWXl0dGRnZb1NraGh8fv3Tp0oCAACMjIwcHh3379tXU1Ozfv198tV73WFtbW0pKipeXl7e3t7Gx8ZYtW3g83kB3V1xcnLm5eWxsbLf2cePGEUKKiooG1BtAr5C2AVQEfYQnOnbsxsnJSVdXV3TGWGlVVVVRFNXrobZIbGysnZ1dcnLy5cuXxduLi4ubmpqcnJxELTNmzNDS0hJdHehGfI/dvXu3paVl8uTJ9CIdHZ1Ro0YNaHcdP348PT39/Pnz4rfR0ejNoQ/6AQYJaRtAXWhra1dXVzMdRT/a2toIIdra2hLW4fP5qampHA5n1apVra2tonb6OSt9fX3xlY2NjRsbG/v9XPqU+5YtWzh/efjwofidZZIdO3Zs9+7deXl5Y8eO7blUR0eH/LVpAIOEtA2gFoRC4cuXL0ePHs10IP2gM1y/U5S4uLisX7++pKRk586dokZjY2NCSLckLeVWjxw5khCSkJBAicnPz5cm5q+//vro0aMXLlx47bXXel2hvb2d/LVpAIOEtA2gFvLy8iiKcnZ2pl9yudy+Tqczy9TUlMPhSPNk9s6dOydMmHDz5k1Ry+TJk/X19cXvI7t69Wp7e/sbb7zRb2+vv/46n88vKCgYULQURUVERBQVFWVnZ3c7yhdHb46ZmdmAOgfoFdI2gMrq6uqqq6vr6OgoLCwMCwuztLRcuXIlvcjW1ra2tjY7O1soFFZXVz98+FD8jcOGDXvy5El5eXljY6NQKMzJyVHYA2C6urrW1taVlZX9rkmfKhd/ZprP54eHhx8/fvzo0aMNDQ1FRUXBwcHm5uaBgYHS9PbRRx/9+OOPKSkpDQ0NnZ2dlZWVT58+JYT4+/ubmZn1OnnqnTt3vvzyywMHDvB4PI6Yr776Snw1enMcHBz6DQOgX0jbAOzwzTffzJgxgxASERHh6emZkpKSkJBACJkyZcr9+/cPHDgQHh5OCHnvvfdKSkrot7S1tTk4OOjo6MyZM2f8+PG//vqr6Jrx6tWrFyxY8P7779vZ2e3cuZM+f+vi4kI/IRYcHGxqampvb7948eLa2loFb6mbm1txcbHoovVPP/1ka2tbVlY2Y8aMzz77THxNZ2fn9evXi7ds3749Li4uJiZmxIgR8+bNGzt2bF5enp6eHiGk3z2WmJi4bt26PXv2DB8+3NzcPCwsrK6ujhDS3t5eVVV14sSJnqFK+Sj2tWvXLCwspkyZIsPeAOiGgxkAgBBCz6KckZHBdCDqgsPhpKWliT88LXdBQUEZGRkvXrwYuo/ol2zfq9LS0okTJ6ampgYEBAxNXAPT1dU1f/78lStXrlq1Soa3v3jxYvTo0bGxsfRfCQOigO8JsA6OtgFUFktrT9na2sbExMTExIhKaTGos7MzOzu7sbHR399fth6io6MdHR1DQkLkGxioLaRtkNHHH39sYGDA4XAGehfPEBEv70jT0tIyNTWdP3/+3r176bOdwBZRUVG+vr7+/v6MVw3Jy8vLysrKycmR/Ch5X+Lj4wsKCs6ePcvj8eQeG6gnpG2Q0cGDBw8cOMB0FP9HVN7RyMiIoqiurq6qqqr09HQrK6uIiIhJkyYNdKJKVtu0aVNqamp9fb2VlVVmZibT4chi165dISEhX3zxBbNhLFy48IcffhDN3z4gJ06cePXqVV5enomJidwDA7XFZToAgCHB4XCMjY3nz58/f/58Nzc3Pz8/Nze3e/fuGRkZMR2aIsTFxcXFxTEdxWC5urq6uroyHYXsPD09PT09mY4CVA2OtkF2HA6HR5NRYAAAIABJREFU6RCk4uPjs3Llyqqqqn379jEdCwDAoCBtwwBQFLV37147OzttbW0jI6ONGzeKL+217mG/1RIvXrw4c+ZMXV1dQ0NDBweHhoaGvroig6ggST+vnJOTo7BQAQCGAtI2DMDWrVsjIiICAwOfP3/+7NmzbiWYeq17KLlaYnNzs4eHh4+PT21tbUlJyfjx4+lpIPsqoShzBUlHR0dCyP379xUWKgDAkKAAKMrHx8fHx0fyOi0tLbq6uu+8846ohT4SvXnzJkVRra2turq6/v7+opW1tbVXr15NUdTmzZsJIa2trfSi5ORkQkhpaSlFUbdv3yaEnD59WvyDJHTVL9EtaT3RV7uVJFRCSFpamjRbxGrSfK9AAjX5nsCA4JY0kFZpaWlLS8vChQt7XSp93UPxaonW1tampqYBAQGhoaErV66kqycNvoRiT83NzRRFGRoaKk+oCQkJKj+/ze+//07+mnQFAOQCJ8lBWvS8ynShpJ5kq3uoo6Nz4cKF2bNn79q1y9ra2t/fv7W1dZAlFHt17949QsiECROUP1QAAAlwtA3S4vP5hJBXr171ulRU9zAsLGxA3U6aNOnUqVPV1dXx8fG7d++eNGkSPR2VDF1JcO7cOULIokWLlCfUdevWqfyklZg0d5DY8rAGKBKOtkFakydP1tDQuHjxYq9LZat7+OTJkzt37hBCRo4c+cUXX0yfPv3OnTuydSXBs2fPEhISRo8eTc8prcyhAgBIhrQN0ho5cqS3t3dmZuahQ4caGhoKCwv3798vWiqh7qEET548CQoK+vPPP9vb22/evPnw4UNnZ2cJXUlTQZKiqKampq6uLoqiqqur09LSZs2apampmZ2dTV/bVkyoAABDguFb4kA5SHnHb2Nj48cffzx8+HB9ff3Zs2dv27aNEDJ69Ohbt25RFPXq1auIiAhLS0sul0vn+OLi4uTkZHoy53HjxpWVle3fv5/OnWPGjLl37155eblAIDAxMdHU1Hzttdc2b97c0dHRV1cURZ09e9bAwCA2NrZnbCdPnpwyZYqurq6WlpaGhgb5a6K0mTNnxsTEvHjxQnxlBYQqGVGPO4RxJ/kgqcn3BAYEhTuBEFyDVDg1KciI79Ugqcn3BAYEJ8kBAABYA2kbAJRFbm5uVFSUeA3WFStWiK/g6upqYGCgqak5adKkGzduMBUnIaSrqyshIUEgEPRcdPny5VmzZunq6pqbm0dERIgevjh58uSePXtYWgQdlAfSNgAohe3btyclJW3atElUg3X48OFHjx49c+aMaJ2ff/45IyPD3d29uLh4+vTpTIVaUlIyd+7c9evX93xGv7i42NXVdeHChdXV1cePHz98+HBwcDC9yMPDg8/nL1y48OXLlwoPGVQH0jaACmptbe31QJDZriTYvXv3sWPH0tPTDQwMRI1JSUkaGhqBgYH19fVDHYD0bt26FRkZGRwcTE90383OnTtHjRq1Y8cOPT09FxeXiIiI77//XjRxXmho6NSpUxcvXtzR0aHYqEF1IG0DqKBDhw5VVVUpW1d9KS0t3bp1644dO+gpfUQEAkFYWNjjx483bNgwpAEMyNSpU7OyspYvX66trd1tUUdHx5kzZ+bNmyeaJmXRokUURZ04cUK0TnR0dEFBQWJiouIiBtWCtA2gpCiKio+Pnzhxora2tomJyZIlS0QHbSEhIVpaWqNGjaJfrlmzRk9Pj8Ph1NTUEELCwsLCw8PLyso4HI6trW1SUhKfzzc1NQ0KCjI3N+fz+QKB4OrVqzJ0RQZRO1WCpKQkiqI8PDx6LoqNjR0/fvzBgwdzc3MHupf6rcQq96Kr9+/fb2pqsrS0FLXY2NgQQgoLC0UtJiYm8+bNS0xMxFM8IBukbQAlFR0dHRUVtXnz5qqqqkuXLj169GjOnDnPnz8nhCQlJYk/FJScnLxjxw7Ry8TERHd3dxsbG4qiSktLQ0JCVq5c2dLSEhoaWl5efuPGjY6OjnfeeefRo0cD7YoMonaqBGfOnLGzs6Mfmu9GR0fn+++/19DQ+OSTT+gZ4LuRsJckV2IlQ1B09dmzZ4QQ8fP8fD5fR0eHjkdk2rRpjx8/vnXr1mA+C9QW0jaAMmptbY2Pj1+6dGlAQICRkZGDg8O+fftqamrEZ6YbEC6XSx+S2tvbp6SkNDY2pqamytCPm5tbQ0PD1q1bZQujp+bm5gcPHtBHpb1ycXFZt25deXl5t/ruROq9JBAIDA0NR44c6e/v39zcXFFRQQhpa2tLSUnx8vLy9vY2NjbesmULj8eTbZ+I0DeNa2pqijfyeLzW1lbxlnHjxhFCioqKBvNZoLaQtgGUUXFxcVNTk5OTk6hlxowZWlpaopPbg+Hk5KSrqzvIWqjyUlVVRVFUr4faIrGxsXZ2dsnJyZcvXxZvH+heEq/EOhT1Yelr891uN2tvb9fR0RFvoTe22yE4gJSQtgGUEf2MkL6+vnijsbFxY2OjXPrX1taurq6WS1eD1NbWRgjpeXuXOD6fn5qayuFwVq1aJX7kOpi9NBRFV+lbBBoaGkQtLS0tbW1t5ubm4qvRWZzecICBQtoGUEbGxsaEkG7p5+XLl6NHjx5850KhUF5dDR6dw/qdhMTFxWX9+vUlJSU7d+4UNQ5mL4nqt4rP9pyfny/DJohYWVkZGBg8fPhQ1ELfEDBlyhTx1drb28lfGw4wUEjbAMpo8uTJ+vr64ndIXb16tb29/Y033qBfcrlc0a1VA5WXl0dRlLOz8+C7GjxTU1MOhyPNk9k7d+6cMGHCzZs3RS397iUJhqLoKpfLXbx48aVLl0S37OXk5HA4nG43ydMba2ZmJsePBvWBtA2gjPh8fnh4+PHjx48ePdrQ0FBUVBQcHGxubh4YGEivYGtrW1tbm52dLRQKq6urxY/wCCHDhg178uRJeXl5Y2MjnZK7urrq6uo6OjoKCwvDwsIsLS1XrlwpQ1fS1E4dEF1dXWtr68rKyn7XpE+Vi9/w1e9ektxbX0VX/f39zczMZJs8devWrc+fP9++fXtzc3N+fv7evXtXrlxpZ2cnvg69sQ4ODjL0D4DCnUBRKLCocESKgoxdXV179+4dN24cj8czMTHx8vK6e/euaOmLFy8WLFjA5/OtrKw+++yzjRs3EkJsbW0rKiooirpx48aYMWN0dHRmz5797NmzwMBAHo9nYWHB5XINDQ2XLFlSVlYmW1cSaqf2JOX3KiQkhMfjtbS00C+PHz9O31g+YsSItWvXdlt548aNnp6e0uwlyZVYqb6Lrnp5eRFCtm3b1mu0+fn5s2bNEl2uHjVqlEAguHjxomiFixcvzpw5U1tb29zcfOPGjW1tbd16cHNzs7CwoEvCSybN9wTUDQp3AiEosKhwCi7IGBQUlJGR8eLFC8V8nIiU36vS0tKJEyempqYGBAQoJK5+dHV1zZ8/f+XKlatWrZJ75y9evBg9enRsbGx4eHi/K6NwJ/SEk+QAakGZC0/Z2trGxMTExMQ0NTUxHQvp7OzMzs5ubGz09/cfiv6jo6MdHR1DQkKGonNQB0jbAMC8qKgoX19ff39/xquG5OXlZWVl5eTkSH6UXDbx8fEFBQVnz57l8Xhy7xzUBNI2gIrbtGlTampqfX29lZVVZmYm0+H0adeuXSEhIV988QWzYSxcuPCHH34QTdIuRydOnHj16lVeXp6JiYncOwf1wWU6AAAYWnFxcXFxcUxHIRVXV1dXV1emoxgqnp6enp6eTEcBrIejbQAAANZA2gYAAGANpG0AAADWQNoGAABgDaRtAAAA1sCd5PC/MjMzORwO01GoET8/Pz8/P6ajUAR8rwDkCJObAiGE5OfnP3r0iOkoQA7y8/MTExPT0tKYDgTkQyAQKEmJVVASSNsAKiU9Pd3Pzw/jGkBV4do2AAAAayBtAwAAsAbSNgAAAGsgbQMAALAG0jYAAABrIG0DAACwBtI2AAAAayBtAwAAsAbSNgAAAGsgbQMAALAG0jYAAABrIG0DAACwBtI2AAAAayBtAwAAsAbSNgAAAGsgbQMAALAG0jYAAABrIG0DAACwBtI2AAAAayBtAwAAsAbSNgAAAGsgbQMAALAG0jYAAABrIG0DAACwBtI2AAAAayBtAwAAsAbSNgAAAGsgbQMAALAG0jYAAABrIG0DAACwBtI2AAAAayBtAwAAsAaX6QAAYFCqq6t/+ukn0cvr168TQvbv3y9qMTAweP/99xmIDACGAIeiKKZjAADZvXr1ytTUtKmpSVNTkxBCj2gOh0MvFQqFf//737///nsGIwQAOcJJcgB209bW9vHx4XK5QqFQKBR2dHR0dHQI/0II+eCDD5iOEQDkBkfbAKz3yy+/vP32270uMjY2rq6u5nJxOQxAReBoG4D1FixYMHLkyJ7tPB4vICAAORtAlSBtA7CehobG8uXLeTxet3ahUIib0QBUDE6SA6iC//znP2+++Wa3xtdee62yslJ0exoAqAAcbQOogpkzZ44ZM0a8RUtL6+9//ztyNoCKQdoGUBErVqwQP0/e3t6OM+QAqgcnyQFUxJ9//jlx4kTRS1tb25KSEgbjAYChgKNtABUxYcIEe3t7+qw4j8f76KOPmI4IAOQPaRtAdXz44Yf0XGkdHR04Q/7/27vXmCaytwHgZ6CFoVguKpcu/FFuoiLi4mWl3kOWrLCACChZMNs1McCqpYCEizcEVFySwlYhxtWtyWqUa1BXMMbdICGi2Q2ibl0VUEBUBJH7HTrvh8nO2xSkpbQdis/v25w5nHnOZOLjTGfOA8CsBA/JAZg9mpqaFi5cSBDEypUrycXJAQCzDNxtAzB72NnZkZ+Bff/993THAgDQCFg+CSgmFAqrqqrojgIoZWhoCMOw27dvV1RU0B0LUEpsbKynpyfdUQCdAXfbQLGqqqr79+/THYWOKSwsbG5u1v5xbW1trayscBzXzuHu378P18Z0FBYWvn79mu4ogC6Bu22glLVr1xYUFNAdhS7BMCwmJmbHjh3aP3RdXZ2Tk5N2jhUSEoIQgmtDZbAeDpgquNsGYLbRWs4GAGgfpG0AAABAZ0DaBgAAAHQGpG0AAABAZ0DaBgAAAHQGpG0AZpDS0lJTU9MbN27QHYim3LlzJykpqaioyMHBAcMwDMN27dol28Hb25vNZuvr67u6ulZXV9MVJ0JIKpVmZWVxudzxuyorK9etW8disTgcTkJCwtDQENl+/fr1U6dOjY2NaTdS8HmBtA3ADDK7Fxs+evSoSCRKTk4OCgp6+fKlo6PjvHnzLl26dPPmTarP7du3CwoK/Pz8JBKJh4cHXaHW1tZu3LgxNja2v79fbpdEIvH29vby8mpraysuLv7111+joqLIXf7+/jiOe3l5dXZ2aj1k8LmAtA3ADOLr69vV1eXn56fpAw0MDEx4H6k5GRkZV69ezc/PZ7PZVKNIJNLT04uIiOjq6tJmMJN79OhRYmJiVFTUihUrxu9NS0uztrY+duyYsbGxp6dnQkLCxYsXnz17Ru6Njo52d3f38fEZHR3VbtTgcwFpG4DP0YULF1pbW7V2uLq6usOHDx87dkxu+TYulysQCN68eXPgwAGtBaOQu7t7UVFRWFiYoaGh3K7R0dGbN29u2rSJWiZl69atBEFcu3aN6pOSklJTU5Odna29iMHnBNI2ADNFZWWlnZ0dhmFnzpxBCOXm5hobG7NYrGvXrm3dutXExMTW1vbKlStkZ5FIhOO4paVlZGQkh8PBcZzL5T548IDcy+fzDQwMrK2tyc29e/caGxtjGPbhwweEkEAgiIuLq6+vxzCMXJvl1q1bJiYmx48f19DURCIRQRD+/v7jd6Wnpy9atOj8+fN37tyZ8G8JghAKhUuWLDE0NDQ3N9+2bRt1azv5KUIIjY2NHTlyxM7OzsjIaPny5Xl5edOcyMuXL3t7e+3s7KgWR0dHhNDjx4+pFnNz802bNmVnZ8/unzwAXSBtAzBTrF+//t69e9Tmjz/+GBMTMzAwwGaz8/Ly6uvrHRwc9uzZMzIyghDi8/k8Hq+/vz86OrqhoaG6unp0dPTrr78mF7gWiUSy66rm5OQcO3aM2szOzvbz83N0dCQIoq6uDiFEvkUllUo1NLWbN2+6uLiwWKzxu4yMjC5evKinp7dnz56+vr7xHVJSUpKSkg4ePNja2lpRUfH69esNGza8f/8eKTpFCKHExMSffvopKyvr3bt3fn5+33333TTrmba0tCCEZJ/z4zhuZGRExkP58ssv37x58+jRo+kcC4AJQdoGYKbjcrkmJiYWFhahoaF9fX1NTU3ULgaDQd6GLl26NDc3t6enRywWq3AIX1/f7u7uw4cPqy/q/9fX1/fq1SvyrnRCnp6eMTExDQ0NiYmJcrsGBgaEQuH27dvDw8NNTU3d3NzOnj374cOHc+fOyXab8BQNDg7m5uYGBgYGBQWZmZkdOnSIyWSqdn4o5Evj+vr6so1MJnNgYEC2xdnZGSH05MmT6RwLgAlB2gZAZxgYGCCEqFtJOatWrWKxWNQD5JmjtbWVIIgJb7Up6enpLi4uOTk5lZWVsu0SiaS3t3fVqlVUy+rVqw0MDKifA+TInqLnz5/39/cvW7aM3GVkZGRtbT3N80P+Ni/3utnw8LCRkZFsCzlZuVtwANQC0jYAs4ehoWFbWxvdUcgbHBxECI1/vUsWjuNisRjDsN27d8veuZJfUs2ZM0e2s5mZWU9Pj8Ljko/cDx06hP2nsbFx/AddU0K+LtDd3U219Pf3Dw4Ocjgc2W5kFicnDoB6QdoGYJYYGRnp7Oy0tbWlOxB5ZA5TuAiJp6dnbGxsbW1tWloa1WhmZoYQkkvSSk7TwsICIZSVlUXIqKqqUmEKFHt7ezab3djYSLWQLwcsX75cttvw8DD6b+IAqBekbQBmifLycoIg1q5dS24yGIxPPU7XMktLSwzDlPkyOy0tbfHixQ8fPqRali1bNmfOHNn3yB48eDA8PLxy5UqFo/3vf//Dcbympka1sCfEYDB8fHwqKiqo1/fKysowDJN7SZ6crJWVlRoPDQAJ0jYAOkwqlXZ0dIyOjj5+/FggENjZ2fF4PHKXk5PTx48fS0pKRkZG2traZG8QEUJz5859+/ZtQ0NDT0/PyMhIWVmZ5j4AY7FYDg4Ozc3NCnuSj8plX/jCcTwuLq64uPjSpUvd3d1PnjyJioricDgRERHKjPbDDz9cuXIlNze3u7t7bGysubn53bt3CKHQ0FArKyvVFk89fPjw+/fvjx492tfXV1VVlZmZyePxXFxcZPuQk3Vzc1NhfAAUIABQJDg4ODg4mO4odAxCKC8vb0p/cvr0afKnUxaL5e/vn5OTQ77Z5OzsXF9ff+7cORMTE4TQggULXrx4QRBEREQEk8m0sbFhMBgmJibbtm2rr6+nRmtvb9+yZQuO4/b29vv374+Pj0cIOTk5NTU1EQRRXV29YMECIyOj9evXt7S0lJaWstns9PT0qU5TyWuDz+czmcz+/n5ys7i4mHyxfP78+fv27ZPrHB8fHxAQQG1KpdLMzExnZ2cmk2lubh4YGPj8+XNyl8JTNDQ0lJCQYGdnx2AwLCwsgoKCJBIJQRCBgYEIoSNHjkwYbVVV1bp166ifq62trblc7t27d6kOd+/eXbNmjaGhIYfDiY+PHxwclBvB19fXxsZGKpUqPDMqXCfgM4cRsCAAUCQkJAQhVFBQQHcgugTDsLy8PNmPp9UuMjKyoKCgvb1dc4dQSMlro66ubsmSJWKxODw8XCtxKSCVSjdv3szj8Xbv3q32wdvb221tbdPT0+Pi4hR21sJ1AmYZeEgOgA7TlWJTTk5Oqampqampvb29dMeCxsbGSkpKenp6QkNDNTF+SkrKihUr+Hy+JgYHANI2AEAbkpKSQkJCQkNDaa8aUl5eXlRUVFZWNvmn5KoRCoU1NTWlpaVMJlPtgwOAIG0DdZGtoIxhGPmba1hY2L///jv5HypfYVruEBiGGRgYWFpabt68OTMzs6OjQ01T0Q3Jyclisbirq8ve3r6wsJDucJRy/PhxPp9/8uRJesPw8vK6fPkytWC7Gl27dm1oaKi8vNzc3FztgwNAgrQN1IOqoGxqakoQRGdn59mzZysrK9esWfP8+fNJ/lD5tyvkDiGVSltbW/Pz8+3t7RMSElxdXae53LRuOXHixNDQEEEQr169Cg4OpjscZXl7e2dkZNAdhaYEBAQkJSXJLX0KgHpB2gYaYWxs7Ofn9/PPP/f29p4+fXqSnipXmMYwzMzMbPPmzWKxOD8///379+RQ04gaAABmOkjbQIPWrFmDEPrnn380faDg4GAej9fa2nr27FlNHwsAAGgEaRtoEFlxgVqMmvzalcVimZiYuLm5dXd3y1WYRtMo/EwuM1JWVkZuTlhoWWF55vERfmooAACgBaRtoEEVFRUIIXd3d4RQX1+fv79/cHDwx48fa2trFy1aNDw8LFdhGk2j8POKFSsQQi9fviQ3Jyy0PHl55gkj/NRQ0z01AACgEkjbQCP6+vqKiooOHDhgaWkZHR2NEGpoaOju7nZ1dcVx3MrKqqioaP78+eP/UOXCz2w2G8MwsuaEwkLLE5ZnnjBCTdRsBgAAlTHoDgDMNl1dXRiG6evrW1tb+/j4HD161MbGBiHk4OBgaWkZHh4eHR3N4/EWLlyo3uP29fURBEGubal8oWXZ8swTRjidms07d+7cuXOnGuY242EYRncIAHwuIG0DNTM1NSVrJMsxMjL6888/ExMTjx8/npqaumPHDrFYrMbKhi9evEAILV68GMkUWj506BDVQa4ispIRqjYUSSAQeHp6Tn0quiQrKwshFBMTQ3cguuoz+Y8dUCNI20B7XF1db9y40dbWJhQKMzIyXF1dVXgY/im3bt1CCG3duhXJFFoWCATTjJBc/1KFoRBCnp6es36taXI18lk/Tc2BtA2mCn7bBlry9u3bp0+fIoQsLCxOnjzp4eFBbqpFS0tLVlaWra0tWRlCtULLE0aoiZrNAACgMkjbQEvevn0bGRn57Nmz4eHhhw8fNjY2rl27dnw3ZQo/EwTR29tLVkVsa2vLy8tbt26dvr5+SUkJ+dv2JIWWpxqhakMBAICGQNoG6nHv3j0XF5f6+vqurq4vvvhi/FNTCwuLsbExLpfLYrG+/fbbyMjIffv2nTlzZvXq1QihhISEgICAyQ9x48YNd3f3d+/eDQ4Ompqa6uvr6+vrL1q0SCgU8ng8iUSycuVKqnN2dnZMTMypU6fmzZvH4XAEAkFHR0dubi75W+zy5ctfvnz5yy+/kKUVv/nmm9ra2gkj/NRQ6j17AACgJKi3DRSDetsq+EzqKMO1MU2fyXUC1AjutgEAAACdAWkbAECbO3fuJCUlyZZk3bVrl2wHb29vNputr6/v6upaXV1NV5wIIalUmpWVxeVyZRuvX79+6tQpcmk/ALQD0jYAgB5Hjx4ViUTJyclUSdZ58+ZdunTp5s2bVJ/bt28XFBT4+flJJBIPDw+6Qq2trd24cWNsbGx/f79su7+/P47jXl5eE65VAIAmQNoGQCcNDAzI3fnNhKGUl5GRcfXq1fz8fDabTTWKRCI9Pb2IiIgZVYD10aNHiYmJUVFR5Lr3cqKjo93d3X18fMjCOQBoGqRtAHTShQsXWltbZ9pQSqqrqzt8+PCxY8dwHJdt53K5AoHgzZs3Bw4c0GY8k3N3dy8qKgoLC6Nq2clJSUmpqanJzs7WcmDg8wRpGwDaEAQhFAqXLFliaGhobm6+bds2arVzPp9vYGBgbW1Nbu7du9fY2BjDsA8fPiCEBAJBXFxcfX09hmFOTk4ikQjHcUtLy8jISA6Hg+M4l8t98OCBCkOhadROVZ5IJCIIwt/ff/yu9PT0RYsWnT9//s6dOxP+7SQnTWFhVg3VYDU3N9+0aVN2djZ8mAO0gQBAkeDg4ODgYLqj0DEIoby8vMn7HDlyxMDA4Lfffuvs7Hz8+LGHh8f8+fNbWlrIvWFhYVZWVlTnzMxMhFBbWxu5GRQU5OjoSO2NiIgwNjZ++vTp4OCgRCJZvXo1m81uampSYajff/+dzWanpqYqM03Vrg0HB4elS5fKNTo6Or569YogiHv37unp6S1cuLC3t5cgiLKysoCAAKrb5Cft4MGDCKE//vijq6urtbV1w4YNxsbGw8PD5N4DBw4YGhoWFhZ2dHQkJyfr6en99ddfyof91Vdfubu7T7grKSkJIfTw4UPlRyMpc50AIAvutgGgx8DAgFAo3L59e3h4uKmpqZub29mzZz98+HDu3DnVBmQwGOQ96NKlS3Nzc3t6elQrMKpy7VQl9fX1vXr1ytHR8VMdPD09Y2JiGhoaEhMT5XYpedImLMyq0Rqszs7OCKEnT56oZTQAJgFpGwB6SCSS3t7eVatWUS2rV682MDCgHm5Px6pVq1gslpIFRrWstbWVIAgWizVJn/T0dBcXl5ycnMrKStn2qZ402cKs06nBqhA5nffv36tlNAAmAWkbAHqQnwzNmTNHttHMzKynp0ct4xsaGra1tallKPUaHBxECH3q9S4SjuNisRjDsN27dw8MDFDt0zlpVA1W7D+NjY1yH3SpjCxBS04NAI2CtA0APczMzBBCcvmms7PT1tZ2+oOPjIyoayi1IzOcwiVKPD09Y2Nja2tr09LSqMbpnDSqnKvsz4RVVVUqTGG84eFh9N/UANAoSNsA0GPZsmVz5sz5+++/qZYHDx4MDw9TBVEYDAb5dFcF5eXlBEFQNdamM5TaWVpaYhimzJfZaWlpixcvfvjwIdWi8KRNQqM1WMnpWFlZaWJwAGRB2gaAHjiOx8XFFRcXX7p0qbu7+8mTJ1FRURwOJyIiguzg5OT08ePHkpKSkZGRtra2xsZG2T+fO3fu27dvGxoaenp6yJQslUo7OjpGR0cfP34sEAjs7Ox4PJ4KQylTO3U6WCyWg4NDc3Ozwp7ko3J9fX3ZlslP2uQFmvL9AAACo0lEQVSjfaoGa2hoqJWV1XQWTyWn4+bmpvIIACiLnhfYgU6BD8BUgJT4sEcqlWZmZjo7OzOZTHNz88DAwOfPn1N729vbt2zZguO4vb39/v374+PjEUJOTk7kZ13V1dULFiwwMjJav359S0tLREQEk8m0sbFhMBgmJibbtm2rr69XbajS0lI2m52enq7MNFW7Nvh8PpPJ7O/vJzeLi4vJF8vnz5+/b98+uc7x8fGyH4BNctJycnLIV8OcnZ3r6+vPnTtH1l9fsGDBixcvCIIYGhpKSEiws7NjMBgWFhZBQUESiYQgiMDAQITQkSNHJoy2qqpq3bp1HA6H/DfT2tqay+XevXtXto+vr6+NjQ1ZA35KlLlOAJAFhTuBYlCcUQVaLsgYGRlZUFDQ3t6uncNRVLs26urqlixZIhaLw8PDNRPX1Eil0s2bN/N4vN27d6vw5+3t7ba2tunp6WT59imBwp1gquAhOQCzhA7VoXJyckpNTU1NTe3t7aU7FjQ2NlZSUtLT0xMaGqraCCkpKStWrODz+eoNDIAJQdoGANAgKSkpJCQkNDSU9qoh5eXlRUVFZWVlk39K/ilCobCmpqa0tJTJZKo9NgDGg7QNgM5LTk4Wi8VdXV329vaFhYV0h6Os48eP8/n8kydP0huGl5fX5cuXqTXbp+TatWtDQ0Pl5eXm5uZqDwyACTHoDgAAMF0nTpw4ceIE3VGowtvb29vbm+4oVBcQEBAQEEB3FODzAnfbAAAAgM6AtA0AAADoDEjbAAAAgM6AtA0AAADoDHglDSilubk5Pz+f7ih0jLrKVMxk5KKecG0AoDWwShpQLCQkRIc+KwJAt8AqaWBKIG0DAAAAOgN+2wYAAAB0BqRtAAAAQGdA2gYAAAB0BqRtAAAAQGf8H8Ij2r6InQ9YAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cD5UO3Rd7Jaf"
      },
      "source": [
        "# Compiling the Model\n",
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.Adam(learning_rate=0.001))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjplMXfRyYQt",
        "outputId": "92790799-e077-4040-a7db-1c58668a2cb8"
      },
      "source": [
        "I_all = tf.concat([I_ut, I_ebt], axis=0)\n",
        "print(I_ut_test)\n",
        "print(I_ebt_test)\n",
        "I = tf.reshape(I_ut_test, (3,))\n",
        "print(I)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[-0.8364769 ]\n",
            " [ 0.31686562]\n",
            " [-0.2996992 ]], shape=(3, 1), dtype=float32)\n",
            "tf.Tensor([10.55247  40.058735 24.476126], shape=(3,), dtype=float32)\n",
            "tf.Tensor([-0.8364769   0.31686562 -0.2996992 ], shape=(3,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-g3-t8dJ8CMq",
        "outputId": "0342592d-05ff-4b12-b8df-a6d38299ad1a"
      },
      "source": [
        "# Training the Model on the prepared data\n",
        "history1 = model.fit([I_ut_train, II_ut_train], psi_ut_train, epochs=1000, validation_data=([I_ut_test, II_ut_test], psi_ut_test))\n",
        "\n",
        "history2 = model.fit([I_ebt_train, II_ebt_train], psi_ebt_train, epochs=1000, validation_data=([I_ebt_test, II_ebt_test], psi_ebt_test))\n",
        "\n",
        "history3 = model.fit([I_ps_train, II_ps_train], psi_ps_train, epochs=1000, validation_data=([I_ps_test, II_ps_test], psi_ps_test))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0332 - val_loss: 0.0221\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0331 - val_loss: 0.0221\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0330 - val_loss: 0.0220\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0329 - val_loss: 0.0220\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0328 - val_loss: 0.0220\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0327 - val_loss: 0.0220\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0326 - val_loss: 0.0220\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0324 - val_loss: 0.0220\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0323 - val_loss: 0.0220\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0322 - val_loss: 0.0220\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0321 - val_loss: 0.0220\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0320 - val_loss: 0.0219\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0319 - val_loss: 0.0219\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0318 - val_loss: 0.0219\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0317 - val_loss: 0.0219\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0316 - val_loss: 0.0219\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0315 - val_loss: 0.0219\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0314 - val_loss: 0.0219\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0313 - val_loss: 0.0218\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0312 - val_loss: 0.0218\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0312 - val_loss: 0.0218\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0311 - val_loss: 0.0218\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0310 - val_loss: 0.0218\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0309 - val_loss: 0.0217\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0308 - val_loss: 0.0217\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0307 - val_loss: 0.0217\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0306 - val_loss: 0.0217\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0306 - val_loss: 0.0217\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0305 - val_loss: 0.0216\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0304 - val_loss: 0.0216\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0303 - val_loss: 0.0216\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0302 - val_loss: 0.0216\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0301 - val_loss: 0.0215\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0301 - val_loss: 0.0215\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0300 - val_loss: 0.0215\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0299 - val_loss: 0.0215\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0298 - val_loss: 0.0214\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0298 - val_loss: 0.0214\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0297 - val_loss: 0.0214\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0296 - val_loss: 0.0214\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0295 - val_loss: 0.0213\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0295 - val_loss: 0.0213\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0294 - val_loss: 0.0213\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0293 - val_loss: 0.0212\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0293 - val_loss: 0.0212\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0292 - val_loss: 0.0212\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0291 - val_loss: 0.0212\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0291 - val_loss: 0.0211\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0290 - val_loss: 0.0211\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0289 - val_loss: 0.0211\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0289 - val_loss: 0.0210\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0288 - val_loss: 0.0210\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0287 - val_loss: 0.0210\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0287 - val_loss: 0.0209\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0286 - val_loss: 0.0209\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0285 - val_loss: 0.0209\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0285 - val_loss: 0.0208\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0284 - val_loss: 0.0208\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0284 - val_loss: 0.0208\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0283 - val_loss: 0.0207\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0282 - val_loss: 0.0207\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0282 - val_loss: 0.0207\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0281 - val_loss: 0.0206\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0281 - val_loss: 0.0206\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0280 - val_loss: 0.0206\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0279 - val_loss: 0.0205\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0279 - val_loss: 0.0205\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0278 - val_loss: 0.0205\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0278 - val_loss: 0.0204\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0277 - val_loss: 0.0204\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0277 - val_loss: 0.0204\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0276 - val_loss: 0.0203\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0276 - val_loss: 0.0203\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0275 - val_loss: 0.0203\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0275 - val_loss: 0.0202\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0274 - val_loss: 0.0202\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0273 - val_loss: 0.0202\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0273 - val_loss: 0.0201\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0272 - val_loss: 0.0201\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0272 - val_loss: 0.0201\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0272 - val_loss: 0.0200\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0271 - val_loss: 0.0200\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0271 - val_loss: 0.0199\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0270 - val_loss: 0.0199\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0270 - val_loss: 0.0199\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0269 - val_loss: 0.0198\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0269 - val_loss: 0.0198\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0268 - val_loss: 0.0198\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0268 - val_loss: 0.0197\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0267 - val_loss: 0.0197\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0267 - val_loss: 0.0197\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0266 - val_loss: 0.0196\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0266 - val_loss: 0.0196\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0266 - val_loss: 0.0196\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0265 - val_loss: 0.0195\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0265 - val_loss: 0.0195\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0264 - val_loss: 0.0195\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0264 - val_loss: 0.0194\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0263 - val_loss: 0.0194\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0263 - val_loss: 0.0194\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0263 - val_loss: 0.0193\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0262 - val_loss: 0.0193\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0262 - val_loss: 0.0193\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0261 - val_loss: 0.0192\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0261 - val_loss: 0.0192\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0260 - val_loss: 0.0192\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0260 - val_loss: 0.0191\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0260 - val_loss: 0.0191\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0259 - val_loss: 0.0191\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0259 - val_loss: 0.0190\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0258 - val_loss: 0.0190\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0258 - val_loss: 0.0190\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0258 - val_loss: 0.0189\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0257 - val_loss: 0.0189\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0257 - val_loss: 0.0189\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0256 - val_loss: 0.0188\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0256 - val_loss: 0.0188\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0256 - val_loss: 0.0188\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0255 - val_loss: 0.0187\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0255 - val_loss: 0.0187\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0255 - val_loss: 0.0187\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0254 - val_loss: 0.0186\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0254 - val_loss: 0.0186\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0254 - val_loss: 0.0186\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0253 - val_loss: 0.0185\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0253 - val_loss: 0.0185\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0252 - val_loss: 0.0185\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0252 - val_loss: 0.0184\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0252 - val_loss: 0.0184\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0251 - val_loss: 0.0184\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0251 - val_loss: 0.0183\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0251 - val_loss: 0.0183\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0250 - val_loss: 0.0183\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0250 - val_loss: 0.0182\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0250 - val_loss: 0.0182\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0249 - val_loss: 0.0182\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0249 - val_loss: 0.0181\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0249 - val_loss: 0.0181\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0248 - val_loss: 0.0181\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0248 - val_loss: 0.0181\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0248 - val_loss: 0.0180\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0247 - val_loss: 0.0180\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0247 - val_loss: 0.0180\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0247 - val_loss: 0.0179\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0246 - val_loss: 0.0179\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0246 - val_loss: 0.0179\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0246 - val_loss: 0.0178\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0245 - val_loss: 0.0178\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0245 - val_loss: 0.0178\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0245 - val_loss: 0.0177\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0244 - val_loss: 0.0177\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0244 - val_loss: 0.0177\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0244 - val_loss: 0.0176\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0243 - val_loss: 0.0176\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0243 - val_loss: 0.0176\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0243 - val_loss: 0.0175\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0243 - val_loss: 0.0175\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0242 - val_loss: 0.0175\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0242 - val_loss: 0.0174\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0242 - val_loss: 0.0174\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0241 - val_loss: 0.0174\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0241 - val_loss: 0.0174\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0241 - val_loss: 0.0173\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0240 - val_loss: 0.0173\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0240 - val_loss: 0.0173\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0240 - val_loss: 0.0172\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0240 - val_loss: 0.0172\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0239 - val_loss: 0.0172\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0239 - val_loss: 0.0171\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0239 - val_loss: 0.0171\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0238 - val_loss: 0.0171\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0238 - val_loss: 0.0170\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0238 - val_loss: 0.0170\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0238 - val_loss: 0.0170\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0237 - val_loss: 0.0169\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0237 - val_loss: 0.0169\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0237 - val_loss: 0.0169\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0236 - val_loss: 0.0169\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0236 - val_loss: 0.0168\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0236 - val_loss: 0.0168\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0236 - val_loss: 0.0168\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0235 - val_loss: 0.0167\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0235 - val_loss: 0.0167\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0235 - val_loss: 0.0167\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0234 - val_loss: 0.0166\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0234 - val_loss: 0.0166\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0234 - val_loss: 0.0166\n",
            "Epoch 688/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0234 - val_loss: 0.0166\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0233 - val_loss: 0.0165\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0233 - val_loss: 0.0165\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0233 - val_loss: 0.0165\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0233 - val_loss: 0.0164\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0232 - val_loss: 0.0164\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0232 - val_loss: 0.0164\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0232 - val_loss: 0.0163\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0232 - val_loss: 0.0163\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0231 - val_loss: 0.0163\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0231 - val_loss: 0.0163\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0231 - val_loss: 0.0162\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0231 - val_loss: 0.0162\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0230 - val_loss: 0.0162\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0230 - val_loss: 0.0161\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0230 - val_loss: 0.0161\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0230 - val_loss: 0.0161\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0229 - val_loss: 0.0161\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0229 - val_loss: 0.0160\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0229 - val_loss: 0.0160\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0229 - val_loss: 0.0160\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0228 - val_loss: 0.0159\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0228 - val_loss: 0.0159\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0228 - val_loss: 0.0159\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0228 - val_loss: 0.0159\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0227 - val_loss: 0.0158\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0227 - val_loss: 0.0158\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0227 - val_loss: 0.0158\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0227 - val_loss: 0.0157\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0226 - val_loss: 0.0157\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0226 - val_loss: 0.0157\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0226 - val_loss: 0.0157\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0226 - val_loss: 0.0156\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0225 - val_loss: 0.0156\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0225 - val_loss: 0.0156\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0225 - val_loss: 0.0156\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0225 - val_loss: 0.0155\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0225 - val_loss: 0.0155\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0224 - val_loss: 0.0155\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0224 - val_loss: 0.0154\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0224 - val_loss: 0.0154\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0224 - val_loss: 0.0154\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0223 - val_loss: 0.0154\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0223 - val_loss: 0.0153\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0223 - val_loss: 0.0153\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0223 - val_loss: 0.0153\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0222 - val_loss: 0.0153\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0222 - val_loss: 0.0152\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0222 - val_loss: 0.0152\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0222 - val_loss: 0.0152\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0222 - val_loss: 0.0151\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0221 - val_loss: 0.0151\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0221 - val_loss: 0.0151\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0221 - val_loss: 0.0151\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0221 - val_loss: 0.0150\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0221 - val_loss: 0.0150\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0220 - val_loss: 0.0150\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0220 - val_loss: 0.0150\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0220 - val_loss: 0.0149\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0220 - val_loss: 0.0149\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0219 - val_loss: 0.0149\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0219 - val_loss: 0.0149\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0219 - val_loss: 0.0148\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0219 - val_loss: 0.0148\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0219 - val_loss: 0.0148\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0218 - val_loss: 0.0148\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0218 - val_loss: 0.0147\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0218 - val_loss: 0.0147\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0218 - val_loss: 0.0147\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0218 - val_loss: 0.0147\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0217 - val_loss: 0.0146\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0217 - val_loss: 0.0146\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0217 - val_loss: 0.0146\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0217 - val_loss: 0.0146\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0217 - val_loss: 0.0145\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0216 - val_loss: 0.0145\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0216 - val_loss: 0.0145\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0216 - val_loss: 0.0145\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0216 - val_loss: 0.0144\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0216 - val_loss: 0.0144\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0215 - val_loss: 0.0144\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0215 - val_loss: 0.0144\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0215 - val_loss: 0.0143\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0215 - val_loss: 0.0143\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0215 - val_loss: 0.0143\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0214 - val_loss: 0.0143\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0214 - val_loss: 0.0142\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0214 - val_loss: 0.0142\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0214 - val_loss: 0.0142\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0214 - val_loss: 0.0142\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0213 - val_loss: 0.0141\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0213 - val_loss: 0.0141\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0213 - val_loss: 0.0141\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0213 - val_loss: 0.0141\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0213 - val_loss: 0.0141\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0213 - val_loss: 0.0140\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0212 - val_loss: 0.0140\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0212 - val_loss: 0.0140\n",
            "Epoch 786/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0212 - val_loss: 0.0140\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0212 - val_loss: 0.0139\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0212 - val_loss: 0.0139\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0211 - val_loss: 0.0139\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0211 - val_loss: 0.0139\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0211 - val_loss: 0.0138\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0211 - val_loss: 0.0138\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0211 - val_loss: 0.0138\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0210 - val_loss: 0.0138\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0210 - val_loss: 0.0138\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0210 - val_loss: 0.0137\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0210 - val_loss: 0.0137\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0210 - val_loss: 0.0137\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0210 - val_loss: 0.0137\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0209 - val_loss: 0.0136\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0209 - val_loss: 0.0136\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0209 - val_loss: 0.0136\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0209 - val_loss: 0.0136\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0209 - val_loss: 0.0136\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0209 - val_loss: 0.0135\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0208 - val_loss: 0.0135\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0208 - val_loss: 0.0135\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0208 - val_loss: 0.0135\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0208 - val_loss: 0.0134\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0208 - val_loss: 0.0134\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0208 - val_loss: 0.0134\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0207 - val_loss: 0.0134\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0207 - val_loss: 0.0134\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0207 - val_loss: 0.0133\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0207 - val_loss: 0.0133\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0207 - val_loss: 0.0133\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0206 - val_loss: 0.0133\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0206 - val_loss: 0.0132\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0206 - val_loss: 0.0132\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0206 - val_loss: 0.0132\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0206 - val_loss: 0.0132\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0206 - val_loss: 0.0132\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0205 - val_loss: 0.0131\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0205 - val_loss: 0.0131\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0205 - val_loss: 0.0131\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0205 - val_loss: 0.0131\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0205 - val_loss: 0.0131\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0204 - val_loss: 0.0130\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0204 - val_loss: 0.0130\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0204 - val_loss: 0.0130\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0204 - val_loss: 0.0130\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0204 - val_loss: 0.0129\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0203 - val_loss: 0.0129\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0203 - val_loss: 0.0129\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0203 - val_loss: 0.0129\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0203 - val_loss: 0.0129\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0203 - val_loss: 0.0128\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0202 - val_loss: 0.0128\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0202 - val_loss: 0.0128\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0202 - val_loss: 0.0128\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0202 - val_loss: 0.0127\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0202 - val_loss: 0.0127\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0202 - val_loss: 0.0127\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0201 - val_loss: 0.0127\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0201 - val_loss: 0.0127\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0201 - val_loss: 0.0126\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0201 - val_loss: 0.0126\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0201 - val_loss: 0.0126\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0200 - val_loss: 0.0126\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0200 - val_loss: 0.0125\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0200 - val_loss: 0.0125\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0200 - val_loss: 0.0125\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0200 - val_loss: 0.0125\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0199 - val_loss: 0.0125\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0199 - val_loss: 0.0124\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0199 - val_loss: 0.0124\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0199 - val_loss: 0.0124\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0199 - val_loss: 0.0124\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0199 - val_loss: 0.0124\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0198 - val_loss: 0.0123\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0198 - val_loss: 0.0123\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0198 - val_loss: 0.0123\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0198 - val_loss: 0.0123\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0198 - val_loss: 0.0122\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0197 - val_loss: 0.0122\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0197 - val_loss: 0.0122\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0197 - val_loss: 0.0122\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0197 - val_loss: 0.0122\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0197 - val_loss: 0.0121\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0197 - val_loss: 0.0121\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0196 - val_loss: 0.0121\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0196 - val_loss: 0.0121\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0196 - val_loss: 0.0121\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0196 - val_loss: 0.0120\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0196 - val_loss: 0.0120\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0195 - val_loss: 0.0120\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0195 - val_loss: 0.0120\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0195 - val_loss: 0.0120\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0195 - val_loss: 0.0119\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0195 - val_loss: 0.0119\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0195 - val_loss: 0.0119\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0194 - val_loss: 0.0119\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0194 - val_loss: 0.0119\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0194 - val_loss: 0.0118\n",
            "Epoch 885/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0194 - val_loss: 0.0118\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0194 - val_loss: 0.0118\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0193 - val_loss: 0.0118\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0193 - val_loss: 0.0118\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0193 - val_loss: 0.0117\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0193 - val_loss: 0.0117\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0193 - val_loss: 0.0117\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0193 - val_loss: 0.0117\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0192 - val_loss: 0.0117\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0192 - val_loss: 0.0116\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0192 - val_loss: 0.0116\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0192 - val_loss: 0.0116\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0192 - val_loss: 0.0116\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0192 - val_loss: 0.0116\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0191 - val_loss: 0.0115\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0191 - val_loss: 0.0115\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0191 - val_loss: 0.0115\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0191 - val_loss: 0.0115\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0191 - val_loss: 0.0115\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0191 - val_loss: 0.0114\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0190 - val_loss: 0.0114\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0190 - val_loss: 0.0114\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0190 - val_loss: 0.0114\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0190 - val_loss: 0.0114\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0190 - val_loss: 0.0113\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0190 - val_loss: 0.0113\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0189 - val_loss: 0.0113\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0189 - val_loss: 0.0113\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0189 - val_loss: 0.0113\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0189 - val_loss: 0.0112\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0189 - val_loss: 0.0112\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0189 - val_loss: 0.0112\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0188 - val_loss: 0.0112\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0188 - val_loss: 0.0112\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0188 - val_loss: 0.0111\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0188 - val_loss: 0.0111\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0188 - val_loss: 0.0111\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0188 - val_loss: 0.0111\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0187 - val_loss: 0.0111\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0187 - val_loss: 0.0110\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0187 - val_loss: 0.0110\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0187 - val_loss: 0.0110\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0187 - val_loss: 0.0110\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0187 - val_loss: 0.0110\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0186 - val_loss: 0.0110\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0186 - val_loss: 0.0109\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0186 - val_loss: 0.0109\n",
            "Epoch 932/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0186 - val_loss: 0.0109\n",
            "Epoch 933/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0186 - val_loss: 0.0109\n",
            "Epoch 934/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0186 - val_loss: 0.0109\n",
            "Epoch 935/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0186 - val_loss: 0.0108\n",
            "Epoch 936/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0185 - val_loss: 0.0108\n",
            "Epoch 937/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0185 - val_loss: 0.0108\n",
            "Epoch 938/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0185 - val_loss: 0.0108\n",
            "Epoch 939/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0185 - val_loss: 0.0108\n",
            "Epoch 940/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0185 - val_loss: 0.0108\n",
            "Epoch 941/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0185 - val_loss: 0.0107\n",
            "Epoch 942/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0184 - val_loss: 0.0107\n",
            "Epoch 943/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0184 - val_loss: 0.0107\n",
            "Epoch 944/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0184 - val_loss: 0.0107\n",
            "Epoch 945/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0184 - val_loss: 0.0107\n",
            "Epoch 946/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0184 - val_loss: 0.0106\n",
            "Epoch 947/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0184 - val_loss: 0.0106\n",
            "Epoch 948/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0183 - val_loss: 0.0106\n",
            "Epoch 949/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0183 - val_loss: 0.0106\n",
            "Epoch 950/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0183 - val_loss: 0.0106\n",
            "Epoch 951/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0183 - val_loss: 0.0106\n",
            "Epoch 952/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0183 - val_loss: 0.0105\n",
            "Epoch 953/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0183 - val_loss: 0.0105\n",
            "Epoch 954/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0183 - val_loss: 0.0105\n",
            "Epoch 955/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0182 - val_loss: 0.0105\n",
            "Epoch 956/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0182 - val_loss: 0.0105\n",
            "Epoch 957/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0182 - val_loss: 0.0104\n",
            "Epoch 958/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0182 - val_loss: 0.0104\n",
            "Epoch 959/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0182 - val_loss: 0.0104\n",
            "Epoch 960/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0182 - val_loss: 0.0104\n",
            "Epoch 961/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0181 - val_loss: 0.0104\n",
            "Epoch 962/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0181 - val_loss: 0.0104\n",
            "Epoch 963/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0181 - val_loss: 0.0103\n",
            "Epoch 964/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0181 - val_loss: 0.0103\n",
            "Epoch 965/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0181 - val_loss: 0.0103\n",
            "Epoch 966/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0180 - val_loss: 0.0103\n",
            "Epoch 967/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0180 - val_loss: 0.0102\n",
            "Epoch 968/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0180 - val_loss: 0.0102\n",
            "Epoch 969/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0180 - val_loss: 0.0102\n",
            "Epoch 970/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0180 - val_loss: 0.0102\n",
            "Epoch 971/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0179 - val_loss: 0.0102\n",
            "Epoch 972/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0179 - val_loss: 0.0101\n",
            "Epoch 973/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0179 - val_loss: 0.0101\n",
            "Epoch 974/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0179 - val_loss: 0.0101\n",
            "Epoch 975/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0179 - val_loss: 0.0101\n",
            "Epoch 976/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0178 - val_loss: 0.0100\n",
            "Epoch 977/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0178 - val_loss: 0.0100\n",
            "Epoch 978/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0178 - val_loss: 0.0100\n",
            "Epoch 979/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0178 - val_loss: 0.0100\n",
            "Epoch 980/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0177 - val_loss: 0.0099\n",
            "Epoch 981/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0177 - val_loss: 0.0099\n",
            "Epoch 982/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0177 - val_loss: 0.0099\n",
            "Epoch 983/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0177 - val_loss: 0.0099\n",
            "Epoch 984/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0177 - val_loss: 0.0099\n",
            "Epoch 985/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0176 - val_loss: 0.0098\n",
            "Epoch 986/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0176 - val_loss: 0.0098\n",
            "Epoch 987/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0176 - val_loss: 0.0098\n",
            "Epoch 988/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0176 - val_loss: 0.0098\n",
            "Epoch 989/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0175 - val_loss: 0.0097\n",
            "Epoch 990/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0175 - val_loss: 0.0097\n",
            "Epoch 991/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0175 - val_loss: 0.0097\n",
            "Epoch 992/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0175 - val_loss: 0.0097\n",
            "Epoch 993/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0174 - val_loss: 0.0096\n",
            "Epoch 994/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0174 - val_loss: 0.0096\n",
            "Epoch 995/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0174 - val_loss: 0.0096\n",
            "Epoch 996/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0174 - val_loss: 0.0096\n",
            "Epoch 997/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0173 - val_loss: 0.0095\n",
            "Epoch 998/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0173 - val_loss: 0.0095\n",
            "Epoch 999/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0173 - val_loss: 0.0095\n",
            "Epoch 1000/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0173 - val_loss: 0.0095\n",
            "Epoch 1/1000\n",
            "1/1 [==============================] - 0s 394ms/step - loss: 85029.7344 - val_loss: 8159.3286\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 81803.3047 - val_loss: 7751.0000\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 77566.9531 - val_loss: 7289.4980\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 72778.6797 - val_loss: 6799.5273\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 67699.9688 - val_loss: 6297.6187\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 62505.0938 - val_loss: 5795.5859\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 57317.6680 - val_loss: 5302.0347\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 52227.5000 - val_loss: 4823.2720\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 47300.2500 - val_loss: 4363.8716\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 42583.4258 - val_loss: 3927.0867\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 38110.5820 - val_loss: 3515.1287\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 33904.3164 - val_loss: 3129.3923\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 29978.5723 - val_loss: 2770.6101\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 26340.4277 - val_loss: 2439.0022\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 22991.4863 - val_loss: 2134.3733\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 19928.9727 - val_loss: 1856.1991\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 17146.6797 - val_loss: 1603.6984\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 14635.6768 - val_loss: 1375.8920\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 12384.9951 - val_loss: 1171.6462\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 10382.0088 - val_loss: 989.7153\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 8612.9453 - val_loss: 828.7696\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 7063.1777 - val_loss: 687.4318\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5717.5195 - val_loss: 564.3049\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4560.4507 - val_loss: 457.9225\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3576.3435 - val_loss: 366.8560\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2749.6150 - val_loss: 289.6937\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2064.8889 - val_loss: 225.0519\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1507.1273 - val_loss: 171.5864\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1061.7567 - val_loss: 128.0031\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 714.7686 - val_loss: 93.0668\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 452.8311 - val_loss: 65.6091\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 263.3637 - val_loss: 44.5357\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 134.6286 - val_loss: 28.8331\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 55.7848 - val_loss: 17.5725\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 16.9460 - val_loss: 9.9135\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 9.2142 - val_loss: 5.1063\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 24.6986 - val_loss: 2.4916\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 56.5182 - val_loss: 1.4995\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 98.7850 - val_loss: 1.6467\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 146.5706 - val_loss: 2.5320\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 195.8580 - val_loss: 3.8314\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 243.4780 - val_loss: 5.2908\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 287.0353 - val_loss: 6.7192\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 324.8265 - val_loss: 7.9811\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 355.7548 - val_loss: 8.9881\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 379.2360 - val_loss: 9.6917\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 395.1185 - val_loss: 10.0752\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 403.5920 - val_loss: 10.1470\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 405.1121 - val_loss: 9.9341\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 400.3262 - val_loss: 9.4765\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 390.0137 - val_loss: 8.8221\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 375.0264 - val_loss: 8.0227\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 356.2458 - val_loss: 7.1306\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 334.5416 - val_loss: 6.1961\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 310.7483 - val_loss: 5.2652\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 285.6362 - val_loss: 4.3786\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 259.9010 - val_loss: 3.5704\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 234.1507 - val_loss: 2.8685\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 208.9039 - val_loss: 2.2933\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 184.5881 - val_loss: 1.8592\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 161.5415 - val_loss: 1.5741\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 140.0186 - val_loss: 1.4404\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 120.1980 - val_loss: 1.4558\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 102.1887 - val_loss: 1.6136\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 86.0394 - val_loss: 1.9039\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 71.7484 - val_loss: 2.3143\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 59.2710 - val_loss: 2.8302\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 48.5283 - val_loss: 3.4360\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 39.4155 - val_loss: 4.1153\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 31.8098 - val_loss: 4.8516\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 25.5752 - val_loss: 5.6288\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 20.5686 - val_loss: 6.4314\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 16.6461 - val_loss: 7.2448\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 13.6647 - val_loss: 8.0557\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 11.4870 - val_loss: 8.8522\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 9.9831 - val_loss: 9.6238\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 9.0326 - val_loss: 10.3612\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 8.5259 - val_loss: 11.0572\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 8.3646 - val_loss: 11.7055\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 8.4621 - val_loss: 12.3017\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 8.7436 - val_loss: 12.8423\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 9.1452 - val_loss: 13.3255\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 9.6142 - val_loss: 13.7500\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 10.1076 - val_loss: 14.1161\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 10.5914 - val_loss: 14.4247\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 11.0401 - val_loss: 14.6773\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 11.4352 - val_loss: 14.8763\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 11.7642 - val_loss: 15.0244\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 12.0205 - val_loss: 15.1248\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 12.2012 - val_loss: 15.1811\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 12.3072 - val_loss: 15.1966\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 12.3422 - val_loss: 15.1753\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 12.3118 - val_loss: 15.1210\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 12.2231 - val_loss: 15.0374\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 12.0841 - val_loss: 14.9282\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 11.9034 - val_loss: 14.7971\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 11.6894 - val_loss: 14.6474\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 11.4504 - val_loss: 14.4825\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 11.1943 - val_loss: 14.3052\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 10.9281 - val_loss: 14.1185\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 10.6585 - val_loss: 13.9250\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 10.3910 - val_loss: 13.7269\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 10.1304 - val_loss: 13.5265\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 9.8804 - val_loss: 13.3257\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 9.6444 - val_loss: 13.1260\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 9.4245 - val_loss: 12.9291\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 9.2222 - val_loss: 12.7361\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 9.0385 - val_loss: 12.5482\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 8.8738 - val_loss: 12.3663\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 8.7279 - val_loss: 12.1911\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 8.6002 - val_loss: 12.0233\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 8.4900 - val_loss: 11.8634\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 8.3962 - val_loss: 11.7116\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 8.3173 - val_loss: 11.5683\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 8.2520 - val_loss: 11.4335\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 8.1989 - val_loss: 11.3074\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 8.1565 - val_loss: 11.1900\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 8.1232 - val_loss: 11.0811\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 8.0978 - val_loss: 10.9806\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 8.0788 - val_loss: 10.8884\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 8.0655 - val_loss: 10.8042\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 8.0572 - val_loss: 10.7278\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 8.0521 - val_loss: 10.6589\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 8.0493 - val_loss: 10.5971\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 8.0479 - val_loss: 10.5422\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 8.0475 - val_loss: 10.4937\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 8.0475 - val_loss: 10.4514\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 8.0475 - val_loss: 10.4148\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 8.0472 - val_loss: 10.3838\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 8.0463 - val_loss: 10.3576\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 8.0447 - val_loss: 10.3361\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 8.0422 - val_loss: 10.3190\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 8.0390 - val_loss: 10.3059\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 8.0348 - val_loss: 10.2963\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 8.0299 - val_loss: 10.2900\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 8.0242 - val_loss: 10.2866\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 8.0179 - val_loss: 10.2859\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 8.0109 - val_loss: 10.2874\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 8.0035 - val_loss: 10.2910\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7.9957 - val_loss: 10.2963\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7.9877 - val_loss: 10.3031\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7.9794 - val_loss: 10.3111\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7.9710 - val_loss: 10.3201\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 7.9625 - val_loss: 10.3298\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7.9541 - val_loss: 10.3401\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.9458 - val_loss: 10.3507\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7.9376 - val_loss: 10.3616\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 7.9295 - val_loss: 10.3725\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 7.9216 - val_loss: 10.3833\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.9140 - val_loss: 10.3938\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7.9065 - val_loss: 10.4040\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7.8993 - val_loss: 10.4138\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 7.8923 - val_loss: 10.4230\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7.8855 - val_loss: 10.4316\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 7.8789 - val_loss: 10.4395\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7.8725 - val_loss: 10.4466\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 7.8662 - val_loss: 10.4530\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7.8601 - val_loss: 10.4587\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7.8542 - val_loss: 10.4634\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 7.8483 - val_loss: 10.4674\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 7.8425 - val_loss: 10.4705\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 7.8369 - val_loss: 10.4727\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7.8312 - val_loss: 10.4742\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7.8257 - val_loss: 10.4748\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 7.8202 - val_loss: 10.4746\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7.8147 - val_loss: 10.4736\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 7.8092 - val_loss: 10.4719\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7.8038 - val_loss: 10.4694\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7.7983 - val_loss: 10.4664\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7.7929 - val_loss: 10.4626\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7.7874 - val_loss: 10.4582\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 7.7820 - val_loss: 10.4532\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.7766 - val_loss: 10.4477\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7.7711 - val_loss: 10.4417\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.7656 - val_loss: 10.4352\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 7.7601 - val_loss: 10.4283\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.7546 - val_loss: 10.4211\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 7.7491 - val_loss: 10.4135\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 7.7436 - val_loss: 10.4056\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7.7381 - val_loss: 10.3975\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7.7325 - val_loss: 10.3891\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7.7270 - val_loss: 10.3805\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 7.7214 - val_loss: 10.3718\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7.7159 - val_loss: 10.3629\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.7104 - val_loss: 10.3539\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7.7048 - val_loss: 10.3448\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7.6993 - val_loss: 10.3357\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 7.6937 - val_loss: 10.3265\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7.6882 - val_loss: 10.3173\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7.6826 - val_loss: 10.3081\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7.6771 - val_loss: 10.2990\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7.6715 - val_loss: 10.2898\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 7.6660 - val_loss: 10.2807\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 7.6605 - val_loss: 10.2716\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 7.6550 - val_loss: 10.2627\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 7.6494 - val_loss: 10.2538\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 7.6439 - val_loss: 10.2449\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7.6384 - val_loss: 10.2362\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7.6329 - val_loss: 10.2275\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7.6274 - val_loss: 10.2189\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7.6219 - val_loss: 10.2105\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7.6163 - val_loss: 10.2022\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 7.6109 - val_loss: 10.1938\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 7.6054 - val_loss: 10.1857\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.5998 - val_loss: 10.1776\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7.5943 - val_loss: 10.1696\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7.5888 - val_loss: 10.1617\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7.5833 - val_loss: 10.1539\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7.5778 - val_loss: 10.1462\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7.5723 - val_loss: 10.1385\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7.5668 - val_loss: 10.1310\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7.5613 - val_loss: 10.1235\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7.5558 - val_loss: 10.1160\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7.5503 - val_loss: 10.1087\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7.5448 - val_loss: 10.1013\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7.5393 - val_loss: 10.0941\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 7.5338 - val_loss: 10.0869\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 7.5283 - val_loss: 10.0797\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7.5228 - val_loss: 10.0726\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7.5173 - val_loss: 10.0656\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 7.5118 - val_loss: 10.0586\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7.5063 - val_loss: 10.0515\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7.5008 - val_loss: 10.0445\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 7.4953 - val_loss: 10.0375\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7.4898 - val_loss: 10.0306\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.4843 - val_loss: 10.0237\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 7.4788 - val_loss: 10.0168\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7.4733 - val_loss: 10.0098\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.4678 - val_loss: 10.0029\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 7.4623 - val_loss: 9.9960\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 7.4568 - val_loss: 9.9891\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7.4513 - val_loss: 9.9821\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7.4458 - val_loss: 9.9752\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 7.4403 - val_loss: 9.9683\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7.4348 - val_loss: 9.9613\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 7.4293 - val_loss: 9.9544\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 7.4238 - val_loss: 9.9475\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7.4183 - val_loss: 9.9405\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7.4128 - val_loss: 9.9335\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 7.4073 - val_loss: 9.9266\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7.4018 - val_loss: 9.9196\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7.3963 - val_loss: 9.9126\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 7.3908 - val_loss: 9.9056\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.3853 - val_loss: 9.8986\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7.3798 - val_loss: 9.8915\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 7.3743 - val_loss: 9.8845\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 7.3688 - val_loss: 9.8774\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.3633 - val_loss: 9.8704\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7.3579 - val_loss: 9.8633\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7.3524 - val_loss: 9.8562\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7.3469 - val_loss: 9.8492\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7.3414 - val_loss: 9.8420\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7.3359 - val_loss: 9.8350\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.3304 - val_loss: 9.8278\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7.3249 - val_loss: 9.8207\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 7.3194 - val_loss: 9.8135\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 7.3139 - val_loss: 9.8064\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7.3084 - val_loss: 9.7992\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 7.3030 - val_loss: 9.7920\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 7.2975 - val_loss: 9.7849\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 7.2920 - val_loss: 9.7777\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7.2865 - val_loss: 9.7705\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7.2810 - val_loss: 9.7634\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7.2755 - val_loss: 9.7562\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7.2700 - val_loss: 9.7490\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.2645 - val_loss: 9.7419\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.2590 - val_loss: 9.7347\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7.2535 - val_loss: 9.7275\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7.2480 - val_loss: 9.7204\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7.2426 - val_loss: 9.7132\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.2371 - val_loss: 9.7060\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 7.2316 - val_loss: 9.6989\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7.2261 - val_loss: 9.6917\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7.2207 - val_loss: 9.6845\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7.2152 - val_loss: 9.6774\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7.2097 - val_loss: 9.6702\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7.2042 - val_loss: 9.6630\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7.1987 - val_loss: 9.6559\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7.1932 - val_loss: 9.6488\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 7.1878 - val_loss: 9.6416\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 7.1823 - val_loss: 9.6345\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7.1768 - val_loss: 9.6273\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7.1713 - val_loss: 9.6202\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7.1659 - val_loss: 9.6130\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 7.1604 - val_loss: 9.6059\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7.1549 - val_loss: 9.5987\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 7.1494 - val_loss: 9.5916\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7.1439 - val_loss: 9.5844\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7.1385 - val_loss: 9.5773\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7.1330 - val_loss: 9.5702\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.1275 - val_loss: 9.5631\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 7.1221 - val_loss: 9.5560\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 7.1166 - val_loss: 9.5488\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7.1111 - val_loss: 9.5417\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7.1056 - val_loss: 9.5346\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7.1002 - val_loss: 9.5274\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7.0947 - val_loss: 9.5203\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7.0892 - val_loss: 9.5132\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 7.0837 - val_loss: 9.5060\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 7.0783 - val_loss: 9.4989\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7.0728 - val_loss: 9.4918\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7.0673 - val_loss: 9.4847\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7.0619 - val_loss: 9.4775\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7.0564 - val_loss: 9.4704\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7.0509 - val_loss: 9.4633\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 7.0455 - val_loss: 9.4561\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7.0400 - val_loss: 9.4490\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7.0346 - val_loss: 9.4419\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 7.0291 - val_loss: 9.4348\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7.0236 - val_loss: 9.4277\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7.0182 - val_loss: 9.4206\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7.0127 - val_loss: 9.4135\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 7.0073 - val_loss: 9.4064\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 7.0018 - val_loss: 9.3993\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 6.9963 - val_loss: 9.3922\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 6.9909 - val_loss: 9.3852\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6.9854 - val_loss: 9.3780\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6.9799 - val_loss: 9.3710\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 6.9745 - val_loss: 9.3639\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 6.9691 - val_loss: 9.3568\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 6.9636 - val_loss: 9.3497\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6.9581 - val_loss: 9.3426\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6.9527 - val_loss: 9.3355\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6.9472 - val_loss: 9.3283\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.9418 - val_loss: 9.3213\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 6.9363 - val_loss: 9.3141\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.9309 - val_loss: 9.3071\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6.9254 - val_loss: 9.3000\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6.9200 - val_loss: 9.2929\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 6.9145 - val_loss: 9.2858\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6.9091 - val_loss: 9.2787\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 6.9036 - val_loss: 9.2716\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6.8982 - val_loss: 9.2645\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6.8927 - val_loss: 9.2574\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6.8873 - val_loss: 9.2503\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 6.8818 - val_loss: 9.2432\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.8764 - val_loss: 9.2361\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6.8710 - val_loss: 9.2290\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6.8655 - val_loss: 9.2219\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6.8601 - val_loss: 9.2148\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6.8547 - val_loss: 9.2077\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 6.8492 - val_loss: 9.2006\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.8438 - val_loss: 9.1935\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.8383 - val_loss: 9.1864\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.8329 - val_loss: 9.1794\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.8275 - val_loss: 9.1723\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6.8220 - val_loss: 9.1652\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6.8166 - val_loss: 9.1581\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 6.8112 - val_loss: 9.1511\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6.8057 - val_loss: 9.1440\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6.8003 - val_loss: 9.1369\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.7949 - val_loss: 9.1298\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6.7894 - val_loss: 9.1227\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6.7840 - val_loss: 9.1157\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6.7786 - val_loss: 9.1086\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6.7731 - val_loss: 9.1016\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6.7677 - val_loss: 9.0945\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6.7623 - val_loss: 9.0875\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6.7569 - val_loss: 9.0804\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 6.7514 - val_loss: 9.0733\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6.7460 - val_loss: 9.0663\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6.7406 - val_loss: 9.0593\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 6.7352 - val_loss: 9.0522\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.7297 - val_loss: 9.0451\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 6.7243 - val_loss: 9.0381\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6.7189 - val_loss: 9.0310\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6.7135 - val_loss: 9.0240\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 6.7081 - val_loss: 9.0169\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.7027 - val_loss: 9.0098\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6.6973 - val_loss: 9.0028\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6.6918 - val_loss: 8.9957\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6.6864 - val_loss: 8.9887\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6.6810 - val_loss: 8.9816\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 6.6756 - val_loss: 8.9745\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 6.6702 - val_loss: 8.9675\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 6.6648 - val_loss: 8.9604\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.6594 - val_loss: 8.9534\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 6.6539 - val_loss: 8.9463\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 6.6485 - val_loss: 8.9392\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 6.6431 - val_loss: 8.9321\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6.6377 - val_loss: 8.9251\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 6.6323 - val_loss: 8.9180\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6.6269 - val_loss: 8.9110\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6.6215 - val_loss: 8.9039\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 6.6161 - val_loss: 8.8969\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 6.6107 - val_loss: 8.8898\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 6.6053 - val_loss: 8.8828\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6.5999 - val_loss: 8.8757\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.5945 - val_loss: 8.8686\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 6.5891 - val_loss: 8.8616\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6.5837 - val_loss: 8.8546\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6.5783 - val_loss: 8.8475\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6.5729 - val_loss: 8.8405\n",
            "Epoch 394/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6.5675 - val_loss: 8.8335\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6.5622 - val_loss: 8.8264\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6.5568 - val_loss: 8.8194\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.5514 - val_loss: 8.8123\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 6.5460 - val_loss: 8.8052\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6.5406 - val_loss: 8.7982\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6.5352 - val_loss: 8.7912\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6.5298 - val_loss: 8.7842\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6.5244 - val_loss: 8.7772\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 6.5191 - val_loss: 8.7702\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 6.5137 - val_loss: 8.7631\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 6.5083 - val_loss: 8.7561\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6.5029 - val_loss: 8.7491\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6.4975 - val_loss: 8.7421\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6.4922 - val_loss: 8.7351\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 6.4868 - val_loss: 8.7281\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6.4814 - val_loss: 8.7211\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6.4760 - val_loss: 8.7141\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 6.4706 - val_loss: 8.7071\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 6.4653 - val_loss: 8.7001\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6.4599 - val_loss: 8.6931\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6.4545 - val_loss: 8.6861\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6.4492 - val_loss: 8.6791\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 6.4438 - val_loss: 8.6721\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6.4384 - val_loss: 8.6651\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6.4331 - val_loss: 8.6581\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6.4277 - val_loss: 8.6511\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6.4223 - val_loss: 8.6442\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 6.4169 - val_loss: 8.6372\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6.4116 - val_loss: 8.6302\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 6.4062 - val_loss: 8.6232\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6.4009 - val_loss: 8.6162\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.3955 - val_loss: 8.6092\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 6.3901 - val_loss: 8.6022\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 6.3848 - val_loss: 8.5953\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6.3794 - val_loss: 8.5883\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6.3741 - val_loss: 8.5812\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 6.3687 - val_loss: 8.5743\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6.3634 - val_loss: 8.5673\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 6.3580 - val_loss: 8.5603\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 6.3527 - val_loss: 8.5533\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6.3473 - val_loss: 8.5463\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.3420 - val_loss: 8.5393\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 6.3366 - val_loss: 8.5324\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.3313 - val_loss: 8.5254\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 6.3259 - val_loss: 8.5184\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.3206 - val_loss: 8.5114\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6.3153 - val_loss: 8.5045\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6.3099 - val_loss: 8.4975\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 6.3046 - val_loss: 8.4905\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6.2993 - val_loss: 8.4836\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6.2939 - val_loss: 8.4766\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 6.2886 - val_loss: 8.4696\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.2832 - val_loss: 8.4626\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 6.2779 - val_loss: 8.4557\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 6.2726 - val_loss: 8.4487\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 6.2672 - val_loss: 8.4418\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 6.2619 - val_loss: 8.4348\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6.2566 - val_loss: 8.4279\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.2513 - val_loss: 8.4210\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 6.2459 - val_loss: 8.4140\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.2406 - val_loss: 8.4071\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 6.2353 - val_loss: 8.4001\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 6.2300 - val_loss: 8.3932\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.2246 - val_loss: 8.3863\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 6.2193 - val_loss: 8.3794\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.2140 - val_loss: 8.3724\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6.2087 - val_loss: 8.3655\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.2034 - val_loss: 8.3586\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 6.1981 - val_loss: 8.3516\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.1927 - val_loss: 8.3447\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.1874 - val_loss: 8.3378\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.1821 - val_loss: 8.3308\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.1768 - val_loss: 8.3239\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.1715 - val_loss: 8.3170\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.1662 - val_loss: 8.3101\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.1609 - val_loss: 8.3032\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 6.1556 - val_loss: 8.2963\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6.1503 - val_loss: 8.2894\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 6.1450 - val_loss: 8.2824\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6.1397 - val_loss: 8.2755\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6.1344 - val_loss: 8.2686\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 6.1291 - val_loss: 8.2617\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 6.1238 - val_loss: 8.2548\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6.1185 - val_loss: 8.2478\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 6.1132 - val_loss: 8.2409\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 6.1079 - val_loss: 8.2340\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 6.1026 - val_loss: 8.2271\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 6.0973 - val_loss: 8.2201\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.0920 - val_loss: 8.2132\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6.0867 - val_loss: 8.2063\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 6.0814 - val_loss: 8.1994\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.0761 - val_loss: 8.1925\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 6.0709 - val_loss: 8.1856\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6.0656 - val_loss: 8.1787\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6.0603 - val_loss: 8.1717\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.0550 - val_loss: 8.1648\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 6.0497 - val_loss: 8.1579\n",
            "Epoch 492/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 6.0445 - val_loss: 8.1510\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6.0392 - val_loss: 8.1442\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6.0339 - val_loss: 8.1372\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6.0286 - val_loss: 8.1303\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.0234 - val_loss: 8.1234\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.0181 - val_loss: 8.1166\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6.0128 - val_loss: 8.1097\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 6.0076 - val_loss: 8.1028\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 6.0023 - val_loss: 8.0959\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 5.9970 - val_loss: 8.0890\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5.9918 - val_loss: 8.0822\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 5.9865 - val_loss: 8.0753\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5.9812 - val_loss: 8.0684\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.9760 - val_loss: 8.0616\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 5.9707 - val_loss: 8.0547\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.9655 - val_loss: 8.0478\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 5.9602 - val_loss: 8.0410\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.9550 - val_loss: 8.0341\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.9497 - val_loss: 8.0272\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 5.9445 - val_loss: 8.0204\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5.9392 - val_loss: 8.0135\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5.9340 - val_loss: 8.0067\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.9287 - val_loss: 7.9998\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.9235 - val_loss: 7.9930\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 5.9182 - val_loss: 7.9862\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.9130 - val_loss: 7.9793\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 5.9077 - val_loss: 7.9725\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 5.9025 - val_loss: 7.9656\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 5.8973 - val_loss: 7.9588\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 5.8920 - val_loss: 7.9519\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 5.8868 - val_loss: 7.9451\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 5.8816 - val_loss: 7.9383\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.8763 - val_loss: 7.9314\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.8711 - val_loss: 7.9246\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 5.8659 - val_loss: 7.9178\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 5.8606 - val_loss: 7.9109\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.8554 - val_loss: 7.9041\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.8502 - val_loss: 7.8973\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 5.8450 - val_loss: 7.8904\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 5.8397 - val_loss: 7.8836\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5.8345 - val_loss: 7.8768\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 5.8293 - val_loss: 7.8699\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.8241 - val_loss: 7.8631\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5.8189 - val_loss: 7.8563\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 5.8137 - val_loss: 7.8495\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.8084 - val_loss: 7.8427\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.8033 - val_loss: 7.8359\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 5.7980 - val_loss: 7.8290\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.7928 - val_loss: 7.8222\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 5.7876 - val_loss: 7.8154\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.7824 - val_loss: 7.8086\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 5.7772 - val_loss: 7.8018\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 5.7720 - val_loss: 7.7950\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 5.7668 - val_loss: 7.7882\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.7616 - val_loss: 7.7814\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 5.7564 - val_loss: 7.7746\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5.7512 - val_loss: 7.7678\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 5.7460 - val_loss: 7.7610\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.7408 - val_loss: 7.7542\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5.7357 - val_loss: 7.7474\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 5.7305 - val_loss: 7.7406\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 5.7253 - val_loss: 7.7338\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5.7201 - val_loss: 7.7270\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.7149 - val_loss: 7.7202\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 5.7097 - val_loss: 7.7135\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 5.7045 - val_loss: 7.7066\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 5.6994 - val_loss: 7.6999\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5.6942 - val_loss: 7.6931\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 5.6890 - val_loss: 7.6863\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.6838 - val_loss: 7.6796\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 5.6786 - val_loss: 7.6728\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 5.6735 - val_loss: 7.6661\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5.6683 - val_loss: 7.6594\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 5.6632 - val_loss: 7.6526\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.6580 - val_loss: 7.6458\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.6528 - val_loss: 7.6391\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.6477 - val_loss: 7.6324\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 5.6425 - val_loss: 7.6256\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5.6373 - val_loss: 7.6189\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.6322 - val_loss: 7.6122\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.6270 - val_loss: 7.6054\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5.6218 - val_loss: 7.5987\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 5.6167 - val_loss: 7.5920\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.6116 - val_loss: 7.5853\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 5.6064 - val_loss: 7.5786\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 5.6013 - val_loss: 7.5718\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.5961 - val_loss: 7.5651\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 5.5910 - val_loss: 7.5584\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 5.5858 - val_loss: 7.5517\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.5807 - val_loss: 7.5450\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.5756 - val_loss: 7.5382\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.5704 - val_loss: 7.5315\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5.5653 - val_loss: 7.5248\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.5601 - val_loss: 7.5181\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 5.5550 - val_loss: 7.5114\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.5499 - val_loss: 7.5047\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5.5447 - val_loss: 7.4980\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.5396 - val_loss: 7.4913\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5.5345 - val_loss: 7.4846\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.5293 - val_loss: 7.4779\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5.5243 - val_loss: 7.4712\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5.5191 - val_loss: 7.4645\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5.5140 - val_loss: 7.4578\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.5089 - val_loss: 7.4511\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 5.5038 - val_loss: 7.4444\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.4986 - val_loss: 7.4377\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.4935 - val_loss: 7.4310\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 5.4884 - val_loss: 7.4243\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 5.4833 - val_loss: 7.4176\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 5.4782 - val_loss: 7.4109\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.4731 - val_loss: 7.4042\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 5.4680 - val_loss: 7.3975\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5.4629 - val_loss: 7.3908\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.4578 - val_loss: 7.3841\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 5.4527 - val_loss: 7.3774\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5.4476 - val_loss: 7.3708\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 5.4425 - val_loss: 7.3641\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 5.4374 - val_loss: 7.3574\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 5.4323 - val_loss: 7.3507\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 5.4272 - val_loss: 7.3441\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 5.4221 - val_loss: 7.3374\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.4170 - val_loss: 7.3307\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 5.4120 - val_loss: 7.3240\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.4069 - val_loss: 7.3174\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.4018 - val_loss: 7.3107\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.3967 - val_loss: 7.3041\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 5.3916 - val_loss: 7.2974\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 5.3866 - val_loss: 7.2907\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 5.3815 - val_loss: 7.2841\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5.3764 - val_loss: 7.2775\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.3713 - val_loss: 7.2708\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 5.3663 - val_loss: 7.2642\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.3612 - val_loss: 7.2576\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 5.3562 - val_loss: 7.2509\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5.3511 - val_loss: 7.2443\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 5.3460 - val_loss: 7.2377\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 5.3410 - val_loss: 7.2311\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 5.3359 - val_loss: 7.2244\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.3308 - val_loss: 7.2178\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 5.3258 - val_loss: 7.2112\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5.3207 - val_loss: 7.2046\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5.3157 - val_loss: 7.1980\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 5.3106 - val_loss: 7.1914\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5.3056 - val_loss: 7.1848\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 5.3006 - val_loss: 7.1782\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 5.2955 - val_loss: 7.1716\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.2905 - val_loss: 7.1651\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.2854 - val_loss: 7.1585\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.2804 - val_loss: 7.1519\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 5.2754 - val_loss: 7.1453\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 5.2703 - val_loss: 7.1387\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.2653 - val_loss: 7.1321\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 5.2603 - val_loss: 7.1256\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 5.2552 - val_loss: 7.1190\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 5.2502 - val_loss: 7.1124\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.2452 - val_loss: 7.1058\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.2401 - val_loss: 7.0992\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.2351 - val_loss: 7.0927\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 5.2301 - val_loss: 7.0861\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.2251 - val_loss: 7.0795\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5.2201 - val_loss: 7.0729\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5.2151 - val_loss: 7.0664\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.2101 - val_loss: 7.0598\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.2050 - val_loss: 7.0532\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5.2000 - val_loss: 7.0466\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 5.1950 - val_loss: 7.0401\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.1900 - val_loss: 7.0335\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5.1850 - val_loss: 7.0269\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 5.1800 - val_loss: 7.0204\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 5.1750 - val_loss: 7.0138\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 5.1701 - val_loss: 7.0073\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 5.1650 - val_loss: 7.0007\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5.1601 - val_loss: 6.9941\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5.1551 - val_loss: 6.9876\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5.1501 - val_loss: 6.9811\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 5.1451 - val_loss: 6.9745\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.1401 - val_loss: 6.9680\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 5.1351 - val_loss: 6.9615\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.1301 - val_loss: 6.9549\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.1252 - val_loss: 6.9484\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5.1202 - val_loss: 6.9419\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 5.1152 - val_loss: 6.9354\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 5.1102 - val_loss: 6.9289\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 5.1053 - val_loss: 6.9223\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5.1003 - val_loss: 6.9158\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.0953 - val_loss: 6.9093\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.0904 - val_loss: 6.9028\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.0854 - val_loss: 6.8963\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 5.0805 - val_loss: 6.8898\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.0755 - val_loss: 6.8833\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.0705 - val_loss: 6.8768\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.0656 - val_loss: 6.8703\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.0606 - val_loss: 6.8638\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5.0557 - val_loss: 6.8573\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 5.0507 - val_loss: 6.8508\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.0458 - val_loss: 6.8443\n",
            "Epoch 688/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.0409 - val_loss: 6.8378\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5.0359 - val_loss: 6.8313\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.0310 - val_loss: 6.8249\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 5.0260 - val_loss: 6.8184\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 5.0211 - val_loss: 6.8119\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 5.0162 - val_loss: 6.8055\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 5.0112 - val_loss: 6.7990\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 5.0063 - val_loss: 6.7925\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 5.0014 - val_loss: 6.7860\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 4.9964 - val_loss: 6.7796\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 4.9915 - val_loss: 6.7731\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 4.9866 - val_loss: 6.7667\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.9816 - val_loss: 6.7603\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.9767 - val_loss: 6.7538\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.9718 - val_loss: 6.7474\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.9669 - val_loss: 6.7409\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.9620 - val_loss: 6.7345\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.9571 - val_loss: 6.7281\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.9522 - val_loss: 6.7216\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.9473 - val_loss: 6.7152\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.9424 - val_loss: 6.7088\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 4.9375 - val_loss: 6.7024\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.9326 - val_loss: 6.6960\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 4.9277 - val_loss: 6.6895\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 4.9228 - val_loss: 6.6831\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.9179 - val_loss: 6.6767\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.9130 - val_loss: 6.6703\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 4.9081 - val_loss: 6.6639\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.9032 - val_loss: 6.6575\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 4.8983 - val_loss: 6.6511\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4.8934 - val_loss: 6.6447\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.8886 - val_loss: 6.6383\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.8837 - val_loss: 6.6319\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.8788 - val_loss: 6.6255\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.8739 - val_loss: 6.6191\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.8690 - val_loss: 6.6127\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.8642 - val_loss: 6.6063\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.8593 - val_loss: 6.5999\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.8545 - val_loss: 6.5936\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.8496 - val_loss: 6.5872\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.8447 - val_loss: 6.5808\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.8399 - val_loss: 6.5744\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.8350 - val_loss: 6.5681\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.8302 - val_loss: 6.5617\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.8253 - val_loss: 6.5553\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 4.8205 - val_loss: 6.5489\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.8156 - val_loss: 6.5426\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.8107 - val_loss: 6.5362\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.8059 - val_loss: 6.5299\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.8011 - val_loss: 6.5235\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.7962 - val_loss: 6.5171\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.7914 - val_loss: 6.5108\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.7865 - val_loss: 6.5045\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 4.7817 - val_loss: 6.4981\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.7769 - val_loss: 6.4918\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.7721 - val_loss: 6.4855\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.7672 - val_loss: 6.4791\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.7624 - val_loss: 6.4728\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.7576 - val_loss: 6.4665\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 4.7527 - val_loss: 6.4601\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.7479 - val_loss: 6.4538\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 4.7431 - val_loss: 6.4475\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.7383 - val_loss: 6.4411\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.7335 - val_loss: 6.4348\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.7287 - val_loss: 6.4285\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.7239 - val_loss: 6.4222\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.7190 - val_loss: 6.4158\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 4.7142 - val_loss: 6.4095\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.7095 - val_loss: 6.4032\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.7047 - val_loss: 6.3969\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 4.6998 - val_loss: 6.3906\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 4.6951 - val_loss: 6.3843\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 4.6903 - val_loss: 6.3780\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 4.6855 - val_loss: 6.3717\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.6807 - val_loss: 6.3654\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.6759 - val_loss: 6.3591\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.6711 - val_loss: 6.3529\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.6663 - val_loss: 6.3465\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.6616 - val_loss: 6.3402\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.6568 - val_loss: 6.3339\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.6520 - val_loss: 6.3276\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.6472 - val_loss: 6.3214\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.6425 - val_loss: 6.3151\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.6377 - val_loss: 6.3088\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 4.6329 - val_loss: 6.3025\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.6282 - val_loss: 6.2963\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.6234 - val_loss: 6.2900\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.6186 - val_loss: 6.2838\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 4.6139 - val_loss: 6.2775\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.6091 - val_loss: 6.2713\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.6044 - val_loss: 6.2650\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.5996 - val_loss: 6.2588\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.5949 - val_loss: 6.2525\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.5901 - val_loss: 6.2463\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.5854 - val_loss: 6.2401\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.5806 - val_loss: 6.2338\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.5759 - val_loss: 6.2276\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.5712 - val_loss: 6.2214\n",
            "Epoch 786/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.5664 - val_loss: 6.2152\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.5617 - val_loss: 6.2090\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.5570 - val_loss: 6.2028\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 4.5522 - val_loss: 6.1966\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.5475 - val_loss: 6.1904\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 4.5428 - val_loss: 6.1842\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.5381 - val_loss: 6.1780\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.5334 - val_loss: 6.1718\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.5286 - val_loss: 6.1655\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.5239 - val_loss: 6.1594\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.5192 - val_loss: 6.1532\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.5145 - val_loss: 6.1470\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.5098 - val_loss: 6.1408\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.5051 - val_loss: 6.1346\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.5004 - val_loss: 6.1284\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.4957 - val_loss: 6.1223\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.4910 - val_loss: 6.1161\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.4863 - val_loss: 6.1099\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 4.4816 - val_loss: 6.1037\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 4.4769 - val_loss: 6.0976\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 4.4722 - val_loss: 6.0914\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 4.4675 - val_loss: 6.0853\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.4628 - val_loss: 6.0791\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.4581 - val_loss: 6.0729\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 4.4535 - val_loss: 6.0668\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.4488 - val_loss: 6.0607\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 4.4441 - val_loss: 6.0545\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.4394 - val_loss: 6.0484\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.4348 - val_loss: 6.0422\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.4301 - val_loss: 6.0361\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 4.4254 - val_loss: 6.0300\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.4208 - val_loss: 6.0238\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.4161 - val_loss: 6.0177\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.4115 - val_loss: 6.0116\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.4068 - val_loss: 6.0054\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.4022 - val_loss: 5.9993\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.3975 - val_loss: 5.9932\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.3928 - val_loss: 5.9871\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 4.3882 - val_loss: 5.9810\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 4.3836 - val_loss: 5.9749\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.3789 - val_loss: 5.9687\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.3743 - val_loss: 5.9626\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.3696 - val_loss: 5.9565\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.3650 - val_loss: 5.9504\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.3603 - val_loss: 5.9443\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.3557 - val_loss: 5.9382\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.3511 - val_loss: 5.9321\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.3465 - val_loss: 5.9260\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.3419 - val_loss: 5.9199\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.3372 - val_loss: 5.9138\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.3326 - val_loss: 5.9077\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 4.3280 - val_loss: 5.9017\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 4.3234 - val_loss: 5.8956\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 4.3188 - val_loss: 5.8896\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.3142 - val_loss: 5.8835\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.3096 - val_loss: 5.8774\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.3050 - val_loss: 5.8714\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 4.3003 - val_loss: 5.8653\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 4.2958 - val_loss: 5.8592\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.2912 - val_loss: 5.8532\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.2866 - val_loss: 5.8472\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.2820 - val_loss: 5.8411\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 4.2774 - val_loss: 5.8351\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 4.2728 - val_loss: 5.8291\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 4.2682 - val_loss: 5.8231\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.2636 - val_loss: 5.8170\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.2591 - val_loss: 5.8110\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.2545 - val_loss: 5.8050\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 4.2499 - val_loss: 5.7990\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 4.2453 - val_loss: 5.7929\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.2408 - val_loss: 5.7869\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.2362 - val_loss: 5.7809\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.2316 - val_loss: 5.7749\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.2271 - val_loss: 5.7689\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.2225 - val_loss: 5.7629\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.2179 - val_loss: 5.7569\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 4.2134 - val_loss: 5.7510\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.2088 - val_loss: 5.7449\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 4.2043 - val_loss: 5.7390\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.1997 - val_loss: 5.7330\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.1952 - val_loss: 5.7270\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.1906 - val_loss: 5.7210\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.1861 - val_loss: 5.7150\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.1816 - val_loss: 5.7091\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.1770 - val_loss: 5.7031\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.1725 - val_loss: 5.6971\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.1680 - val_loss: 5.6912\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.1634 - val_loss: 5.6852\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.1589 - val_loss: 5.6792\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.1544 - val_loss: 5.6733\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 4.1499 - val_loss: 5.6673\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.1453 - val_loss: 5.6614\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.1408 - val_loss: 5.6555\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.1363 - val_loss: 5.6495\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 4.1318 - val_loss: 5.6435\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.1273 - val_loss: 5.6376\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.1228 - val_loss: 5.6316\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 4.1183 - val_loss: 5.6257\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.1138 - val_loss: 5.6197\n",
            "Epoch 885/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 4.1093 - val_loss: 5.6138\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 4.1048 - val_loss: 5.6078\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.1003 - val_loss: 5.6019\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.0958 - val_loss: 5.5959\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.0913 - val_loss: 5.5900\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.0868 - val_loss: 5.5841\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 4.0823 - val_loss: 5.5782\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 4.0779 - val_loss: 5.5723\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 4.0734 - val_loss: 5.5664\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 4.0689 - val_loss: 5.5605\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.0644 - val_loss: 5.5546\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.0599 - val_loss: 5.5487\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.0555 - val_loss: 5.5428\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.0510 - val_loss: 5.5369\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.0466 - val_loss: 5.5310\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.0421 - val_loss: 5.5251\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 4.0376 - val_loss: 5.5193\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.0332 - val_loss: 5.5134\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.0287 - val_loss: 5.5075\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.0243 - val_loss: 5.5017\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.0198 - val_loss: 5.4958\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.0154 - val_loss: 5.4899\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 4.0109 - val_loss: 5.4841\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.0065 - val_loss: 5.4783\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.0021 - val_loss: 5.4724\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.9976 - val_loss: 5.4666\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.9932 - val_loss: 5.4607\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.9888 - val_loss: 5.4549\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.9843 - val_loss: 5.4491\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.9799 - val_loss: 5.4432\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.9755 - val_loss: 5.4374\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.9711 - val_loss: 5.4316\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.9666 - val_loss: 5.4258\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.9622 - val_loss: 5.4200\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.9578 - val_loss: 5.4142\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.9534 - val_loss: 5.4083\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.9490 - val_loss: 5.4025\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.9446 - val_loss: 5.3967\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.9402 - val_loss: 5.3909\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.9358 - val_loss: 5.3851\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.9314 - val_loss: 5.3793\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.9270 - val_loss: 5.3735\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 3.9226 - val_loss: 5.3677\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.9182 - val_loss: 5.3620\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.9138 - val_loss: 5.3562\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.9094 - val_loss: 5.3504\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.9051 - val_loss: 5.3447\n",
            "Epoch 932/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.9007 - val_loss: 5.3389\n",
            "Epoch 933/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.8963 - val_loss: 5.3332\n",
            "Epoch 934/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.8919 - val_loss: 5.3274\n",
            "Epoch 935/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.8876 - val_loss: 5.3217\n",
            "Epoch 936/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.8832 - val_loss: 5.3158\n",
            "Epoch 937/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.8788 - val_loss: 5.3101\n",
            "Epoch 938/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.8745 - val_loss: 5.3043\n",
            "Epoch 939/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.8701 - val_loss: 5.2986\n",
            "Epoch 940/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.8657 - val_loss: 5.2928\n",
            "Epoch 941/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.8614 - val_loss: 5.2871\n",
            "Epoch 942/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.8570 - val_loss: 5.2813\n",
            "Epoch 943/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.8527 - val_loss: 5.2756\n",
            "Epoch 944/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.8483 - val_loss: 5.2699\n",
            "Epoch 945/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.8440 - val_loss: 5.2641\n",
            "Epoch 946/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.8396 - val_loss: 5.2584\n",
            "Epoch 947/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.8353 - val_loss: 5.2527\n",
            "Epoch 948/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.8310 - val_loss: 5.2469\n",
            "Epoch 949/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.8266 - val_loss: 5.2412\n",
            "Epoch 950/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.8223 - val_loss: 5.2355\n",
            "Epoch 951/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.8180 - val_loss: 5.2298\n",
            "Epoch 952/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.8136 - val_loss: 5.2241\n",
            "Epoch 953/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.8093 - val_loss: 5.2184\n",
            "Epoch 954/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.8050 - val_loss: 5.2127\n",
            "Epoch 955/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.8007 - val_loss: 5.2070\n",
            "Epoch 956/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.7963 - val_loss: 5.2013\n",
            "Epoch 957/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.7920 - val_loss: 5.1956\n",
            "Epoch 958/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.7877 - val_loss: 5.1899\n",
            "Epoch 959/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.7834 - val_loss: 5.1843\n",
            "Epoch 960/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.7791 - val_loss: 5.1786\n",
            "Epoch 961/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.7748 - val_loss: 5.1729\n",
            "Epoch 962/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.7705 - val_loss: 5.1672\n",
            "Epoch 963/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.7662 - val_loss: 5.1615\n",
            "Epoch 964/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.7619 - val_loss: 5.1558\n",
            "Epoch 965/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 3.7576 - val_loss: 5.1502\n",
            "Epoch 966/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3.7533 - val_loss: 5.1445\n",
            "Epoch 967/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.7490 - val_loss: 5.1388\n",
            "Epoch 968/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.7448 - val_loss: 5.1332\n",
            "Epoch 969/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.7405 - val_loss: 5.1275\n",
            "Epoch 970/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.7362 - val_loss: 5.1219\n",
            "Epoch 971/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.7319 - val_loss: 5.1162\n",
            "Epoch 972/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.7276 - val_loss: 5.1105\n",
            "Epoch 973/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.7234 - val_loss: 5.1049\n",
            "Epoch 974/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.7191 - val_loss: 5.0993\n",
            "Epoch 975/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.7148 - val_loss: 5.0936\n",
            "Epoch 976/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3.7106 - val_loss: 5.0880\n",
            "Epoch 977/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.7063 - val_loss: 5.0824\n",
            "Epoch 978/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.7020 - val_loss: 5.0767\n",
            "Epoch 979/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.6978 - val_loss: 5.0711\n",
            "Epoch 980/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.6936 - val_loss: 5.0655\n",
            "Epoch 981/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.6893 - val_loss: 5.0599\n",
            "Epoch 982/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.6851 - val_loss: 5.0542\n",
            "Epoch 983/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.6808 - val_loss: 5.0486\n",
            "Epoch 984/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.6766 - val_loss: 5.0430\n",
            "Epoch 985/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.6723 - val_loss: 5.0374\n",
            "Epoch 986/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.6681 - val_loss: 5.0318\n",
            "Epoch 987/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.6639 - val_loss: 5.0262\n",
            "Epoch 988/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.6596 - val_loss: 5.0206\n",
            "Epoch 989/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.6554 - val_loss: 5.0150\n",
            "Epoch 990/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.6512 - val_loss: 5.0095\n",
            "Epoch 991/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.6470 - val_loss: 5.0039\n",
            "Epoch 992/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.6427 - val_loss: 4.9983\n",
            "Epoch 993/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.6385 - val_loss: 4.9927\n",
            "Epoch 994/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.6343 - val_loss: 4.9871\n",
            "Epoch 995/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.6301 - val_loss: 4.9815\n",
            "Epoch 996/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.6259 - val_loss: 4.9760\n",
            "Epoch 997/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.6217 - val_loss: 4.9704\n",
            "Epoch 998/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.6175 - val_loss: 4.9649\n",
            "Epoch 999/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.6133 - val_loss: 4.9593\n",
            "Epoch 1000/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.6091 - val_loss: 4.9538\n",
            "Epoch 1/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 9.9851 - val_loss: 5.8550\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 9.4227 - val_loss: 5.4637\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 8.7083 - val_loss: 5.0322\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7.9366 - val_loss: 4.5971\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7.1404 - val_loss: 4.1663\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.3519 - val_loss: 3.7465\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5.5926 - val_loss: 3.3454\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.8764 - val_loss: 3.0791\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.6596 - val_loss: 3.0425\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 4.6012 - val_loss: 3.0212\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 4.5856 - val_loss: 3.0140\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.5707 - val_loss: 3.0068\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.5564 - val_loss: 2.9996\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.5436 - val_loss: 2.9923\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 4.5313 - val_loss: 2.9851\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.5190 - val_loss: 2.9778\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.5066 - val_loss: 2.9705\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.4943 - val_loss: 2.9631\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.4819 - val_loss: 2.9558\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.4694 - val_loss: 2.9485\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.4570 - val_loss: 2.9411\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.4446 - val_loss: 2.9338\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.4321 - val_loss: 2.9264\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.4197 - val_loss: 2.9191\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.4072 - val_loss: 2.9118\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.3948 - val_loss: 2.9044\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4.3824 - val_loss: 2.8971\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 4.3700 - val_loss: 2.8898\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 4.3576 - val_loss: 2.8825\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.3452 - val_loss: 2.8752\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.3328 - val_loss: 2.8679\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.3204 - val_loss: 2.8606\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.3081 - val_loss: 2.8533\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.2958 - val_loss: 2.8460\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.2835 - val_loss: 2.8388\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 4.2712 - val_loss: 2.8315\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 4.2589 - val_loss: 2.8243\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.2467 - val_loss: 2.8171\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.2344 - val_loss: 2.8099\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 4.2222 - val_loss: 2.8027\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.2101 - val_loss: 2.7955\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.1979 - val_loss: 2.7883\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.1858 - val_loss: 2.7811\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.1737 - val_loss: 2.7740\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.1616 - val_loss: 2.7669\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 4.1496 - val_loss: 2.7598\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 4.1375 - val_loss: 2.7526\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.1255 - val_loss: 2.7456\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.1136 - val_loss: 2.7385\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 4.1016 - val_loss: 2.7314\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.0897 - val_loss: 2.7244\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 4.0778 - val_loss: 2.7174\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.0659 - val_loss: 2.7103\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.0541 - val_loss: 2.7033\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.0423 - val_loss: 2.6964\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.0305 - val_loss: 2.6894\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 4.0187 - val_loss: 2.6824\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.0070 - val_loss: 2.6755\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.9953 - val_loss: 2.6686\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.9836 - val_loss: 2.6616\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.9719 - val_loss: 2.6547\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.9603 - val_loss: 2.6479\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.9487 - val_loss: 2.6410\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.9371 - val_loss: 2.6341\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.9256 - val_loss: 2.6273\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.9140 - val_loss: 2.6205\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.9025 - val_loss: 2.6137\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.8911 - val_loss: 2.6069\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.8796 - val_loss: 2.6001\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.8682 - val_loss: 2.5933\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.8568 - val_loss: 2.5866\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.8455 - val_loss: 2.5798\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.8341 - val_loss: 2.5731\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.8228 - val_loss: 2.5664\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.8115 - val_loss: 2.5597\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.8003 - val_loss: 2.5530\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.7891 - val_loss: 2.5463\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.7779 - val_loss: 2.5397\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.7667 - val_loss: 2.5331\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.7555 - val_loss: 2.5264\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.7444 - val_loss: 2.5198\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.7333 - val_loss: 2.5132\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.7223 - val_loss: 2.5067\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.7112 - val_loss: 2.5001\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.7002 - val_loss: 2.4935\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.6892 - val_loss: 2.4870\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.6782 - val_loss: 2.4805\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.6673 - val_loss: 2.4740\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.6564 - val_loss: 2.4675\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.6455 - val_loss: 2.4610\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.6347 - val_loss: 2.4546\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.6238 - val_loss: 2.4481\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.6130 - val_loss: 2.4417\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.6022 - val_loss: 2.4352\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.5915 - val_loss: 2.4288\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.5807 - val_loss: 2.4224\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.5700 - val_loss: 2.4161\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.5594 - val_loss: 2.4097\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.5487 - val_loss: 2.4034\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.5381 - val_loss: 2.3970\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.5275 - val_loss: 2.3907\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.5169 - val_loss: 2.3844\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.5064 - val_loss: 2.3781\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.4959 - val_loss: 2.3718\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.4854 - val_loss: 2.3656\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.4749 - val_loss: 2.3593\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.4644 - val_loss: 2.3531\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.4540 - val_loss: 2.3468\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.4436 - val_loss: 2.3406\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.4333 - val_loss: 2.3344\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.4229 - val_loss: 2.3283\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.4126 - val_loss: 2.3221\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.4023 - val_loss: 2.3159\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.3920 - val_loss: 2.3098\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.3818 - val_loss: 2.3037\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.3716 - val_loss: 2.2976\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.3614 - val_loss: 2.2915\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.3512 - val_loss: 2.2854\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.3411 - val_loss: 2.2793\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.3309 - val_loss: 2.2732\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.3209 - val_loss: 2.2672\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.3108 - val_loss: 2.2612\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.3007 - val_loss: 2.2552\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.2907 - val_loss: 2.2492\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.2807 - val_loss: 2.2432\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.2708 - val_loss: 2.2372\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3.2608 - val_loss: 2.2312\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.2509 - val_loss: 2.2253\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.2410 - val_loss: 2.2193\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.2311 - val_loss: 2.2134\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.2213 - val_loss: 2.2075\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.2115 - val_loss: 2.2016\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.2017 - val_loss: 2.1957\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.1919 - val_loss: 2.1899\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3.1821 - val_loss: 2.1840\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.1724 - val_loss: 2.1782\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.1627 - val_loss: 2.1723\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.1530 - val_loss: 2.1665\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.1434 - val_loss: 2.1607\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.1338 - val_loss: 2.1549\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.1242 - val_loss: 2.1492\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 3.1146 - val_loss: 2.1434\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.1050 - val_loss: 2.1377\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.0955 - val_loss: 2.1319\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.0860 - val_loss: 2.1262\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.0765 - val_loss: 2.1205\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.0670 - val_loss: 2.1148\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.0576 - val_loss: 2.1091\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.0482 - val_loss: 2.1034\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.0388 - val_loss: 2.0978\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.0295 - val_loss: 2.0921\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.0201 - val_loss: 2.0865\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.0108 - val_loss: 2.0809\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.0015 - val_loss: 2.0753\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.9922 - val_loss: 2.0697\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.9830 - val_loss: 2.0641\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.9738 - val_loss: 2.0586\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.9646 - val_loss: 2.0530\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.9554 - val_loss: 2.0475\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.9462 - val_loss: 2.0419\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.9371 - val_loss: 2.0364\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.9280 - val_loss: 2.0309\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.9189 - val_loss: 2.0254\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.9098 - val_loss: 2.0199\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.9008 - val_loss: 2.0145\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.8918 - val_loss: 2.0090\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.8828 - val_loss: 2.0036\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.8738 - val_loss: 1.9982\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.8649 - val_loss: 1.9928\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.8560 - val_loss: 1.9874\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2.8471 - val_loss: 1.9820\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.8382 - val_loss: 1.9766\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.8293 - val_loss: 1.9712\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.8205 - val_loss: 1.9659\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.8117 - val_loss: 1.9605\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.8029 - val_loss: 1.9552\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.7941 - val_loss: 1.9499\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.7854 - val_loss: 1.9446\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.7767 - val_loss: 1.9393\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.7680 - val_loss: 1.9340\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.7593 - val_loss: 1.9288\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.7507 - val_loss: 1.9235\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.7420 - val_loss: 1.9183\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.7334 - val_loss: 1.9131\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.7248 - val_loss: 1.9079\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.7163 - val_loss: 1.9027\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.7077 - val_loss: 1.8975\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.6992 - val_loss: 1.8923\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.6907 - val_loss: 1.8871\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.6822 - val_loss: 1.8820\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.6738 - val_loss: 1.8768\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.6654 - val_loss: 1.8717\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.6570 - val_loss: 1.8666\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.6486 - val_loss: 1.8615\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.6402 - val_loss: 1.8564\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.6319 - val_loss: 1.8513\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.6236 - val_loss: 1.8462\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.6153 - val_loss: 1.8412\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.6070 - val_loss: 1.8361\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.5987 - val_loss: 1.8311\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.5905 - val_loss: 1.8261\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.5823 - val_loss: 1.8211\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.5741 - val_loss: 1.8161\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.5659 - val_loss: 1.8111\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.5578 - val_loss: 1.8061\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.5496 - val_loss: 1.8012\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.5415 - val_loss: 1.7962\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.5335 - val_loss: 1.7913\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.5254 - val_loss: 1.7864\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.5174 - val_loss: 1.7815\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.5093 - val_loss: 1.7766\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.5013 - val_loss: 1.7717\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.4934 - val_loss: 1.7668\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.4854 - val_loss: 1.7619\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.4775 - val_loss: 1.7571\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.4696 - val_loss: 1.7522\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.4617 - val_loss: 1.7474\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.4538 - val_loss: 1.7426\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.4459 - val_loss: 1.7378\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.4381 - val_loss: 1.7330\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.4303 - val_loss: 1.7282\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.4225 - val_loss: 1.7234\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.4148 - val_loss: 1.7187\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.4070 - val_loss: 1.7139\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.3993 - val_loss: 1.7092\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.3916 - val_loss: 1.7044\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.3839 - val_loss: 1.6997\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.3762 - val_loss: 1.6950\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.3686 - val_loss: 1.6903\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.3610 - val_loss: 1.6856\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.3534 - val_loss: 1.6810\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.3458 - val_loss: 1.6763\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.3382 - val_loss: 1.6717\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.3307 - val_loss: 1.6670\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.3232 - val_loss: 1.6624\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.3157 - val_loss: 1.6578\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.3082 - val_loss: 1.6532\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.3007 - val_loss: 1.6486\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.2933 - val_loss: 1.6440\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.2858 - val_loss: 1.6395\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.2784 - val_loss: 1.6349\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.2711 - val_loss: 1.6304\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.2637 - val_loss: 1.6258\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.2564 - val_loss: 1.6213\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.2490 - val_loss: 1.6168\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.2417 - val_loss: 1.6123\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.2345 - val_loss: 1.6078\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.2272 - val_loss: 1.6033\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.2200 - val_loss: 1.5988\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.2127 - val_loss: 1.5944\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.2055 - val_loss: 1.5899\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.1984 - val_loss: 1.5855\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.1912 - val_loss: 1.5811\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.1841 - val_loss: 1.5767\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.1769 - val_loss: 1.5723\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.1698 - val_loss: 1.5679\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.1627 - val_loss: 1.5635\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.1557 - val_loss: 1.5591\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.1486 - val_loss: 1.5548\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.1416 - val_loss: 1.5504\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.1346 - val_loss: 1.5461\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.1276 - val_loss: 1.5417\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.1206 - val_loss: 1.5374\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.1137 - val_loss: 1.5331\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.1068 - val_loss: 1.5288\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.0998 - val_loss: 1.5245\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.0930 - val_loss: 1.5203\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.0861 - val_loss: 1.5160\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.0792 - val_loss: 1.5117\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.0724 - val_loss: 1.5075\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.0656 - val_loss: 1.5033\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.0588 - val_loss: 1.4990\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.0520 - val_loss: 1.4948\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.0452 - val_loss: 1.4906\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.0385 - val_loss: 1.4864\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.0318 - val_loss: 1.4823\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.0251 - val_loss: 1.4781\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.0184 - val_loss: 1.4739\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.0117 - val_loss: 1.4698\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.0051 - val_loss: 1.4656\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.9984 - val_loss: 1.4615\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.9918 - val_loss: 1.4574\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.9852 - val_loss: 1.4533\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.9787 - val_loss: 1.4492\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.9721 - val_loss: 1.4451\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.9656 - val_loss: 1.4410\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.9590 - val_loss: 1.4370\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.9525 - val_loss: 1.4329\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.9461 - val_loss: 1.4289\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.9396 - val_loss: 1.4248\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.9331 - val_loss: 1.4208\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.9267 - val_loss: 1.4168\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.9203 - val_loss: 1.4128\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.9139 - val_loss: 1.4088\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.9075 - val_loss: 1.4048\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.9012 - val_loss: 1.4008\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.8948 - val_loss: 1.3969\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.8885 - val_loss: 1.3929\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.8822 - val_loss: 1.3890\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.8759 - val_loss: 1.3850\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.8697 - val_loss: 1.3811\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.8634 - val_loss: 1.3772\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.8572 - val_loss: 1.3733\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.8510 - val_loss: 1.3694\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 1.8448 - val_loss: 1.3655\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.8386 - val_loss: 1.3616\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.8324 - val_loss: 1.3578\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.8263 - val_loss: 1.3539\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.8202 - val_loss: 1.3501\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.8141 - val_loss: 1.3462\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.8080 - val_loss: 1.3424\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.8019 - val_loss: 1.3386\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.7958 - val_loss: 1.3348\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.7898 - val_loss: 1.3310\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.7838 - val_loss: 1.3272\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.7778 - val_loss: 1.3234\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.7718 - val_loss: 1.3197\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.7658 - val_loss: 1.3159\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.7599 - val_loss: 1.3121\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.7539 - val_loss: 1.3084\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.7480 - val_loss: 1.3047\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.7421 - val_loss: 1.3010\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.7362 - val_loss: 1.2972\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.7303 - val_loss: 1.2935\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.7245 - val_loss: 1.2899\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.7187 - val_loss: 1.2862\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.7128 - val_loss: 1.2825\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.7070 - val_loss: 1.2788\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.7013 - val_loss: 1.2752\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.6955 - val_loss: 1.2715\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.6897 - val_loss: 1.2679\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.6840 - val_loss: 1.2643\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.6783 - val_loss: 1.2607\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.6726 - val_loss: 1.2571\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.6669 - val_loss: 1.2535\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.6612 - val_loss: 1.2499\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.6556 - val_loss: 1.2463\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.6499 - val_loss: 1.2427\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.6443 - val_loss: 1.2392\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.6387 - val_loss: 1.2356\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.6331 - val_loss: 1.2321\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.6276 - val_loss: 1.2285\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.6220 - val_loss: 1.2250\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.6165 - val_loss: 1.2215\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.6110 - val_loss: 1.2180\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.6054 - val_loss: 1.2145\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.6000 - val_loss: 1.2110\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.5945 - val_loss: 1.2075\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.5890 - val_loss: 1.2041\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.5836 - val_loss: 1.2006\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.5782 - val_loss: 1.1972\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.5728 - val_loss: 1.1937\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.5674 - val_loss: 1.1903\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.5620 - val_loss: 1.1869\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.5566 - val_loss: 1.1834\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.5513 - val_loss: 1.1800\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.5459 - val_loss: 1.1766\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.5406 - val_loss: 1.1732\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.5353 - val_loss: 1.1699\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.5300 - val_loss: 1.1665\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.5248 - val_loss: 1.1631\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.5195 - val_loss: 1.1598\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.5143 - val_loss: 1.1564\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.5091 - val_loss: 1.1531\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.5039 - val_loss: 1.1498\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.4987 - val_loss: 1.1465\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.4935 - val_loss: 1.1432\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.4883 - val_loss: 1.1399\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.4832 - val_loss: 1.1366\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.4781 - val_loss: 1.1333\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.4730 - val_loss: 1.1300\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.4679 - val_loss: 1.1267\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.4628 - val_loss: 1.1235\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.4577 - val_loss: 1.1202\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.4527 - val_loss: 1.1170\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.4476 - val_loss: 1.1138\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.4426 - val_loss: 1.1105\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.4376 - val_loss: 1.1073\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.4326 - val_loss: 1.1041\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.4276 - val_loss: 1.1009\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.4227 - val_loss: 1.0977\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.4177 - val_loss: 1.0946\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.4128 - val_loss: 1.0914\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.4079 - val_loss: 1.0882\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.4030 - val_loss: 1.0851\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.3981 - val_loss: 1.0819\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.3932 - val_loss: 1.0788\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.3883 - val_loss: 1.0756\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.3835 - val_loss: 1.0725\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.3787 - val_loss: 1.0694\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.3738 - val_loss: 1.0663\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.3690 - val_loss: 1.0632\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.3643 - val_loss: 1.0601\n",
            "Epoch 394/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.3595 - val_loss: 1.0570\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.3547 - val_loss: 1.0540\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.3500 - val_loss: 1.0509\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.3453 - val_loss: 1.0478\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.3405 - val_loss: 1.0448\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.3358 - val_loss: 1.0418\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.3312 - val_loss: 1.0387\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.3265 - val_loss: 1.0357\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.3218 - val_loss: 1.0327\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.3172 - val_loss: 1.0297\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.3126 - val_loss: 1.0267\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.3079 - val_loss: 1.0237\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.3033 - val_loss: 1.0207\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.2988 - val_loss: 1.0177\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.2942 - val_loss: 1.0148\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.2896 - val_loss: 1.0118\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.2851 - val_loss: 1.0089\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.2806 - val_loss: 1.0059\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.2760 - val_loss: 1.0030\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.2715 - val_loss: 1.0001\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.2670 - val_loss: 0.9971\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.2626 - val_loss: 0.9942\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.2581 - val_loss: 0.9913\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.2537 - val_loss: 0.9884\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.2492 - val_loss: 0.9855\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.2448 - val_loss: 0.9827\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.2404 - val_loss: 0.9798\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.2360 - val_loss: 0.9769\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.2316 - val_loss: 0.9741\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.2273 - val_loss: 0.9712\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.2229 - val_loss: 0.9684\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.2186 - val_loss: 0.9656\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.2142 - val_loss: 0.9627\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.2099 - val_loss: 0.9599\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.2056 - val_loss: 0.9571\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.2014 - val_loss: 0.9543\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.1971 - val_loss: 0.9515\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.1928 - val_loss: 0.9487\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.1886 - val_loss: 0.9459\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.1843 - val_loss: 0.9432\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.1801 - val_loss: 0.9404\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.1759 - val_loss: 0.9376\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.1717 - val_loss: 0.9349\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.1675 - val_loss: 0.9322\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.1634 - val_loss: 0.9294\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.1592 - val_loss: 0.9267\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.1551 - val_loss: 0.9240\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.1510 - val_loss: 0.9213\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 1.1468 - val_loss: 0.9186\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.1427 - val_loss: 0.9159\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.1387 - val_loss: 0.9132\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.1346 - val_loss: 0.9105\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.1305 - val_loss: 0.9078\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.1265 - val_loss: 0.9051\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.1224 - val_loss: 0.9025\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.1184 - val_loss: 0.8998\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1.1144 - val_loss: 0.8972\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.1104 - val_loss: 0.8946\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.1064 - val_loss: 0.8919\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.1024 - val_loss: 0.8893\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.0985 - val_loss: 0.8867\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.0945 - val_loss: 0.8841\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.0906 - val_loss: 0.8815\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.0867 - val_loss: 0.8789\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.0827 - val_loss: 0.8763\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.0788 - val_loss: 0.8737\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.0750 - val_loss: 0.8711\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.0711 - val_loss: 0.8686\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.0672 - val_loss: 0.8660\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.0634 - val_loss: 0.8635\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.0595 - val_loss: 0.8609\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.0557 - val_loss: 0.8584\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.0519 - val_loss: 0.8558\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.0481 - val_loss: 0.8533\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.0443 - val_loss: 0.8508\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.0405 - val_loss: 0.8483\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.0368 - val_loss: 0.8458\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.0330 - val_loss: 0.8433\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.0293 - val_loss: 0.8408\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.0255 - val_loss: 0.8383\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.0218 - val_loss: 0.8358\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.0181 - val_loss: 0.8334\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.0144 - val_loss: 0.8309\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.0107 - val_loss: 0.8285\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.0071 - val_loss: 0.8260\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.0034 - val_loss: 0.8236\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.9998 - val_loss: 0.8211\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.9961 - val_loss: 0.8187\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.9925 - val_loss: 0.8163\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.9889 - val_loss: 0.8139\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.9853 - val_loss: 0.8115\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.9817 - val_loss: 0.8091\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.9781 - val_loss: 0.8067\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.9746 - val_loss: 0.8043\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.9710 - val_loss: 0.8019\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.9675 - val_loss: 0.7995\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.9639 - val_loss: 0.7972\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.9604 - val_loss: 0.7948\n",
            "Epoch 492/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.9569 - val_loss: 0.7925\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.9534 - val_loss: 0.7901\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.9499 - val_loss: 0.7878\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.9465 - val_loss: 0.7854\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.9430 - val_loss: 0.7831\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.9395 - val_loss: 0.7808\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.9361 - val_loss: 0.7785\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.9327 - val_loss: 0.7762\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.9293 - val_loss: 0.7739\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.9259 - val_loss: 0.7716\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.9225 - val_loss: 0.7693\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.9191 - val_loss: 0.7670\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.9157 - val_loss: 0.7647\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.9123 - val_loss: 0.7625\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.9090 - val_loss: 0.7602\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.9057 - val_loss: 0.7579\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.9023 - val_loss: 0.7557\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.8990 - val_loss: 0.7535\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.8957 - val_loss: 0.7512\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.8924 - val_loss: 0.7490\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.8891 - val_loss: 0.7468\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.8858 - val_loss: 0.7445\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.8826 - val_loss: 0.7423\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.8793 - val_loss: 0.7401\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.8761 - val_loss: 0.7379\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.8729 - val_loss: 0.7357\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.8696 - val_loss: 0.7335\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.8664 - val_loss: 0.7314\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.8632 - val_loss: 0.7292\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.8600 - val_loss: 0.7270\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.8569 - val_loss: 0.7249\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.8537 - val_loss: 0.7227\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.8505 - val_loss: 0.7206\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.8474 - val_loss: 0.7184\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.8443 - val_loss: 0.7163\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.8411 - val_loss: 0.7142\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.8380 - val_loss: 0.7120\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.8349 - val_loss: 0.7099\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.8318 - val_loss: 0.7078\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.8287 - val_loss: 0.7057\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.8257 - val_loss: 0.7036\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.8226 - val_loss: 0.7015\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.8195 - val_loss: 0.6994\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.8165 - val_loss: 0.6973\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.8135 - val_loss: 0.6952\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.8104 - val_loss: 0.6932\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.8074 - val_loss: 0.6911\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.8044 - val_loss: 0.6891\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.8014 - val_loss: 0.6870\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.7985 - val_loss: 0.6850\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.7955 - val_loss: 0.6829\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.7925 - val_loss: 0.6809\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.7896 - val_loss: 0.6788\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.7866 - val_loss: 0.6768\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.7837 - val_loss: 0.6748\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.7808 - val_loss: 0.6728\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.7779 - val_loss: 0.6708\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.7750 - val_loss: 0.6688\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.7721 - val_loss: 0.6668\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.7692 - val_loss: 0.6648\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.7663 - val_loss: 0.6628\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.7634 - val_loss: 0.6608\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.7606 - val_loss: 0.6589\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.7577 - val_loss: 0.6569\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.7549 - val_loss: 0.6550\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.7521 - val_loss: 0.6530\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.7493 - val_loss: 0.6510\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.7465 - val_loss: 0.6491\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.7437 - val_loss: 0.6472\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.7409 - val_loss: 0.6452\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.7381 - val_loss: 0.6433\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.7353 - val_loss: 0.6414\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.7326 - val_loss: 0.6395\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.7298 - val_loss: 0.6376\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.7271 - val_loss: 0.6357\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.7243 - val_loss: 0.6338\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.7216 - val_loss: 0.6319\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.7189 - val_loss: 0.6300\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.7162 - val_loss: 0.6281\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.7135 - val_loss: 0.6262\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.7108 - val_loss: 0.6244\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.7082 - val_loss: 0.6225\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.7055 - val_loss: 0.6206\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.7028 - val_loss: 0.6188\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.7002 - val_loss: 0.6169\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6975 - val_loss: 0.6151\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6949 - val_loss: 0.6132\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6923 - val_loss: 0.6114\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6897 - val_loss: 0.6096\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6871 - val_loss: 0.6078\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6845 - val_loss: 0.6059\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6819 - val_loss: 0.6041\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6793 - val_loss: 0.6023\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6768 - val_loss: 0.6005\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6742 - val_loss: 0.5987\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6717 - val_loss: 0.5969\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6691 - val_loss: 0.5952\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6666 - val_loss: 0.5934\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6641 - val_loss: 0.5916\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6616 - val_loss: 0.5898\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6591 - val_loss: 0.5881\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6566 - val_loss: 0.5863\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6541 - val_loss: 0.5846\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6516 - val_loss: 0.5828\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6491 - val_loss: 0.5811\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6467 - val_loss: 0.5793\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6442 - val_loss: 0.5776\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6418 - val_loss: 0.5759\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6393 - val_loss: 0.5741\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6369 - val_loss: 0.5724\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6345 - val_loss: 0.5707\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6321 - val_loss: 0.5690\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6297 - val_loss: 0.5673\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6273 - val_loss: 0.5656\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6249 - val_loss: 0.5639\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6225 - val_loss: 0.5622\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6201 - val_loss: 0.5606\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6178 - val_loss: 0.5589\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6154 - val_loss: 0.5572\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6131 - val_loss: 0.5555\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6108 - val_loss: 0.5539\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6084 - val_loss: 0.5522\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6061 - val_loss: 0.5506\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6038 - val_loss: 0.5489\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6015 - val_loss: 0.5473\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5992 - val_loss: 0.5456\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5969 - val_loss: 0.5440\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5946 - val_loss: 0.5424\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5924 - val_loss: 0.5407\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5901 - val_loss: 0.5391\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5879 - val_loss: 0.5375\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5856 - val_loss: 0.5359\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5834 - val_loss: 0.5343\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.5811 - val_loss: 0.5327\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5789 - val_loss: 0.5311\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5767 - val_loss: 0.5295\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5745 - val_loss: 0.5279\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5723 - val_loss: 0.5264\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5701 - val_loss: 0.5248\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5679 - val_loss: 0.5232\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5658 - val_loss: 0.5216\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5636 - val_loss: 0.5201\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5614 - val_loss: 0.5185\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5593 - val_loss: 0.5170\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5571 - val_loss: 0.5154\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5550 - val_loss: 0.5139\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5529 - val_loss: 0.5123\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5507 - val_loss: 0.5108\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5486 - val_loss: 0.5093\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5465 - val_loss: 0.5078\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5444 - val_loss: 0.5062\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5423 - val_loss: 0.5047\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5403 - val_loss: 0.5032\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5382 - val_loss: 0.5017\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5361 - val_loss: 0.5002\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5341 - val_loss: 0.4987\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5320 - val_loss: 0.4972\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5300 - val_loss: 0.4957\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5279 - val_loss: 0.4942\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5259 - val_loss: 0.4928\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5239 - val_loss: 0.4913\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5218 - val_loss: 0.4898\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5198 - val_loss: 0.4884\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5178 - val_loss: 0.4869\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5158 - val_loss: 0.4854\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5139 - val_loss: 0.4840\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5119 - val_loss: 0.4825\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5099 - val_loss: 0.4811\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5079 - val_loss: 0.4797\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5060 - val_loss: 0.4782\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5040 - val_loss: 0.4768\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.5021 - val_loss: 0.4754\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5001 - val_loss: 0.4739\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.4982 - val_loss: 0.4725\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.4963 - val_loss: 0.4711\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4944 - val_loss: 0.4697\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4925 - val_loss: 0.4683\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.4906 - val_loss: 0.4669\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4887 - val_loss: 0.4655\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.4868 - val_loss: 0.4641\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4849 - val_loss: 0.4627\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.4830 - val_loss: 0.4613\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.4812 - val_loss: 0.4600\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4793 - val_loss: 0.4586\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.4774 - val_loss: 0.4572\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4756 - val_loss: 0.4558\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.4738 - val_loss: 0.4545\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.4719 - val_loss: 0.4531\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4701 - val_loss: 0.4518\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4683 - val_loss: 0.4504\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4665 - val_loss: 0.4491\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4647 - val_loss: 0.4477\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4629 - val_loss: 0.4464\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4611 - val_loss: 0.4451\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4593 - val_loss: 0.4437\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4575 - val_loss: 0.4424\n",
            "Epoch 688/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.4557 - val_loss: 0.4411\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4540 - val_loss: 0.4398\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4522 - val_loss: 0.4385\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4504 - val_loss: 0.4371\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.4487 - val_loss: 0.4358\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4470 - val_loss: 0.4345\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4452 - val_loss: 0.4332\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.4435 - val_loss: 0.4320\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4418 - val_loss: 0.4307\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4401 - val_loss: 0.4294\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.4384 - val_loss: 0.4281\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.4367 - val_loss: 0.4268\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.4350 - val_loss: 0.4255\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.4333 - val_loss: 0.4243\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.4316 - val_loss: 0.4230\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.4299 - val_loss: 0.4217\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4282 - val_loss: 0.4205\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.4266 - val_loss: 0.4192\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4249 - val_loss: 0.4180\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.4233 - val_loss: 0.4167\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4216 - val_loss: 0.4155\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.4200 - val_loss: 0.4143\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.4183 - val_loss: 0.4130\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4167 - val_loss: 0.4118\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4151 - val_loss: 0.4106\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4135 - val_loss: 0.4093\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4119 - val_loss: 0.4081\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4103 - val_loss: 0.4069\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.4087 - val_loss: 0.4057\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4071 - val_loss: 0.4045\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.4055 - val_loss: 0.4033\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.4039 - val_loss: 0.4021\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.4024 - val_loss: 0.4009\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.4008 - val_loss: 0.3997\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.3992 - val_loss: 0.3985\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.3977 - val_loss: 0.3973\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3961 - val_loss: 0.3961\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3946 - val_loss: 0.3950\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.3930 - val_loss: 0.3938\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.3915 - val_loss: 0.3926\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3900 - val_loss: 0.3914\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.3885 - val_loss: 0.3903\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.3870 - val_loss: 0.3891\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.3854 - val_loss: 0.3880\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.3839 - val_loss: 0.3868\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3824 - val_loss: 0.3857\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3810 - val_loss: 0.3845\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3795 - val_loss: 0.3834\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.3780 - val_loss: 0.3822\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3765 - val_loss: 0.3811\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3751 - val_loss: 0.3800\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3736 - val_loss: 0.3788\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3721 - val_loss: 0.3777\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.3707 - val_loss: 0.3766\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3692 - val_loss: 0.3755\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3678 - val_loss: 0.3743\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.3664 - val_loss: 0.3732\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.3649 - val_loss: 0.3721\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3635 - val_loss: 0.3710\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3621 - val_loss: 0.3699\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3607 - val_loss: 0.3688\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.3593 - val_loss: 0.3677\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3579 - val_loss: 0.3666\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.3565 - val_loss: 0.3656\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3551 - val_loss: 0.3645\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.3537 - val_loss: 0.3634\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3523 - val_loss: 0.3623\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3509 - val_loss: 0.3612\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3496 - val_loss: 0.3602\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.3482 - val_loss: 0.3591\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3468 - val_loss: 0.3580\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.3455 - val_loss: 0.3570\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3441 - val_loss: 0.3559\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3428 - val_loss: 0.3549\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3415 - val_loss: 0.3538\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3401 - val_loss: 0.3528\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3388 - val_loss: 0.3517\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.3375 - val_loss: 0.3507\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.3362 - val_loss: 0.3497\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.3349 - val_loss: 0.3486\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3335 - val_loss: 0.3476\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3322 - val_loss: 0.3466\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3309 - val_loss: 0.3455\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3297 - val_loss: 0.3445\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3284 - val_loss: 0.3435\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3271 - val_loss: 0.3425\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3258 - val_loss: 0.3415\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3245 - val_loss: 0.3405\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.3233 - val_loss: 0.3395\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3220 - val_loss: 0.3385\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.3208 - val_loss: 0.3375\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3195 - val_loss: 0.3365\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3183 - val_loss: 0.3355\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3170 - val_loss: 0.3345\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3158 - val_loss: 0.3335\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3145 - val_loss: 0.3325\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3133 - val_loss: 0.3315\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.3121 - val_loss: 0.3306\n",
            "Epoch 786/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3109 - val_loss: 0.3296\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3097 - val_loss: 0.3286\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.3085 - val_loss: 0.3277\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.3073 - val_loss: 0.3267\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.3061 - val_loss: 0.3257\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3049 - val_loss: 0.3248\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.3037 - val_loss: 0.3238\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3025 - val_loss: 0.3229\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3013 - val_loss: 0.3219\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3001 - val_loss: 0.3210\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.2990 - val_loss: 0.3200\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.2978 - val_loss: 0.3191\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.2966 - val_loss: 0.3182\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2955 - val_loss: 0.3172\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2943 - val_loss: 0.3163\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.2932 - val_loss: 0.3154\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2920 - val_loss: 0.3144\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2909 - val_loss: 0.3135\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2898 - val_loss: 0.3126\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2886 - val_loss: 0.3117\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2875 - val_loss: 0.3108\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2864 - val_loss: 0.3099\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2853 - val_loss: 0.3089\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.2842 - val_loss: 0.3080\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2831 - val_loss: 0.3071\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2820 - val_loss: 0.3062\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2809 - val_loss: 0.3053\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.2798 - val_loss: 0.3045\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2787 - val_loss: 0.3036\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2776 - val_loss: 0.3027\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.2765 - val_loss: 0.3018\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2755 - val_loss: 0.3009\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.2744 - val_loss: 0.3000\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.2733 - val_loss: 0.2992\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2722 - val_loss: 0.2983\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.2712 - val_loss: 0.2974\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.2701 - val_loss: 0.2965\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2691 - val_loss: 0.2957\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2680 - val_loss: 0.2948\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2670 - val_loss: 0.2940\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2660 - val_loss: 0.2931\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2649 - val_loss: 0.2922\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2639 - val_loss: 0.2914\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2629 - val_loss: 0.2905\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2619 - val_loss: 0.2897\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2608 - val_loss: 0.2889\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2598 - val_loss: 0.2880\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2588 - val_loss: 0.2872\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.2578 - val_loss: 0.2863\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.2568 - val_loss: 0.2855\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2558 - val_loss: 0.2847\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2548 - val_loss: 0.2839\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2538 - val_loss: 0.2830\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.2529 - val_loss: 0.2822\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2519 - val_loss: 0.2814\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2509 - val_loss: 0.2806\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.2499 - val_loss: 0.2798\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.2490 - val_loss: 0.2790\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2480 - val_loss: 0.2781\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2470 - val_loss: 0.2773\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2461 - val_loss: 0.2765\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2451 - val_loss: 0.2757\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2442 - val_loss: 0.2749\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.2432 - val_loss: 0.2741\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2423 - val_loss: 0.2733\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2414 - val_loss: 0.2726\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2404 - val_loss: 0.2718\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.2395 - val_loss: 0.2710\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2386 - val_loss: 0.2702\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2377 - val_loss: 0.2694\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2367 - val_loss: 0.2686\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.2358 - val_loss: 0.2679\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2349 - val_loss: 0.2671\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2340 - val_loss: 0.2663\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2331 - val_loss: 0.2656\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.2322 - val_loss: 0.2648\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2313 - val_loss: 0.2640\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2304 - val_loss: 0.2633\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2295 - val_loss: 0.2625\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2287 - val_loss: 0.2618\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2278 - val_loss: 0.2610\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.2269 - val_loss: 0.2603\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2260 - val_loss: 0.2595\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2252 - val_loss: 0.2588\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2243 - val_loss: 0.2580\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2234 - val_loss: 0.2573\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2226 - val_loss: 0.2565\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2217 - val_loss: 0.2558\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.2209 - val_loss: 0.2551\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.2200 - val_loss: 0.2543\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2192 - val_loss: 0.2536\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.2183 - val_loss: 0.2529\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2175 - val_loss: 0.2522\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2167 - val_loss: 0.2514\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2158 - val_loss: 0.2507\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.2150 - val_loss: 0.2500\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2142 - val_loss: 0.2493\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2134 - val_loss: 0.2486\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.2126 - val_loss: 0.2479\n",
            "Epoch 885/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2117 - val_loss: 0.2472\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2109 - val_loss: 0.2464\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.2101 - val_loss: 0.2457\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2093 - val_loss: 0.2450\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2085 - val_loss: 0.2443\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2077 - val_loss: 0.2436\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2069 - val_loss: 0.2430\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2061 - val_loss: 0.2423\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2054 - val_loss: 0.2416\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2046 - val_loss: 0.2409\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2038 - val_loss: 0.2402\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2030 - val_loss: 0.2395\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2023 - val_loss: 0.2388\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2015 - val_loss: 0.2382\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2007 - val_loss: 0.2375\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2000 - val_loss: 0.2368\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.1992 - val_loss: 0.2361\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.1984 - val_loss: 0.2355\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1977 - val_loss: 0.2348\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1969 - val_loss: 0.2341\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1962 - val_loss: 0.2335\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1954 - val_loss: 0.2328\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1947 - val_loss: 0.2321\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1940 - val_loss: 0.2315\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1932 - val_loss: 0.2308\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1925 - val_loss: 0.2302\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.1918 - val_loss: 0.2295\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1911 - val_loss: 0.2289\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1903 - val_loss: 0.2282\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1896 - val_loss: 0.2276\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1889 - val_loss: 0.2270\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1882 - val_loss: 0.2263\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1875 - val_loss: 0.2257\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1868 - val_loss: 0.2250\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1861 - val_loss: 0.2244\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.1854 - val_loss: 0.2238\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1847 - val_loss: 0.2232\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1840 - val_loss: 0.2225\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1833 - val_loss: 0.2219\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1826 - val_loss: 0.2213\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1819 - val_loss: 0.2207\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.1812 - val_loss: 0.2200\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1806 - val_loss: 0.2194\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1799 - val_loss: 0.2188\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1792 - val_loss: 0.2182\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1785 - val_loss: 0.2176\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1779 - val_loss: 0.2170\n",
            "Epoch 932/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.1772 - val_loss: 0.2164\n",
            "Epoch 933/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1765 - val_loss: 0.2158\n",
            "Epoch 934/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1759 - val_loss: 0.2152\n",
            "Epoch 935/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1752 - val_loss: 0.2146\n",
            "Epoch 936/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1746 - val_loss: 0.2140\n",
            "Epoch 937/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1739 - val_loss: 0.2134\n",
            "Epoch 938/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1733 - val_loss: 0.2128\n",
            "Epoch 939/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.1726 - val_loss: 0.2122\n",
            "Epoch 940/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.1720 - val_loss: 0.2116\n",
            "Epoch 941/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.1713 - val_loss: 0.2110\n",
            "Epoch 942/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1707 - val_loss: 0.2104\n",
            "Epoch 943/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1701 - val_loss: 0.2098\n",
            "Epoch 944/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1694 - val_loss: 0.2092\n",
            "Epoch 945/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1688 - val_loss: 0.2087\n",
            "Epoch 946/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1682 - val_loss: 0.2081\n",
            "Epoch 947/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1676 - val_loss: 0.2075\n",
            "Epoch 948/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1670 - val_loss: 0.2069\n",
            "Epoch 949/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1663 - val_loss: 0.2064\n",
            "Epoch 950/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1657 - val_loss: 0.2058\n",
            "Epoch 951/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1651 - val_loss: 0.2052\n",
            "Epoch 952/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.1645 - val_loss: 0.2046\n",
            "Epoch 953/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1639 - val_loss: 0.2041\n",
            "Epoch 954/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1633 - val_loss: 0.2035\n",
            "Epoch 955/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1627 - val_loss: 0.2029\n",
            "Epoch 956/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1621 - val_loss: 0.2024\n",
            "Epoch 957/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.1615 - val_loss: 0.2018\n",
            "Epoch 958/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1609 - val_loss: 0.2013\n",
            "Epoch 959/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1603 - val_loss: 0.2007\n",
            "Epoch 960/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.1597 - val_loss: 0.2002\n",
            "Epoch 961/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1591 - val_loss: 0.1996\n",
            "Epoch 962/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1586 - val_loss: 0.1991\n",
            "Epoch 963/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1580 - val_loss: 0.1985\n",
            "Epoch 964/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.1574 - val_loss: 0.1980\n",
            "Epoch 965/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1568 - val_loss: 0.1974\n",
            "Epoch 966/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1562 - val_loss: 0.1969\n",
            "Epoch 967/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1557 - val_loss: 0.1963\n",
            "Epoch 968/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1551 - val_loss: 0.1958\n",
            "Epoch 969/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1545 - val_loss: 0.1953\n",
            "Epoch 970/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1540 - val_loss: 0.1947\n",
            "Epoch 971/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1534 - val_loss: 0.1942\n",
            "Epoch 972/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1529 - val_loss: 0.1937\n",
            "Epoch 973/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1523 - val_loss: 0.1931\n",
            "Epoch 974/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1518 - val_loss: 0.1926\n",
            "Epoch 975/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1512 - val_loss: 0.1921\n",
            "Epoch 976/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1507 - val_loss: 0.1916\n",
            "Epoch 977/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1501 - val_loss: 0.1910\n",
            "Epoch 978/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1496 - val_loss: 0.1905\n",
            "Epoch 979/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1490 - val_loss: 0.1900\n",
            "Epoch 980/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1485 - val_loss: 0.1895\n",
            "Epoch 981/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1480 - val_loss: 0.1890\n",
            "Epoch 982/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1474 - val_loss: 0.1884\n",
            "Epoch 983/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1469 - val_loss: 0.1879\n",
            "Epoch 984/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1464 - val_loss: 0.1874\n",
            "Epoch 985/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1458 - val_loss: 0.1869\n",
            "Epoch 986/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1453 - val_loss: 0.1864\n",
            "Epoch 987/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1448 - val_loss: 0.1859\n",
            "Epoch 988/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.1443 - val_loss: 0.1854\n",
            "Epoch 989/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.1437 - val_loss: 0.1849\n",
            "Epoch 990/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1432 - val_loss: 0.1844\n",
            "Epoch 991/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.1427 - val_loss: 0.1839\n",
            "Epoch 992/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1422 - val_loss: 0.1834\n",
            "Epoch 993/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1417 - val_loss: 0.1829\n",
            "Epoch 994/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1412 - val_loss: 0.1824\n",
            "Epoch 995/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1407 - val_loss: 0.1819\n",
            "Epoch 996/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1402 - val_loss: 0.1814\n",
            "Epoch 997/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1397 - val_loss: 0.1809\n",
            "Epoch 998/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.1392 - val_loss: 0.1804\n",
            "Epoch 999/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1387 - val_loss: 0.1800\n",
            "Epoch 1000/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1382 - val_loss: 0.1795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 928
        },
        "id": "P671j-LR01cQ",
        "outputId": "54124a8b-8e41-4481-8fc4-f099d5224360"
      },
      "source": [
        "pd.DataFrame(history1.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "pd.DataFrame(history2.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "pd.DataFrame(history3.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUdx4CGIRdPI"
      },
      "source": [
        "# Predicting the strain energy outputs for the I, II inputs\n",
        "results = model.predict([I_ut, II_ut])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OD-WeKFwEq1"
      },
      "source": [
        "#Getting the Stress Values from the Strain Energy Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_78KsoCvz2HM"
      },
      "source": [
        "# Return the Second Piola Kirchhoff Stress\n",
        "batch_size = C_ut.shape[0]\n",
        "S_ut = tf.Variable(tf.zeros([batch_size, 3, 3]))\n",
        "S_ebt = tf.Variable(tf.zeros([batch_size, 3, 3]))\n",
        "S_ps = tf.Variable(tf.zeros([batch_size, 3, 3]))\n",
        "\n",
        "for i in range(0, batch_size):\n",
        "  S_ut[i,:,:].assign(second_Piola_Kirchhoff_stress(psi_ut[i], C_ut[i,:,:]))\n",
        "  S_ebt[i,:,:].assign(second_Piola_Kirchhoff_stress(psi_ebt[i], C_ebt[i,:,:]))\n",
        "  S_ps[i,:,:].assign(second_Piola_Kirchhoff_stress(psi_ebt[i], C_ebt[i,:,:]))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1lcbD3Ihjtr"
      },
      "source": [
        "# First Piola-Kirchhoff Stress\n",
        "P_ut = first_Piola_Kirchhoff_stress(S_ut, UT)\n",
        "P_ebt = first_Piola_Kirchhoff_stress(S_ebt, EBT)\n",
        "P_ps = first_Piola_Kirchhoff_stress(S_ps, PS)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "za0_272LlphX",
        "outputId": "016ce9fe-361a-463a-ff73-86e7ea0dc3f2"
      },
      "source": [
        "# Getting the values for P11\n",
        "P11_ut = P_ut[:,0,0]\n",
        "P11_ebt = P_ebt[:,0,0]\n",
        "P11_ps = P_ps[:,0,0]\n",
        "print(P11_ut)\n",
        "print(P11_ebt)\n",
        "print(P11_ps)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[1.0658603  0.8414261  1.171297   0.9861523  3.461773   3.3265383\n",
            " 1.4641339  0.97686464 1.4088945  0.7588134  0.5246003  1.3738366\n",
            " 0.87670904 0.8392835  0.99456155], shape=(15,), dtype=float32)\n",
            "tf.Tensor(\n",
            "[ 2.3109348  1.2789661  2.9662473  1.8812209 15.836295  15.217662\n",
            "  4.977878   1.835593   4.5969825  1.0291852  0.5608648  4.3537564\n",
            "  1.4049664  1.2717133  1.9233639], shape=(15,), dtype=float32)\n",
            "tf.Tensor(\n",
            "[ 2.3109348  1.2789661  2.9662473  1.8812209 15.836295  15.217662\n",
            "  4.977878   1.835593   4.5969825  1.0291852  0.5608648  4.3537564\n",
            "  1.4049664  1.2717133  1.9233639], shape=(15,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "Bd-Gob2ipE8F",
        "outputId": "8e4c8eda-f09b-416a-adaf-bc857cbfa3a5"
      },
      "source": [
        "# Plot P11 vs Stretch for all three types of deformations\n",
        "plt.scatter(stretch, P11_ut, s=15, color=\"blue\", marker=\"s\", label=\"UT\")\n",
        "plt.scatter(stretch, P11_ebt, s=15, color=\"green\", marker=\"o\", label=\"EBT\")\n",
        "plt.scatter(stretch, P11_ps, s=15, color=\"red\", marker=\"x\", label=\"PS\")\n",
        "plt.xlabel(\"Stretch λ\")\n",
        "plt.ylabel(\"P11\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# EBT and PS are almost coinciding in their plots so only one can be seen"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMgAG-3BpHfW"
      },
      "source": [
        "**Predicted Stress Values by Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsH2RHapwoVr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6bf4186-8d0e-42fc-b67a-ee4e7c81e913"
      },
      "source": [
        "#Predicting the Stress Values on the entire DataSet\n",
        "\n",
        "psi_ut_pred = model.predict([I_ut_scaled, II_ut_scaled]).reshape(batch_size)\n",
        "psi_ebt_pred = model.predict([I_ebt_scaled, II_ebt_scaled]).reshape(batch_size)\n",
        "psi_ps_pred = model.predict([I_ps_scaled, II_ps_scaled]).reshape(batch_size)\n",
        "print(psi_ut_pred)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.0578259  0.5819645  1.3348998  0.86403394 4.9130597  4.7973504\n",
            " 2.0821378  0.8429365  1.9421042  0.46952164 0.31880963 1.8576902\n",
            " 0.64093006 0.5785965  0.8834394 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cybNwAUPyzrd"
      },
      "source": [
        "# Getting the stress values for the predicted strain energy values\n",
        "# Return the Second Piola Kirchhoff Stress\n",
        "batch_size = C_ut.shape[0]\n",
        "S_ut_pred = tf.Variable(tf.zeros([batch_size, 3, 3]))\n",
        "S_ebt_pred = tf.Variable(tf.zeros([batch_size, 3, 3]))\n",
        "S_ps_pred = tf.Variable(tf.zeros([batch_size, 3, 3]))\n",
        "\n",
        "for i in range(0, batch_size):\n",
        "  S_ut_pred[i,:,:].assign(second_Piola_Kirchhoff_stress(psi_ut_pred[i], C_ut[i,:,:]))\n",
        "  S_ebt_pred[i,:,:].assign(second_Piola_Kirchhoff_stress(psi_ebt_pred[i], C_ebt[i,:,:]))\n",
        "  S_ps_pred[i,:,:].assign(second_Piola_Kirchhoff_stress(psi_ebt_pred[i], C_ebt[i,:,:]))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiM5Ukcm1hHU"
      },
      "source": [
        "# Getting the First Piola-Kirchhoff Stress for predicted strain energy values\n",
        "P_ut_pred = first_Piola_Kirchhoff_stress(S_ut_pred, UT)\n",
        "P_ebt_pred = first_Piola_Kirchhoff_stress(S_ebt_pred, EBT)\n",
        "P_ps_pred = first_Piola_Kirchhoff_stress(S_ps_pred, PS)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6DhnujwrvC_",
        "outputId": "f6b798c8-c207-4a43-eca7-d47724ce7256"
      },
      "source": [
        "# Getting the values for P11 for generated strain energy values\n",
        "P11_ut_pred = P_ut_pred[:,0,0]\n",
        "P11_ebt_pred = P_ebt_pred[:,0,0]\n",
        "P11_ps_pred = P_ps_pred[:,0,0]\n",
        "print(P11_ut_pred)\n",
        "print(P11_ebt_pred)\n",
        "print(P11_ps_pred)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[1.0658603  0.8414261  1.171297   0.9861523  3.461773   3.3265383\n",
            " 1.4641339  0.97686464 1.4088945  0.7588134  0.5246003  1.3738366\n",
            " 0.87670904 0.8392835  0.99456155], shape=(15,), dtype=float32)\n",
            "tf.Tensor(\n",
            "[ 2.3109348  1.2789661  2.9662473  1.8812209 15.836295  15.217662\n",
            "  4.977878   1.835593   4.5969825  1.0291852  0.5608648  4.3537564\n",
            "  1.4049664  1.2717133  1.9233639], shape=(15,), dtype=float32)\n",
            "tf.Tensor(\n",
            "[ 2.3109348  1.2789661  2.9662473  1.8812209 15.836295  15.217662\n",
            "  4.977878   1.835593   4.5969825  1.0291852  0.5608648  4.3537564\n",
            "  1.4049664  1.2717133  1.9233639], shape=(15,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "ugC3UMvRr9B6",
        "outputId": "d7d734b9-fddc-4c9d-dbbd-87a9b98f77a4"
      },
      "source": [
        "# Plot P11 vs Stretch for all three types of deformations\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(stretch.numpy(), P11_ut_pred.numpy(), color=\"blue\", linestyle=\"solid\", label=\"UT_pred\")\n",
        "plt.plot(stretch.numpy(), P11_ebt_pred.numpy(), color=\"green\", linestyle=\"solid\", label=\"EBT_pred\")\n",
        "plt.plot(stretch.numpy(), P11_ps_pred.numpy(), color=\"red\", linestyle=\"solid\", label=\"PS_pred\")\n",
        "\n",
        "# The previous Graph showing actual values\n",
        "# Plot P11 vs Stretch for all three types of deformations\n",
        "plt.scatter(stretch, P11_ut, s=20, color=\"blue\", marker=\"s\", label=\"UT\")\n",
        "plt.scatter(stretch, P11_ebt, s=20, color=\"green\", marker=\"o\", label=\"EBT\")\n",
        "plt.scatter(stretch, P11_ps, s=20, color=\"red\", marker=\"x\", label=\"PS\")\n",
        "plt.xlabel(\"Stretch λ\")\n",
        "plt.ylabel(\"P11\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}