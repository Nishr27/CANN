{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CANN for Mooney-Rivlin material.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOAf6wX7T3yIqXCJ7pFUxye",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nishr27/CANN/blob/main/CANN_for_Mooney_Rivlin_material.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXC1YvLfDGXd"
      },
      "source": [
        "#Generating Training and Test Data for CANN\n",
        "\n",
        "We start by preparing data according to the Mooney-Rivlin model using the following equation, for generating the strain energy function:\n",
        "\n",
        "- psi = ci0*(I - 3)**i + c0i*(II - 3)**i\n",
        "we have the material parameters given as per the Table 1 in the research paper Linka et al.\n",
        "\n",
        "We write the functions that are used throughout the program. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgvoRLNMGNoa"
      },
      "source": [
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.preprocessing as StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPk0qeSLntuM"
      },
      "source": [
        "def deformation_gradient(batch_size):\n",
        "  \"\"\"\n",
        "  Returns the Deformation Gradients generated for three types of loading: Uniaxial Tension Loading, Equi-Biaxial Loading and Pure Shear Loading\n",
        "\n",
        "  \"\"\"\n",
        "  # Generating random stretch values between 1 to 7\n",
        "  #stretch = tf.random.uniform(shape=[batch_size], minval=1, maxval=7, dtype=tf.float32, seed=42)\n",
        "  stretch = tf.Variable(np.linspace(1.2, 7.0, num=batch_size, endpoint=True, dtype=np.float32))\n",
        "  sqrt_stretch = tf.math.sqrt(stretch)\n",
        "  stretch_sqr = tf.math.square(stretch)\n",
        "\n",
        "  # Deformation Gradient for Uniform Tension Loading\n",
        "  uniform_tension = tf.Variable(tf.zeros(shape=[batch_size, 3, 3]))\n",
        "  for i in range(0, batch_size):\n",
        "    uniform_tension[i, 0, 0].assign(stretch[i])\n",
        "    uniform_tension[i, 1, 1].assign(1/sqrt_stretch[i])\n",
        "    uniform_tension[i, 2, 2].assign(1/sqrt_stretch[i])\n",
        "  \n",
        "  # Deformation Gradient for Equi-Biaxial Loading\n",
        "  eq_biaxial = tf.Variable(tf.zeros(shape=[batch_size, 3, 3]))\n",
        "  for i in range(0, batch_size):\n",
        "    eq_biaxial[i, 0, 0].assign(stretch[i])\n",
        "    eq_biaxial[i, 1, 1].assign(stretch[i])\n",
        "    eq_biaxial[i, 2, 2].assign(1/stretch_sqr[i])\n",
        "  \n",
        "  # Deformation Gradient for Pure Shear Loading\n",
        "  pure_shear = tf.Variable(tf.eye(3, batch_shape=[batch_size], dtype=tf.float32))\n",
        "  for i in range(0, batch_size):\n",
        "    pure_shear[i, 0, 0].assign(stretch[i])\n",
        "    pure_shear[i, 1, 1].assign(1/stretch[i])\n",
        "  \n",
        "  return uniform_tension, eq_biaxial, pure_shear, stretch  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRWii-tSEUA8"
      },
      "source": [
        "def strain_energy(first_inv, second_inv):\n",
        "  \"\"\" \n",
        "  This function provides the strain energy function based on the Mooney-Rivlin rule, given the first and second strain invariants (Ic and IIc).\n",
        "  We also define the material constants ci0 and c0i here.\n",
        "  This can then be used for training the CANN using the invariants as inputs and the energy function as the label for a certain pair of invariants.\n",
        "\n",
        "  \"\"\"\n",
        "  # Material Constants\n",
        "  ci0 = tf.constant([1.6e-1, -1.4e-3, 3.9e-5])\n",
        "  c0i = tf.constant([1.5e-2, -2.0e-6, 1.0e-10])\n",
        "  \n",
        "  # Getting the batch size for the data\n",
        "  batch_size = first_inv.shape[0]\n",
        "\n",
        "  # Initializing the psi function with zeros\n",
        "  psi = tf.Variable(tf.zeros(batch_size))\n",
        "\n",
        "  # Calculation of strain energy function\n",
        "  for i in range(0, batch_size):\n",
        "    sum = 0\n",
        "    \n",
        "    for j in range(0, 3):\n",
        "      sum = sum + ci0[j] * ((first_inv[i] - 3)**(j+1)) + c0i[j] * ((second_inv[i] - 3)**(j+1))\n",
        "\n",
        "    psi[i].assign(sum)\n",
        "\n",
        "  # Return the calculated energy function\n",
        "  return psi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWN613gDJ4NW"
      },
      "source": [
        "def right_Cauchy_Green_tensor(def_gradient):\n",
        "  \"\"\"\n",
        "  Function formulates the right Cauchy-Green Tensor from the Deformation Gradient\n",
        "  \n",
        "  \"\"\"\n",
        "  # Right Cauchy-Green Tensor C from Deformation Gradient\n",
        "  C = tf.linalg.matmul(def_gradient, def_gradient, transpose_a=True)\n",
        "\n",
        "  return C"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5FG5hesQVTf"
      },
      "source": [
        "def strain_invariants(C):\n",
        "  \"\"\" \n",
        "  This function calculates the strain/stress invariants given the right Cauchy-Green Tensor.\n",
        "  \n",
        "  \"\"\"\n",
        "  # First Strain Invariant\n",
        "  first_inv = tf.linalg.trace(C)\n",
        "\n",
        "  # Second Strain Invariant\n",
        "  second_inv = 0.5*((tf.math.square(first_inv)) - tf.linalg.trace(tf.linalg.matmul(C, C, transpose_a=True)))\n",
        "\n",
        "  return first_inv, second_inv  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7uUzq53SgG0"
      },
      "source": [
        "def second_Piola_Kirchhoff_stress(psi, C):\n",
        "  \"\"\"\n",
        "  This function calculate the second Piola-Kirchhoff stress by taking the Gradient of the strain energy w.r.t right Cauchy Green Tensor\n",
        "  \n",
        "  \"\"\"\n",
        "  with tf.GradientTape() as tape:\n",
        "    tape.watch(C)\n",
        "    I = tf.linalg.trace(C)\n",
        "    II = 0.5*( (tf.linalg.trace(C)**2) - (tf.linalg.trace(tf.linalg.matmul(C, C, transpose_a=True))) )\n",
        "    psi = 1.6e-1*(I - 3) + 1.5e-2*(II - 3) + (-1.4e-3)*((I - 3)**2) + (-2.0e-6)*((II - 3)**2) + (3.9e-5)*((I - 3)**3) + (1.0e-10)*((II - 3)**3)\n",
        "\n",
        "  return 2*tape.gradient(psi, C)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ3VYEcOnqKF"
      },
      "source": [
        "def first_Piola_Kirchhoff_stress(S, def_grad):\n",
        "  \"\"\"\n",
        "  This function returns the first Piola-Kirchhoff (nominal) stress by multiplying the Deformation Gradient and the second Piola-Kirchhoff stress\n",
        "  \"\"\"\n",
        "  return tf.linalg.matmul(def_grad, S)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owlp1BwCEnVh"
      },
      "source": [
        "def standard_scaling(first_inv, second_inv):\n",
        "  from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "  first_inv_scaled = scaler.fit_transform(first_inv)\n",
        "  second_inv_scaled = scaler.transform(second_inv)\n",
        "\n",
        "  return first_inv_scaled, second_inv_scaled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jzr5AsDryc-e"
      },
      "source": [
        "def split_train_test(first_inv, second_inv, psi):\n",
        "  \"\"\" \n",
        "  Splitting the Strain invariant data into Training and Test Sets with a Test size of 0.2\n",
        "  \"\"\"\n",
        "  np.random.seed(42)\n",
        "  shuffled_indices = np.random.permutation(first_inv.shape[0])\n",
        "  test_set_size = int(first_inv.shape[0] * 0.2)\n",
        "  test_indices = shuffled_indices[:test_set_size]\n",
        "  train_indices = shuffled_indices[test_set_size:]\n",
        "\n",
        "  return tf.gather(first_inv, train_indices), tf.gather(first_inv, test_indices), tf.gather(second_inv, train_indices), tf.gather(second_inv, test_indices), tf.gather(psi, train_indices), tf.gather(psi, test_indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEcaW3uC5_rs"
      },
      "source": [
        "def CANN_model():\n",
        "  \"\"\"\n",
        "  ANN Model \n",
        "  \n",
        "  \"\"\"  \n",
        "  I = keras.layers.Input(shape=[1], name=\"I\")\n",
        "  II = keras.layers.Input(shape=[1],name=\"II\")\n",
        "  concat = keras.layers.concatenate([I, II])\n",
        "  hidden0 = keras.layers.Dense(10, activation=\"relu\")(concat)\n",
        "  Psi = keras.layers.Dense(1, activation=\"relu\", name=\"Psi\")(hidden0)\n",
        "\n",
        "  model = keras.models.Model(inputs=[I, II], outputs=[Psi])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIJe8d7WmFZ3"
      },
      "source": [
        "#Body of the Main Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jBgU1-q_mPb"
      },
      "source": [
        "**Generating the Deformation gradient values for the three load cases**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUiThq52l1FS",
        "outputId": "795ec833-e513-445e-e197-57d98fcef928"
      },
      "source": [
        "# Setting the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Generating deformation gradients for the various load cases: Uniaxial Tension (UT), Equi-biaxial Tension (EBT) and Pure Shear (PS)\n",
        "# Also returning the stretches \n",
        "UT, EBT, PS, stretch = deformation_gradient(15)\n",
        "\n",
        "# Checking the examples generated\n",
        "print(\"Examples of the Deformation Gradients generated are: \\n\\n UT = \", UT[0], \"\\n\\n EBT = \", EBT[0], \"\\n\\n PS = \", PS[0], \"\\n\\n Stretch = \", stretch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples of the Deformation Gradients generated are: \n",
            "\n",
            " UT =  tf.Tensor(\n",
            "[[1.2       0.        0.       ]\n",
            " [0.        0.9128709 0.       ]\n",
            " [0.        0.        0.9128709]], shape=(3, 3), dtype=float32) \n",
            "\n",
            " EBT =  tf.Tensor(\n",
            "[[1.2       0.        0.       ]\n",
            " [0.        1.2       0.       ]\n",
            " [0.        0.        0.6944444]], shape=(3, 3), dtype=float32) \n",
            "\n",
            " PS =  tf.Tensor(\n",
            "[[1.2       0.        0.       ]\n",
            " [0.        0.8333333 0.       ]\n",
            " [0.        0.        1.       ]], shape=(3, 3), dtype=float32) \n",
            "\n",
            " Stretch =  <tf.Variable 'Variable:0' shape=(15,) dtype=float32, numpy=\n",
            "array([1.2      , 1.6142857, 2.0285714, 2.442857 , 2.857143 , 3.2714286,\n",
            "       3.6857142, 4.1      , 4.5142856, 4.928571 , 5.3428574, 5.757143 ,\n",
            "       6.1714287, 6.5857143, 7.       ], dtype=float32)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpSqRCzWqQXe"
      },
      "source": [
        "**Calculating the strain invariants from the generated deformation gradients**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUfnBHXMLtrw",
        "outputId": "5b4cd773-108e-4ba3-f8f9-a68f3a634902"
      },
      "source": [
        "# Right Cauchy-Green Tensor from the Deformation Gradient\n",
        "C_ut = right_Cauchy_Green_tensor(UT)\n",
        "C_ebt = right_Cauchy_Green_tensor(EBT)\n",
        "C_ps = right_Cauchy_Green_tensor(PS)\n",
        "\n",
        "print(\"Right Cauchy Green Tensors: \\n\\n UT = \", C_ut[0], \"\\n\\n EBT = \", C_ebt[0], \"\\n\\n PS = \", C_ps[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Right Cauchy Green Tensors: \n",
            "\n",
            " UT =  tf.Tensor(\n",
            "[[1.44       0.         0.        ]\n",
            " [0.         0.83333325 0.        ]\n",
            " [0.         0.         0.83333325]], shape=(3, 3), dtype=float32) \n",
            "\n",
            " EBT =  tf.Tensor(\n",
            "[[1.44       0.         0.        ]\n",
            " [0.         1.44       0.        ]\n",
            " [0.         0.         0.48225304]], shape=(3, 3), dtype=float32) \n",
            "\n",
            " PS =  tf.Tensor(\n",
            "[[1.44      0.        0.       ]\n",
            " [0.        0.6944444 0.       ]\n",
            " [0.        0.        1.       ]], shape=(3, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5nxCoFg_07w",
        "outputId": "4d2e9303-5193-4408-9b87-f7de17da18f4"
      },
      "source": [
        "# Strain Invariants for the three cases\n",
        "I_ut, II_ut = strain_invariants(C_ut) \n",
        "I_ebt, II_ebt = strain_invariants(C_ebt)\n",
        "I_ps, II_ps = strain_invariants(C_ps)\n",
        "\n",
        "# Examples of the strain invariants \n",
        "print(\"Strain Invariants for Uniaxial Tension: \\n\\n First Invariant = \", I_ut, \"\\n\\n Second Invariant = \", II_ut, \"\\n\\n\")\n",
        "print(\"Strain Invariants for Equi-Biaxial Tension: \\n\\n First Invariant = \", I_ebt, \"\\n\\n Second Invariant = \", II_ebt, \"\\n\\n\")\n",
        "print(\"Strain Invariants for Pure Shear: \\n\\n First Invariant = \", I_ps, \"\\n\\n Second Invariant = \", II_ps, \"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Strain Invariants for Uniaxial Tension: \n",
            "\n",
            " First Invariant =  tf.Tensor(\n",
            "[ 3.1066666  3.8448563  5.101017   6.7862635  8.863266  11.313599\n",
            " 14.127125  17.297804  20.821814  24.69661   28.920458  33.492092\n",
            " 38.410606  43.67532   49.285713 ], shape=(15,), dtype=float32) \n",
            "\n",
            " Second Invariant =  tf.Tensor(\n",
            "[ 3.094444   3.6123128  4.300148   5.0532856  5.836796   6.636299\n",
            "  7.445038   8.259491   9.077652   9.898315  10.720764  11.544556\n",
            " 12.36908   13.194519  14.020264 ], shape=(15,), dtype=float32) \n",
            "\n",
            "\n",
            "Strain Invariants for Equi-Biaxial Tension: \n",
            "\n",
            " First Invariant =  tf.Tensor(\n",
            "[ 3.3622532  5.3590946  8.289256  11.9631815 16.341537  21.41322\n",
            " 27.174398  33.62354   40.759956  48.58332   57.09348   66.2903\n",
            " 76.17375   86.7438    98.00042  ], shape=(15,), dtype=float32) \n",
            "\n",
            " Second Invariant =  tf.Tensor(\n",
            "[   3.4624894    7.5582943   17.420078    35.946804    66.8839\n",
            "  114.72491    184.6856     282.6951     415.39255    590.1259\n",
            "  814.95135   1098.6311    1450.6362    1881.1448    2401.041    ], shape=(15,), dtype=float32) \n",
            "\n",
            "\n",
            "Strain Invariants for Pure Shear: \n",
            "\n",
            " First Invariant =  tf.Tensor(\n",
            "[ 3.1344445  3.9896603  5.358109   7.1351233  9.285766  11.795683\n",
            " 14.658103  17.869488  21.427845  25.331982  29.581156  34.174866\n",
            " 39.11279   44.394688  50.02041  ], shape=(15,), dtype=float32) \n",
            "\n",
            " Second Invariant =  tf.Tensor(\n",
            "[ 3.1344447  3.9896603  5.3581076  7.135124   9.285767  11.795685\n",
            " 14.658104  17.869492  21.427826  25.33197   29.581146  34.174866\n",
            " 39.112793  44.394714  50.020386 ], shape=(15,), dtype=float32) \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yKeZFMBBDLR"
      },
      "source": [
        "**Calculating the Strain Energy Function from the Strain Invariants**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTTY2yRjDFTt",
        "outputId": "93ffba4a-d031-4a0a-e168-1adea6e03c68"
      },
      "source": [
        "# Strain Invariants for the three cases\n",
        "psi_ut = strain_energy(I_ut, II_ut)\n",
        "psi_ebt = strain_energy(I_ebt, II_ebt)\n",
        "psi_ps = strain_energy(I_ps, II_ps)\n",
        "\n",
        "print(\"Strain Energy Functions for UT, EBT and PS are: \\n\\n UT = \", psi_ut[0], \"\\n\\n EBT = \", psi_ebt[0], \"\\n\\n PS = \", psi_ps[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Strain Energy Functions for UT, EBT and PS are: \n",
            "\n",
            " UT =  tf.Tensor(0.01846741, shape=(), dtype=float32) \n",
            "\n",
            " EBT =  tf.Tensor(0.064715564, shape=(), dtype=float32) \n",
            "\n",
            " PS =  tf.Tensor(0.02350254, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90NyM20q3yDb"
      },
      "source": [
        "# Neural Network Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRsm3CLoh5-8"
      },
      "source": [
        "**Preparing Training and Test sets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u40Ecslt12ng",
        "outputId": "e31d3612-b949-4609-db60-b9f23b7820a0"
      },
      "source": [
        "# Plotting the Invariant plane (I-II plane)\n",
        "plt.scatter(I_ut[:5], II_ut[:5], color=\"blue\", marker=\"s\", label=\"UT\")\n",
        "plt.scatter(I_ebt[:5], II_ebt[:5], color=\"cyan\", marker=\"o\", label=\"EBT\")\n",
        "plt.scatter(I_ps[:5], II_ps[:5], color=\"red\", marker=\"x\", label=\"PS\")\n",
        "plt.xlabel(\"Ic\")\n",
        "plt.ylabel(\"IIc\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "kBByENmgRnm7",
        "outputId": "ee1585b7-23db-4387-94d9-1041868e1533"
      },
      "source": [
        "plt.scatter(I_ut, psi_ut, label=\"I\")\n",
        "plt.scatter(II_ut, psi_ut, label=\"II\")\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7faa19386b90>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mu8IJJTAFciI"
      },
      "source": [
        "I_ut_scaled, II_ut_scaled = standard_scaling(I_ut.numpy().reshape(-1,1), II_ut.numpy().reshape(-1,1))\n",
        "\n",
        "I_ebt_scaled, II_ebt_scaled = standard_scaling(I_ebt.numpy().reshape(-1,1), II_ebt.numpy().reshape(-1,1))\n",
        "\n",
        "I_ps_scaled, II_ps_scaled = standard_scaling(I_ps.numpy().reshape(-1, 1), II_ps.numpy().reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19PET9_FuwIT"
      },
      "source": [
        "I_ut_train, I_ut_test, II_ut_train, II_ut_test, psi_ut_train, psi_ut_test = split_train_test(I_ut_scaled, II_ut_scaled, psi_ut)\n",
        "\n",
        "I_ebt_train, I_ebt_test, II_ebt_train, II_ebt_test, psi_ebt_train, psi_ebt_test = split_train_test(I_ebt, II_ebt, psi_ebt)\n",
        "\n",
        "I_ps_train, I_ps_test, II_ps_train, II_ps_test, psi_ps_train, psi_ps_test = split_train_test(I_ps, II_ps, psi_ps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-rt8LdryPsR"
      },
      "source": [
        "**Building the Neural Network Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8uSd0di3ohR"
      },
      "source": [
        "model = CANN_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "UGYkusXg6p5r",
        "outputId": "f051d1ed-1cc9-4ba3-8b00-34bc34d31a97"
      },
      "source": [
        "# Checking the construction of the Neural Network\n",
        "# Activation functions used in all layers are \"ReLU\"\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cD5UO3Rd7Jaf"
      },
      "source": [
        "# Compiling the Model\n",
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.Adam(learning_rate=0.001))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjplMXfRyYQt",
        "outputId": "c49ee526-8d57-4b72-93b9-ee6157b03b16"
      },
      "source": [
        "I_all = tf.concat([I_ut, I_ebt], axis=0)\n",
        "print(I_ut_test)\n",
        "print(I_ebt_test)\n",
        "I = tf.reshape(I_ut_test, (3,))\n",
        "print(I)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 0.27624863]\n",
            " [ 0.87661994]\n",
            " [-1.1974604 ]], shape=(3, 1), dtype=float32)\n",
            "tf.Tensor([48.58332   66.2903     3.3622532], shape=(3,), dtype=float32)\n",
            "tf.Tensor([ 0.27624863  0.87661994 -1.1974604 ], shape=(3,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-g3-t8dJ8CMq",
        "outputId": "09fa4868-1264-4f96-d2a0-449442c76d1c"
      },
      "source": [
        "# Training the Model on the prepared data\n",
        "history1 = model.fit([I_ut_train, II_ut_train], psi_ut_train, epochs=1000, validation_data=([I_ut_test, II_ut_test], psi_ut_test))\n",
        "\n",
        "history2 = model.fit([I_ebt_train, II_ebt_train], psi_ebt_train, epochs=1000, validation_data=([I_ebt_test, II_ebt_test], psi_ebt_test))\n",
        "\n",
        "history3 = model.fit([I_ps_train, II_ps_train], psi_ps_train, epochs=1000, validation_data=([I_ps_test, II_ps_test], psi_ps_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0801 - val_loss: 0.1402\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0798 - val_loss: 0.1404\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0795 - val_loss: 0.1406\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0792 - val_loss: 0.1409\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0789 - val_loss: 0.1411\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0786 - val_loss: 0.1414\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0783 - val_loss: 0.1416\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0781 - val_loss: 0.1419\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0778 - val_loss: 0.1421\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0776 - val_loss: 0.1423\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0773 - val_loss: 0.1425\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0771 - val_loss: 0.1428\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0768 - val_loss: 0.1430\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0766 - val_loss: 0.1432\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0764 - val_loss: 0.1434\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0762 - val_loss: 0.1437\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0760 - val_loss: 0.1439\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0757 - val_loss: 0.1441\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0755 - val_loss: 0.1443\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0753 - val_loss: 0.1445\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0752 - val_loss: 0.1447\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0750 - val_loss: 0.1449\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0748 - val_loss: 0.1451\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0746 - val_loss: 0.1453\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0744 - val_loss: 0.1455\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0743 - val_loss: 0.1457\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0741 - val_loss: 0.1459\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0739 - val_loss: 0.1460\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0738 - val_loss: 0.1462\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0736 - val_loss: 0.1464\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0735 - val_loss: 0.1466\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0733 - val_loss: 0.1467\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0732 - val_loss: 0.1469\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0730 - val_loss: 0.1471\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0729 - val_loss: 0.1472\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0728 - val_loss: 0.1474\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0726 - val_loss: 0.1476\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0725 - val_loss: 0.1477\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0724 - val_loss: 0.1479\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0722 - val_loss: 0.1480\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0721 - val_loss: 0.1482\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0720 - val_loss: 0.1483\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0719 - val_loss: 0.1484\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0718 - val_loss: 0.1486\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0717 - val_loss: 0.1487\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0716 - val_loss: 0.1489\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0715 - val_loss: 0.1490\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0714 - val_loss: 0.1491\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0713 - val_loss: 0.1492\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0712 - val_loss: 0.1493\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0711 - val_loss: 0.1495\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0710 - val_loss: 0.1496\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0709 - val_loss: 0.1497\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0708 - val_loss: 0.1498\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0707 - val_loss: 0.1499\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0706 - val_loss: 0.1500\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0705 - val_loss: 0.1501\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0705 - val_loss: 0.1502\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0704 - val_loss: 0.1503\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0703 - val_loss: 0.1504\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0702 - val_loss: 0.1505\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0701 - val_loss: 0.1506\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0701 - val_loss: 0.1507\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0700 - val_loss: 0.1507\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0699 - val_loss: 0.1508\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0699 - val_loss: 0.1509\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0698 - val_loss: 0.1510\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0697 - val_loss: 0.1510\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0697 - val_loss: 0.1511\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0696 - val_loss: 0.1512\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0695 - val_loss: 0.1512\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0695 - val_loss: 0.1513\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0694 - val_loss: 0.1513\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0693 - val_loss: 0.1514\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0693 - val_loss: 0.1515\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0692 - val_loss: 0.1515\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0692 - val_loss: 0.1516\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0691 - val_loss: 0.1516\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0691 - val_loss: 0.1517\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0690 - val_loss: 0.1517\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0689 - val_loss: 0.1517\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0689 - val_loss: 0.1518\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0688 - val_loss: 0.1518\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0688 - val_loss: 0.1518\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0687 - val_loss: 0.1519\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0687 - val_loss: 0.1519\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0686 - val_loss: 0.1519\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0686 - val_loss: 0.1519\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0685 - val_loss: 0.1520\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0685 - val_loss: 0.1520\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0684 - val_loss: 0.1520\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0684 - val_loss: 0.1520\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0684 - val_loss: 0.1520\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0683 - val_loss: 0.1521\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0683 - val_loss: 0.1521\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0682 - val_loss: 0.1521\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0682 - val_loss: 0.1521\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0681 - val_loss: 0.1521\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0681 - val_loss: 0.1521\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0681 - val_loss: 0.1521\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0680 - val_loss: 0.1521\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0680 - val_loss: 0.1521\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0679 - val_loss: 0.1521\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0679 - val_loss: 0.1521\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0679 - val_loss: 0.1521\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0678 - val_loss: 0.1521\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0678 - val_loss: 0.1520\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0677 - val_loss: 0.1520\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0677 - val_loss: 0.1520\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0677 - val_loss: 0.1520\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0676 - val_loss: 0.1520\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0676 - val_loss: 0.1520\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0676 - val_loss: 0.1520\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0675 - val_loss: 0.1519\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0675 - val_loss: 0.1519\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0675 - val_loss: 0.1519\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0674 - val_loss: 0.1519\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0674 - val_loss: 0.1518\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0674 - val_loss: 0.1518\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0673 - val_loss: 0.1518\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0673 - val_loss: 0.1517\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0673 - val_loss: 0.1517\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0672 - val_loss: 0.1517\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0672 - val_loss: 0.1516\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0672 - val_loss: 0.1516\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0671 - val_loss: 0.1516\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0671 - val_loss: 0.1515\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0671 - val_loss: 0.1515\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0670 - val_loss: 0.1514\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0670 - val_loss: 0.1514\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0670 - val_loss: 0.1513\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0669 - val_loss: 0.1513\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0669 - val_loss: 0.1513\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0669 - val_loss: 0.1512\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0668 - val_loss: 0.1512\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0668 - val_loss: 0.1511\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0668 - val_loss: 0.1511\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0667 - val_loss: 0.1510\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0667 - val_loss: 0.1510\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0667 - val_loss: 0.1509\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0667 - val_loss: 0.1508\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0666 - val_loss: 0.1508\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0666 - val_loss: 0.1507\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0666 - val_loss: 0.1507\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0665 - val_loss: 0.1506\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0665 - val_loss: 0.1506\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0665 - val_loss: 0.1505\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0664 - val_loss: 0.1504\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0664 - val_loss: 0.1504\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0664 - val_loss: 0.1503\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0664 - val_loss: 0.1503\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0663 - val_loss: 0.1502\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0663 - val_loss: 0.1501\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0663 - val_loss: 0.1501\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0662 - val_loss: 0.1500\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0662 - val_loss: 0.1499\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0662 - val_loss: 0.1499\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0662 - val_loss: 0.1498\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0661 - val_loss: 0.1497\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0661 - val_loss: 0.1496\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0661 - val_loss: 0.1496\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0660 - val_loss: 0.1495\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0660 - val_loss: 0.1494\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0660 - val_loss: 0.1494\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0660 - val_loss: 0.1493\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0659 - val_loss: 0.1492\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0659 - val_loss: 0.1491\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0659 - val_loss: 0.1491\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0659 - val_loss: 0.1490\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0658 - val_loss: 0.1489\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0658 - val_loss: 0.1488\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0658 - val_loss: 0.1488\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0657 - val_loss: 0.1487\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0657 - val_loss: 0.1486\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0657 - val_loss: 0.1485\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0657 - val_loss: 0.1484\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0656 - val_loss: 0.1484\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0656 - val_loss: 0.1483\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0656 - val_loss: 0.1482\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0656 - val_loss: 0.1481\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0655 - val_loss: 0.1480\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0655 - val_loss: 0.1479\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0655 - val_loss: 0.1479\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0654 - val_loss: 0.1478\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0654 - val_loss: 0.1477\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0654 - val_loss: 0.1476\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0654 - val_loss: 0.1475\n",
            "Epoch 688/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0653 - val_loss: 0.1474\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0653 - val_loss: 0.1474\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0653 - val_loss: 0.1473\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0653 - val_loss: 0.1472\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0652 - val_loss: 0.1471\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0652 - val_loss: 0.1470\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0652 - val_loss: 0.1469\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0652 - val_loss: 0.1468\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0651 - val_loss: 0.1468\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0651 - val_loss: 0.1467\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0651 - val_loss: 0.1466\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0651 - val_loss: 0.1465\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0650 - val_loss: 0.1464\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0650 - val_loss: 0.1463\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0650 - val_loss: 0.1462\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0649 - val_loss: 0.1461\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0649 - val_loss: 0.1460\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0649 - val_loss: 0.1460\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0649 - val_loss: 0.1459\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0648 - val_loss: 0.1458\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0648 - val_loss: 0.1457\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0648 - val_loss: 0.1456\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0648 - val_loss: 0.1455\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0647 - val_loss: 0.1454\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0647 - val_loss: 0.1453\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0647 - val_loss: 0.1452\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0647 - val_loss: 0.1451\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0646 - val_loss: 0.1450\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0646 - val_loss: 0.1449\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0646 - val_loss: 0.1449\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0646 - val_loss: 0.1448\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0645 - val_loss: 0.1447\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0645 - val_loss: 0.1446\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0645 - val_loss: 0.1445\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0645 - val_loss: 0.1444\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0644 - val_loss: 0.1443\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0644 - val_loss: 0.1442\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0644 - val_loss: 0.1441\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0644 - val_loss: 0.1440\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0643 - val_loss: 0.1439\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0643 - val_loss: 0.1438\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0643 - val_loss: 0.1437\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0642 - val_loss: 0.1436\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0642 - val_loss: 0.1435\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0642 - val_loss: 0.1434\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0642 - val_loss: 0.1434\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0641 - val_loss: 0.1433\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0641 - val_loss: 0.1432\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0641 - val_loss: 0.1431\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0641 - val_loss: 0.1430\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0640 - val_loss: 0.1429\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0640 - val_loss: 0.1428\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0640 - val_loss: 0.1427\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0640 - val_loss: 0.1426\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0639 - val_loss: 0.1425\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0639 - val_loss: 0.1424\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0639 - val_loss: 0.1423\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0639 - val_loss: 0.1422\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0638 - val_loss: 0.1421\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0638 - val_loss: 0.1420\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0638 - val_loss: 0.1419\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0638 - val_loss: 0.1418\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0637 - val_loss: 0.1417\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0637 - val_loss: 0.1416\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0637 - val_loss: 0.1415\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0637 - val_loss: 0.1414\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0636 - val_loss: 0.1414\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0636 - val_loss: 0.1413\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0636 - val_loss: 0.1412\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0636 - val_loss: 0.1411\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0635 - val_loss: 0.1410\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0635 - val_loss: 0.1409\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0635 - val_loss: 0.1408\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0635 - val_loss: 0.1407\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0634 - val_loss: 0.1406\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0634 - val_loss: 0.1405\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0634 - val_loss: 0.1404\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0634 - val_loss: 0.1403\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0633 - val_loss: 0.1402\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0633 - val_loss: 0.1401\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0633 - val_loss: 0.1400\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0633 - val_loss: 0.1399\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0632 - val_loss: 0.1398\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0632 - val_loss: 0.1397\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0632 - val_loss: 0.1396\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0632 - val_loss: 0.1395\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0631 - val_loss: 0.1394\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0631 - val_loss: 0.1393\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0631 - val_loss: 0.1392\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0631 - val_loss: 0.1392\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0630 - val_loss: 0.1391\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0630 - val_loss: 0.1390\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0630 - val_loss: 0.1389\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0630 - val_loss: 0.1388\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0629 - val_loss: 0.1387\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0629 - val_loss: 0.1386\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0629 - val_loss: 0.1385\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0629 - val_loss: 0.1384\n",
            "Epoch 786/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0628 - val_loss: 0.1383\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0628 - val_loss: 0.1382\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0628 - val_loss: 0.1381\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0628 - val_loss: 0.1380\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0627 - val_loss: 0.1379\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0627 - val_loss: 0.1378\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0627 - val_loss: 0.1377\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0627 - val_loss: 0.1376\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0626 - val_loss: 0.1375\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0626 - val_loss: 0.1374\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0626 - val_loss: 0.1373\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0626 - val_loss: 0.1373\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0625 - val_loss: 0.1372\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0625 - val_loss: 0.1371\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0625 - val_loss: 0.1370\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0625 - val_loss: 0.1369\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0624 - val_loss: 0.1368\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0624 - val_loss: 0.1367\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0624 - val_loss: 0.1366\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0624 - val_loss: 0.1365\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0624 - val_loss: 0.1364\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0623 - val_loss: 0.1363\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0623 - val_loss: 0.1362\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0623 - val_loss: 0.1361\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0623 - val_loss: 0.1360\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0622 - val_loss: 0.1359\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0622 - val_loss: 0.1358\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0622 - val_loss: 0.1358\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0622 - val_loss: 0.1357\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0621 - val_loss: 0.1356\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0621 - val_loss: 0.1355\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0621 - val_loss: 0.1354\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0621 - val_loss: 0.1353\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0620 - val_loss: 0.1352\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0620 - val_loss: 0.1351\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0620 - val_loss: 0.1350\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0620 - val_loss: 0.1349\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0619 - val_loss: 0.1348\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0619 - val_loss: 0.1347\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0619 - val_loss: 0.1346\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0619 - val_loss: 0.1345\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0618 - val_loss: 0.1345\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0618 - val_loss: 0.1344\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0618 - val_loss: 0.1343\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0618 - val_loss: 0.1342\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0617 - val_loss: 0.1341\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0617 - val_loss: 0.1340\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0617 - val_loss: 0.1339\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0617 - val_loss: 0.1338\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0616 - val_loss: 0.1337\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0616 - val_loss: 0.1336\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0616 - val_loss: 0.1335\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0616 - val_loss: 0.1334\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0616 - val_loss: 0.1334\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0615 - val_loss: 0.1333\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0615 - val_loss: 0.1332\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0615 - val_loss: 0.1331\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0615 - val_loss: 0.1330\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0614 - val_loss: 0.1329\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0614 - val_loss: 0.1328\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0614 - val_loss: 0.1327\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0614 - val_loss: 0.1326\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0613 - val_loss: 0.1325\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0613 - val_loss: 0.1325\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0613 - val_loss: 0.1324\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0613 - val_loss: 0.1323\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0612 - val_loss: 0.1322\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0612 - val_loss: 0.1321\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0612 - val_loss: 0.1320\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0612 - val_loss: 0.1319\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0611 - val_loss: 0.1318\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0611 - val_loss: 0.1317\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0611 - val_loss: 0.1316\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0611 - val_loss: 0.1316\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0610 - val_loss: 0.1315\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0610 - val_loss: 0.1314\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0610 - val_loss: 0.1313\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0610 - val_loss: 0.1312\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0610 - val_loss: 0.1311\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0609 - val_loss: 0.1310\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0609 - val_loss: 0.1309\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0609 - val_loss: 0.1309\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0609 - val_loss: 0.1308\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0608 - val_loss: 0.1307\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0608 - val_loss: 0.1306\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0608 - val_loss: 0.1305\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0608 - val_loss: 0.1304\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0607 - val_loss: 0.1303\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0607 - val_loss: 0.1302\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0607 - val_loss: 0.1301\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0607 - val_loss: 0.1301\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0606 - val_loss: 0.1300\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0606 - val_loss: 0.1299\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0606 - val_loss: 0.1298\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0606 - val_loss: 0.1297\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0606 - val_loss: 0.1296\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0605 - val_loss: 0.1295\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0605 - val_loss: 0.1295\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0605 - val_loss: 0.1294\n",
            "Epoch 885/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0605 - val_loss: 0.1293\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0604 - val_loss: 0.1292\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0604 - val_loss: 0.1291\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0604 - val_loss: 0.1290\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0604 - val_loss: 0.1289\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0603 - val_loss: 0.1289\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0603 - val_loss: 0.1288\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0603 - val_loss: 0.1287\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0603 - val_loss: 0.1286\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0602 - val_loss: 0.1285\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0602 - val_loss: 0.1284\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0602 - val_loss: 0.1283\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0602 - val_loss: 0.1283\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0602 - val_loss: 0.1282\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0601 - val_loss: 0.1281\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0601 - val_loss: 0.1280\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0601 - val_loss: 0.1279\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0601 - val_loss: 0.1278\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0600 - val_loss: 0.1277\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0600 - val_loss: 0.1277\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0600 - val_loss: 0.1276\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0600 - val_loss: 0.1275\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0599 - val_loss: 0.1274\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0599 - val_loss: 0.1273\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0599 - val_loss: 0.1272\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0599 - val_loss: 0.1272\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0598 - val_loss: 0.1271\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0598 - val_loss: 0.1270\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0598 - val_loss: 0.1269\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0598 - val_loss: 0.1268\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0598 - val_loss: 0.1267\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0597 - val_loss: 0.1267\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0597 - val_loss: 0.1266\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0597 - val_loss: 0.1265\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0597 - val_loss: 0.1264\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0596 - val_loss: 0.1263\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0596 - val_loss: 0.1262\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0596 - val_loss: 0.1262\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0596 - val_loss: 0.1261\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0595 - val_loss: 0.1260\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0595 - val_loss: 0.1259\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0595 - val_loss: 0.1258\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0595 - val_loss: 0.1258\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0595 - val_loss: 0.1257\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0594 - val_loss: 0.1256\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0594 - val_loss: 0.1255\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0594 - val_loss: 0.1254\n",
            "Epoch 932/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0594 - val_loss: 0.1253\n",
            "Epoch 933/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0593 - val_loss: 0.1253\n",
            "Epoch 934/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0593 - val_loss: 0.1252\n",
            "Epoch 935/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0593 - val_loss: 0.1251\n",
            "Epoch 936/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0593 - val_loss: 0.1250\n",
            "Epoch 937/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0592 - val_loss: 0.1249\n",
            "Epoch 938/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0592 - val_loss: 0.1249\n",
            "Epoch 939/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0592 - val_loss: 0.1248\n",
            "Epoch 940/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0592 - val_loss: 0.1247\n",
            "Epoch 941/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0592 - val_loss: 0.1246\n",
            "Epoch 942/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0591 - val_loss: 0.1245\n",
            "Epoch 943/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0591 - val_loss: 0.1245\n",
            "Epoch 944/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0591 - val_loss: 0.1244\n",
            "Epoch 945/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0591 - val_loss: 0.1243\n",
            "Epoch 946/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0590 - val_loss: 0.1242\n",
            "Epoch 947/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0590 - val_loss: 0.1241\n",
            "Epoch 948/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0590 - val_loss: 0.1241\n",
            "Epoch 949/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0590 - val_loss: 0.1240\n",
            "Epoch 950/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0590 - val_loss: 0.1239\n",
            "Epoch 951/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0589 - val_loss: 0.1238\n",
            "Epoch 952/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0589 - val_loss: 0.1237\n",
            "Epoch 953/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0589 - val_loss: 0.1237\n",
            "Epoch 954/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0589 - val_loss: 0.1236\n",
            "Epoch 955/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0588 - val_loss: 0.1235\n",
            "Epoch 956/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0588 - val_loss: 0.1234\n",
            "Epoch 957/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0588 - val_loss: 0.1233\n",
            "Epoch 958/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0588 - val_loss: 0.1233\n",
            "Epoch 959/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0587 - val_loss: 0.1232\n",
            "Epoch 960/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0587 - val_loss: 0.1231\n",
            "Epoch 961/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0587 - val_loss: 0.1230\n",
            "Epoch 962/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0587 - val_loss: 0.1229\n",
            "Epoch 963/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0587 - val_loss: 0.1229\n",
            "Epoch 964/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0586 - val_loss: 0.1228\n",
            "Epoch 965/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0586 - val_loss: 0.1227\n",
            "Epoch 966/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0586 - val_loss: 0.1226\n",
            "Epoch 967/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0586 - val_loss: 0.1226\n",
            "Epoch 968/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0585 - val_loss: 0.1225\n",
            "Epoch 969/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0585 - val_loss: 0.1224\n",
            "Epoch 970/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0585 - val_loss: 0.1223\n",
            "Epoch 971/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0585 - val_loss: 0.1222\n",
            "Epoch 972/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0585 - val_loss: 0.1222\n",
            "Epoch 973/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0584 - val_loss: 0.1221\n",
            "Epoch 974/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0584 - val_loss: 0.1220\n",
            "Epoch 975/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0584 - val_loss: 0.1219\n",
            "Epoch 976/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0584 - val_loss: 0.1219\n",
            "Epoch 977/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0583 - val_loss: 0.1218\n",
            "Epoch 978/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0583 - val_loss: 0.1217\n",
            "Epoch 979/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0583 - val_loss: 0.1216\n",
            "Epoch 980/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0583 - val_loss: 0.1216\n",
            "Epoch 981/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0582 - val_loss: 0.1215\n",
            "Epoch 982/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0582 - val_loss: 0.1214\n",
            "Epoch 983/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0582 - val_loss: 0.1213\n",
            "Epoch 984/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0582 - val_loss: 0.1213\n",
            "Epoch 985/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0582 - val_loss: 0.1212\n",
            "Epoch 986/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0581 - val_loss: 0.1211\n",
            "Epoch 987/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0581 - val_loss: 0.1210\n",
            "Epoch 988/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0581 - val_loss: 0.1209\n",
            "Epoch 989/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0581 - val_loss: 0.1209\n",
            "Epoch 990/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0580 - val_loss: 0.1208\n",
            "Epoch 991/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0580 - val_loss: 0.1207\n",
            "Epoch 992/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0580 - val_loss: 0.1206\n",
            "Epoch 993/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0580 - val_loss: 0.1206\n",
            "Epoch 994/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0580 - val_loss: 0.1205\n",
            "Epoch 995/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0579 - val_loss: 0.1204\n",
            "Epoch 996/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0579 - val_loss: 0.1203\n",
            "Epoch 997/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0579 - val_loss: 0.1203\n",
            "Epoch 998/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0579 - val_loss: 0.1202\n",
            "Epoch 999/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0578 - val_loss: 0.1201\n",
            "Epoch 1000/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0578 - val_loss: 0.1200\n",
            "Epoch 1/1000\n",
            "1/1 [==============================] - 0s 405ms/step - loss: 111862.3047 - val_loss: 57185.3477\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 107308.3828 - val_loss: 54061.1367\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 101339.5625 - val_loss: 50536.1758\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 94609.1172 - val_loss: 46805.5742\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 87490.9766 - val_loss: 42999.5117\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 80234.8984 - val_loss: 39210.3438\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 73017.8516 - val_loss: 35505.0742\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 65968.1328 - val_loss: 31932.4473\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 59179.0312 - val_loss: 28527.5801\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 52717.5469 - val_loss: 25314.9531\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 46630.1758 - val_loss: 22310.7559\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 40947.5625 - val_loss: 19524.5176\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 35687.4805 - val_loss: 16960.5547\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 30857.6562 - val_loss: 14618.9414\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 26457.6855 - val_loss: 12496.4072\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 22480.7168 - val_loss: 10587.0322\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 18914.8105 - val_loss: 8882.8086\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 15744.0068 - val_loss: 7374.1235\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 12949.2900 - val_loss: 6050.1167\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 10509.1885 - val_loss: 4899.0479\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 8400.5820 - val_loss: 3908.5413\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6599.1465 - val_loss: 3065.8250\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5079.8306 - val_loss: 2357.9375\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3817.2195 - val_loss: 1771.9023\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2785.8953 - val_loss: 1294.8707\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1960.7323 - val_loss: 914.2776\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1317.1621 - val_loss: 617.9596\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 831.4352 - val_loss: 394.2726\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 480.8368 - val_loss: 232.1949\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 243.8937 - val_loss: 121.4197\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 100.5547 - val_loss: 52.4330\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 32.3443 - val_loss: 16.5776\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 22.4861 - val_loss: 6.0983\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 55.9919 - val_loss: 14.1687\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 119.7141 - val_loss: 34.8983\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 202.3567 - val_loss: 63.3183\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 294.4478 - val_loss: 95.3503\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 388.2744 - val_loss: 127.7541\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 477.7765 - val_loss: 158.0622\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 558.4243 - val_loss: 184.5042\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 605.6163 - val_loss: 208.0603\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 632.7385 - val_loss: 229.5777\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 643.8252 - val_loss: 248.8497\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 653.7354 - val_loss: 265.7646\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 657.5098 - val_loss: 281.2072\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 659.3647 - val_loss: 295.1984\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 661.0601 - val_loss: 307.7813\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 662.5956 - val_loss: 319.0121\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 663.9743 - val_loss: 321.1540\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 665.2014 - val_loss: 322.7464\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 666.2831 - val_loss: 324.1351\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 667.2274 - val_loss: 325.3325\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 668.0421 - val_loss: 326.3514\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 668.7360 - val_loss: 327.2047\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 669.3177 - val_loss: 327.9048\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 669.7955 - val_loss: 328.4640\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 670.1777 - val_loss: 328.8941\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 670.4722 - val_loss: 329.2068\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 670.6870 - val_loss: 329.4120\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 670.8287 - val_loss: 329.5197\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 670.9043 - val_loss: 329.5396\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 670.9203 - val_loss: 329.4799\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 670.8822 - val_loss: 329.3492\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 670.7957 - val_loss: 329.1542\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 670.6657 - val_loss: 328.9022\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 670.4967 - val_loss: 328.5990\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 670.2933 - val_loss: 328.2507\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 670.0590 - val_loss: 327.8620\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 669.7975 - val_loss: 327.4382\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 669.5123 - val_loss: 326.9836\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 669.2059 - val_loss: 326.5017\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 668.8812 - val_loss: 325.9964\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 668.5406 - val_loss: 325.4708\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 668.1863 - val_loss: 324.9280\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 667.8203 - val_loss: 324.3703\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 667.4446 - val_loss: 323.8005\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 667.0604 - val_loss: 323.2205\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 666.6694 - val_loss: 322.6323\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 666.2729 - val_loss: 322.0376\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 665.8721 - val_loss: 321.4380\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 665.4681 - val_loss: 320.8349\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 665.0617 - val_loss: 320.2294\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 664.6539 - val_loss: 319.6230\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 664.2455 - val_loss: 318.5097\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 663.8370 - val_loss: 315.2094\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 663.4290 - val_loss: 311.9121\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 663.0223 - val_loss: 308.6239\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 662.6171 - val_loss: 305.3447\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 662.2140 - val_loss: 302.0800\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 661.8133 - val_loss: 298.8316\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 661.4153 - val_loss: 295.6018\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 661.0203 - val_loss: 292.3929\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 660.6286 - val_loss: 289.2063\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 660.2404 - val_loss: 286.0439\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 659.8558 - val_loss: 282.9072\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 659.4751 - val_loss: 279.7973\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 659.0983 - val_loss: 276.7155\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 658.7256 - val_loss: 273.6625\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 658.3573 - val_loss: 270.6394\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 657.9931 - val_loss: 267.6461\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 657.6334 - val_loss: 264.6830\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 657.2779 - val_loss: 261.7515\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 656.9269 - val_loss: 258.8512\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 656.5803 - val_loss: 255.9831\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 656.2383 - val_loss: 253.1462\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 655.9008 - val_loss: 250.3417\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 654.7331 - val_loss: 246.7014\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 652.8659 - val_loss: 242.3356\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 650.6251 - val_loss: 237.3500\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 648.0649 - val_loss: 231.8404\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 645.2339 - val_loss: 225.8962\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 642.1775 - val_loss: 219.6003\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 638.9377 - val_loss: 213.0268\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 635.5535 - val_loss: 206.2443\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 632.0581 - val_loss: 199.3128\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 625.4370 - val_loss: 191.0235\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 615.0214 - val_loss: 181.6559\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 603.1998 - val_loss: 171.4750\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 590.2867 - val_loss: 160.7252\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 568.5281 - val_loss: 147.8413\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 534.5859 - val_loss: 133.4997\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 496.3004 - val_loss: 118.3397\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 455.1620 - val_loss: 102.9398\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 412.5298 - val_loss: 87.8066\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 369.6079 - val_loss: 73.3651\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 327.4276 - val_loss: 59.9564\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 286.8375 - val_loss: 47.8376\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 248.5123 - val_loss: 37.1876\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 212.9542 - val_loss: 28.1119\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 180.5076 - val_loss: 20.6516\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 151.3788 - val_loss: 14.7921\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 125.6492 - val_loss: 10.4726\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 103.2956 - val_loss: 7.5948\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 84.2107 - val_loss: 6.0329\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 68.2180 - val_loss: 5.6411\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 55.0927 - val_loss: 6.2616\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 44.5735 - val_loss: 7.7312\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 36.3794 - val_loss: 9.8872\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 30.2199 - val_loss: 12.5717\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 25.8057 - val_loss: 15.6356\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 22.8564 - val_loss: 18.9413\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 21.1070 - val_loss: 22.3651\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 20.3128 - val_loss: 25.7982\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 20.2521 - val_loss: 29.1469\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 20.7285 - val_loss: 32.3340\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 21.5717 - val_loss: 35.2970\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 22.6374 - val_loss: 37.9878\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 23.8060 - val_loss: 40.3724\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 24.9820 - val_loss: 42.4285\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 26.0915 - val_loss: 44.1448\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 27.0797 - val_loss: 45.5196\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 27.9096 - val_loss: 46.5593\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 28.5589 - val_loss: 47.2772\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 29.0179 - val_loss: 47.6914\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 29.2867 - val_loss: 47.8243\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 29.3738 - val_loss: 47.7010\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 29.2938 - val_loss: 47.3487\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 29.0651 - val_loss: 46.7955\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 28.7092 - val_loss: 46.0693\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 28.2490 - val_loss: 45.1982\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 27.7076 - val_loss: 44.2089\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 27.1072 - val_loss: 43.1262\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 26.4691 - val_loss: 41.9736\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 25.8123 - val_loss: 40.7728\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 25.1541 - val_loss: 39.5434\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 24.5089 - val_loss: 38.3022\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 23.8888 - val_loss: 37.0646\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 23.3034 - val_loss: 35.8435\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 22.7599 - val_loss: 34.6497\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 22.2634 - val_loss: 33.4928\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 21.8168 - val_loss: 32.3799\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 21.4213 - val_loss: 31.3166\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 21.0774 - val_loss: 30.3077\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 20.7833 - val_loss: 29.3564\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 20.5356 - val_loss: 28.4643\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 20.3312 - val_loss: 27.6328\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 20.1661 - val_loss: 26.8619\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 20.0361 - val_loss: 26.1509\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 19.9366 - val_loss: 25.4991\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 19.8636 - val_loss: 24.9047\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 19.8124 - val_loss: 24.3662\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 19.7792 - val_loss: 23.8814\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 19.7602 - val_loss: 23.4477\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 19.7519 - val_loss: 23.0632\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 19.7514 - val_loss: 22.7250\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 19.7561 - val_loss: 22.4306\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 19.7636 - val_loss: 22.1775\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 19.7723 - val_loss: 21.9630\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 19.7806 - val_loss: 21.7845\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 19.7876 - val_loss: 21.6398\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 19.7923 - val_loss: 21.5258\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 19.7942 - val_loss: 21.4408\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 19.7932 - val_loss: 21.3819\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 19.7889 - val_loss: 21.3471\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 19.7816 - val_loss: 21.3341\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 19.7715 - val_loss: 21.3407\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 19.7587 - val_loss: 21.3649\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 19.7435 - val_loss: 21.4046\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 19.7266 - val_loss: 21.4579\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 19.7081 - val_loss: 21.5230\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 19.6884 - val_loss: 21.5981\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 19.6679 - val_loss: 21.6818\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 19.6470 - val_loss: 21.7722\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 19.6261 - val_loss: 21.8678\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 19.6052 - val_loss: 21.9676\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 19.5846 - val_loss: 22.0699\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 19.5645 - val_loss: 22.1737\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 19.5452 - val_loss: 22.2777\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 19.5266 - val_loss: 22.3810\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 19.5088 - val_loss: 22.4828\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 19.4919 - val_loss: 22.5822\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 19.4758 - val_loss: 22.6783\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 19.4605 - val_loss: 22.7707\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 19.4459 - val_loss: 22.8588\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 19.4322 - val_loss: 22.9421\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 19.4191 - val_loss: 23.0201\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 19.4066 - val_loss: 23.0926\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 19.3946 - val_loss: 23.1596\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 19.3831 - val_loss: 23.2206\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 19.3719 - val_loss: 23.2759\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 19.3610 - val_loss: 23.3251\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 19.3504 - val_loss: 23.3684\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 19.3399 - val_loss: 23.4060\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 19.3296 - val_loss: 23.4379\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 19.3193 - val_loss: 23.4641\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 19.3091 - val_loss: 23.4850\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 19.2989 - val_loss: 23.5010\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 19.2887 - val_loss: 23.5120\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 19.2784 - val_loss: 23.5184\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 19.2682 - val_loss: 23.5207\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 19.2578 - val_loss: 23.5190\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 19.2474 - val_loss: 23.5137\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 19.2370 - val_loss: 23.5050\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 19.2265 - val_loss: 23.4932\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 19.2159 - val_loss: 23.4785\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 19.2052 - val_loss: 23.4616\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 19.1947 - val_loss: 23.4425\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 19.1840 - val_loss: 23.4216\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 19.1732 - val_loss: 23.3991\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 19.1625 - val_loss: 23.3752\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 19.1517 - val_loss: 23.3504\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 19.1411 - val_loss: 23.3246\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 19.1303 - val_loss: 23.2983\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 19.1195 - val_loss: 23.2715\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 19.1088 - val_loss: 23.2445\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 19.0981 - val_loss: 23.2173\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 19.0874 - val_loss: 23.1904\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 19.0766 - val_loss: 23.1637\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 19.0660 - val_loss: 23.1373\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 19.0553 - val_loss: 23.1114\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 19.0447 - val_loss: 23.0858\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 19.0339 - val_loss: 23.0611\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 19.0233 - val_loss: 23.0369\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 19.0127 - val_loss: 23.0134\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 19.0022 - val_loss: 22.9908\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 18.9915 - val_loss: 22.9689\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 18.9809 - val_loss: 22.9478\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 18.9703 - val_loss: 22.9275\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 18.9597 - val_loss: 22.9081\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 18.9491 - val_loss: 22.8895\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 18.9386 - val_loss: 22.8717\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 18.9280 - val_loss: 22.8547\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 18.9174 - val_loss: 22.8385\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 18.9068 - val_loss: 22.8229\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 18.8962 - val_loss: 22.8081\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 18.8857 - val_loss: 22.7940\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 18.8751 - val_loss: 22.7805\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 18.8645 - val_loss: 22.7675\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 18.8538 - val_loss: 22.7551\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 18.8433 - val_loss: 22.7433\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 18.8327 - val_loss: 22.7318\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 18.8221 - val_loss: 22.7207\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 18.8115 - val_loss: 22.7102\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 18.8009 - val_loss: 22.6998\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 18.7903 - val_loss: 22.6898\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 18.7797 - val_loss: 22.6802\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 18.7690 - val_loss: 22.6706\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 18.7585 - val_loss: 22.6612\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 18.7479 - val_loss: 22.6519\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 18.7373 - val_loss: 22.6429\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 18.7267 - val_loss: 22.6339\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 18.7161 - val_loss: 22.6249\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 18.7054 - val_loss: 22.6159\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 18.6948 - val_loss: 22.6069\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 18.6842 - val_loss: 22.5980\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 18.6736 - val_loss: 22.5890\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 18.6630 - val_loss: 22.5800\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 18.6523 - val_loss: 22.5707\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 18.6418 - val_loss: 22.5615\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 18.6311 - val_loss: 22.5523\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 18.6205 - val_loss: 22.5429\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 18.6099 - val_loss: 22.5334\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 18.5992 - val_loss: 22.5238\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 18.5887 - val_loss: 22.5141\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 18.5781 - val_loss: 22.5043\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 18.5674 - val_loss: 22.4943\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 18.5568 - val_loss: 22.4842\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 18.5461 - val_loss: 22.4740\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 18.5356 - val_loss: 22.4636\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 18.5249 - val_loss: 22.4533\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 18.5143 - val_loss: 22.4427\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 18.5037 - val_loss: 22.4321\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 18.4931 - val_loss: 22.4213\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 18.4824 - val_loss: 22.4106\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 18.4718 - val_loss: 22.3996\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 18.4612 - val_loss: 22.3887\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 18.4505 - val_loss: 22.3777\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 18.4399 - val_loss: 22.3666\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 18.4293 - val_loss: 22.3554\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 18.4186 - val_loss: 22.3441\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 18.4080 - val_loss: 22.3328\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 18.3974 - val_loss: 22.3214\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 18.3867 - val_loss: 22.3099\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 18.3761 - val_loss: 22.2985\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 18.3654 - val_loss: 22.2871\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 18.3548 - val_loss: 22.2756\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 18.3442 - val_loss: 22.2640\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 18.3335 - val_loss: 22.2525\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 18.3229 - val_loss: 22.2410\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 18.3123 - val_loss: 22.2295\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 18.3016 - val_loss: 22.2179\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 18.2910 - val_loss: 22.2064\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 18.2803 - val_loss: 22.1948\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 18.2696 - val_loss: 22.1832\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 18.2590 - val_loss: 22.1717\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 18.2483 - val_loss: 22.1601\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 18.2377 - val_loss: 22.1485\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 18.2271 - val_loss: 22.1371\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 18.2164 - val_loss: 22.1257\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 18.2058 - val_loss: 22.1142\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 18.1951 - val_loss: 22.1028\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 18.1844 - val_loss: 22.0916\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 18.1738 - val_loss: 22.0802\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 18.1632 - val_loss: 22.0687\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 18.1525 - val_loss: 22.0574\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 18.1418 - val_loss: 22.0461\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 18.1312 - val_loss: 22.0346\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 18.1205 - val_loss: 22.0234\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 18.1099 - val_loss: 22.0122\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 18.0992 - val_loss: 22.0008\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 18.0886 - val_loss: 21.9896\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 18.0779 - val_loss: 21.9783\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 18.0672 - val_loss: 21.9672\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 18.0565 - val_loss: 21.9558\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 18.0459 - val_loss: 21.9446\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 18.0353 - val_loss: 21.9333\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 18.0246 - val_loss: 21.9221\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 18.0139 - val_loss: 21.9108\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 18.0032 - val_loss: 21.8996\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 17.9926 - val_loss: 21.8884\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 17.9819 - val_loss: 21.8772\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 17.9712 - val_loss: 21.8660\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 17.9606 - val_loss: 21.8548\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 17.9499 - val_loss: 21.8436\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 17.9393 - val_loss: 21.8323\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 17.9286 - val_loss: 21.8210\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 17.9179 - val_loss: 21.8098\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 17.9073 - val_loss: 21.7988\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 17.8966 - val_loss: 21.7875\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 17.8859 - val_loss: 21.7764\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 17.8752 - val_loss: 21.7652\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 17.8646 - val_loss: 21.7539\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 17.8539 - val_loss: 21.7428\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 17.8432 - val_loss: 21.7317\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 17.8326 - val_loss: 21.7204\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 17.8219 - val_loss: 21.7092\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 17.8112 - val_loss: 21.6981\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 17.8006 - val_loss: 21.6869\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 17.7899 - val_loss: 21.6757\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 17.7792 - val_loss: 21.6646\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 17.7685 - val_loss: 21.6533\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 17.7578 - val_loss: 21.6421\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 17.7472 - val_loss: 21.6309\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 17.7365 - val_loss: 21.6198\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 17.7258 - val_loss: 21.6085\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 17.7151 - val_loss: 21.5972\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 17.7045 - val_loss: 21.5859\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 17.6938 - val_loss: 21.5746\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 17.6831 - val_loss: 21.5634\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 17.6724 - val_loss: 21.5521\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 17.6617 - val_loss: 21.5408\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 17.6511 - val_loss: 21.5295\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 17.6404 - val_loss: 21.5182\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 17.6298 - val_loss: 21.5068\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 17.6190 - val_loss: 21.4954\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 17.6083 - val_loss: 21.4841\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 17.5976 - val_loss: 21.4726\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 17.5870 - val_loss: 21.4613\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 17.5763 - val_loss: 21.4499\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 17.5657 - val_loss: 21.4387\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 17.5550 - val_loss: 21.4272\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 17.5443 - val_loss: 21.4160\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 17.5336 - val_loss: 21.4047\n",
            "Epoch 394/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 17.5229 - val_loss: 21.3935\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 17.5122 - val_loss: 21.3824\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 17.5016 - val_loss: 21.3711\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 17.4909 - val_loss: 21.3599\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 17.4802 - val_loss: 21.3487\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 17.4695 - val_loss: 21.3372\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 17.4588 - val_loss: 21.3261\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 17.4481 - val_loss: 21.3148\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 17.4374 - val_loss: 21.3036\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 17.4268 - val_loss: 21.2923\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 17.4161 - val_loss: 21.2810\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 17.4054 - val_loss: 21.2697\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 17.3947 - val_loss: 21.2584\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 17.3840 - val_loss: 21.2471\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 17.3733 - val_loss: 21.2359\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 17.3627 - val_loss: 21.2245\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 17.3520 - val_loss: 21.2132\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 17.3413 - val_loss: 21.2018\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 17.3306 - val_loss: 21.1905\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 17.3199 - val_loss: 21.1792\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 17.3093 - val_loss: 21.1678\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 17.2986 - val_loss: 21.1565\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 17.2878 - val_loss: 21.1453\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 17.2772 - val_loss: 21.1340\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 17.2665 - val_loss: 21.1227\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 17.2558 - val_loss: 21.1114\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 17.2451 - val_loss: 21.1001\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 17.2344 - val_loss: 21.0888\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 17.2237 - val_loss: 21.0775\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 17.2130 - val_loss: 21.0663\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 17.2024 - val_loss: 21.0551\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 17.1917 - val_loss: 21.0438\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 17.1810 - val_loss: 21.0325\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 17.1703 - val_loss: 21.0213\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 17.1596 - val_loss: 21.0099\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 17.1490 - val_loss: 20.9986\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 17.1383 - val_loss: 20.9872\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 17.1276 - val_loss: 20.9760\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 17.1169 - val_loss: 20.9648\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 17.1062 - val_loss: 20.9535\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 17.0955 - val_loss: 20.9420\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 17.0848 - val_loss: 20.9307\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 17.0741 - val_loss: 20.9193\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 17.0634 - val_loss: 20.9079\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 17.0527 - val_loss: 20.8966\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 17.0421 - val_loss: 20.8852\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 17.0314 - val_loss: 20.8738\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 17.0207 - val_loss: 20.8624\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 17.0100 - val_loss: 20.8510\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 16.9993 - val_loss: 20.8397\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 16.9886 - val_loss: 20.8282\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 16.9779 - val_loss: 20.8170\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 16.9672 - val_loss: 20.8054\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 16.9565 - val_loss: 20.7941\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 16.9458 - val_loss: 20.7827\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 16.9351 - val_loss: 20.7713\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 16.9245 - val_loss: 20.7600\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 16.9138 - val_loss: 20.7486\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 16.9031 - val_loss: 20.7373\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 16.8924 - val_loss: 20.7261\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 16.8817 - val_loss: 20.7149\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 16.8710 - val_loss: 20.7035\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 16.8603 - val_loss: 20.6923\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 16.8497 - val_loss: 20.6808\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 16.8389 - val_loss: 20.6695\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 16.8283 - val_loss: 20.6582\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 16.8175 - val_loss: 20.6469\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 16.8069 - val_loss: 20.6355\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 16.7962 - val_loss: 20.6243\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 16.7855 - val_loss: 20.6129\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 16.7749 - val_loss: 20.6016\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 16.7641 - val_loss: 20.5903\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 16.7534 - val_loss: 20.5789\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 16.7427 - val_loss: 20.5675\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 16.7321 - val_loss: 20.5563\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 16.7214 - val_loss: 20.5449\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 16.7107 - val_loss: 20.5335\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 16.7000 - val_loss: 20.5222\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 16.6894 - val_loss: 20.5109\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 16.6787 - val_loss: 20.4995\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 16.6680 - val_loss: 20.4882\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 16.6572 - val_loss: 20.4769\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 16.6466 - val_loss: 20.4655\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 16.6359 - val_loss: 20.4543\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 16.6252 - val_loss: 20.4430\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 16.6145 - val_loss: 20.4318\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 16.6038 - val_loss: 20.4206\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 16.5932 - val_loss: 20.4093\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 16.5825 - val_loss: 20.3980\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 16.5718 - val_loss: 20.3867\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 16.5611 - val_loss: 20.3754\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 16.5504 - val_loss: 20.3641\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 16.5397 - val_loss: 20.3528\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 16.5291 - val_loss: 20.3414\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 16.5184 - val_loss: 20.3301\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 16.5077 - val_loss: 20.3189\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 16.4970 - val_loss: 20.3075\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 16.4864 - val_loss: 20.2961\n",
            "Epoch 492/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 16.4757 - val_loss: 20.2847\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 16.4650 - val_loss: 20.2732\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 16.4543 - val_loss: 20.2620\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 16.4436 - val_loss: 20.2506\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 16.4329 - val_loss: 20.2392\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 16.4222 - val_loss: 20.2279\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 16.4116 - val_loss: 20.2165\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 16.4009 - val_loss: 20.2051\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 16.3902 - val_loss: 20.1938\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 16.3796 - val_loss: 20.1824\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 16.3689 - val_loss: 20.1710\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 16.3582 - val_loss: 20.1597\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 16.3475 - val_loss: 20.1483\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 16.3369 - val_loss: 20.1369\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 16.3262 - val_loss: 20.1254\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 16.3155 - val_loss: 20.1140\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 16.3049 - val_loss: 20.1027\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 16.2942 - val_loss: 20.0912\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 16.2835 - val_loss: 20.0799\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 16.2729 - val_loss: 20.0686\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 16.2622 - val_loss: 20.0572\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 16.2515 - val_loss: 20.0459\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 16.2409 - val_loss: 20.0346\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 16.2302 - val_loss: 20.0233\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 16.2195 - val_loss: 20.0120\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 16.2088 - val_loss: 20.0007\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 16.1982 - val_loss: 19.9893\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 16.1875 - val_loss: 19.9780\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 16.1768 - val_loss: 19.9667\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 16.1662 - val_loss: 19.9553\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 16.1555 - val_loss: 19.9441\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 16.1448 - val_loss: 19.9327\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 16.1342 - val_loss: 19.9215\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 16.1235 - val_loss: 19.9101\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 16.1129 - val_loss: 19.8988\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 16.1022 - val_loss: 19.8874\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 16.0915 - val_loss: 19.8761\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 16.0808 - val_loss: 19.8648\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 16.0702 - val_loss: 19.8534\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 16.0596 - val_loss: 19.8420\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 16.0489 - val_loss: 19.8307\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 16.0382 - val_loss: 19.8193\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 16.0276 - val_loss: 19.8079\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 16.0169 - val_loss: 19.7965\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 16.0063 - val_loss: 19.7852\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 15.9956 - val_loss: 19.7739\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 15.9850 - val_loss: 19.7625\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 15.9743 - val_loss: 19.7513\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 15.9637 - val_loss: 19.7400\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 15.9530 - val_loss: 19.7287\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 15.9423 - val_loss: 19.7174\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 15.9317 - val_loss: 19.7061\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 15.9210 - val_loss: 19.6949\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 15.9104 - val_loss: 19.6837\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 15.8997 - val_loss: 19.6723\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 15.8891 - val_loss: 19.6611\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 15.8784 - val_loss: 19.6499\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 15.8678 - val_loss: 19.6385\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 15.8571 - val_loss: 19.6272\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 15.8465 - val_loss: 19.6159\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 15.8358 - val_loss: 19.6045\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 15.8252 - val_loss: 19.5931\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 15.8146 - val_loss: 19.5819\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 15.8039 - val_loss: 19.5706\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 15.7933 - val_loss: 19.5591\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 15.7826 - val_loss: 19.5479\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 15.7720 - val_loss: 19.5364\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 15.7613 - val_loss: 19.5251\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 15.7507 - val_loss: 19.5138\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 15.7401 - val_loss: 19.5024\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 15.7294 - val_loss: 19.4910\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 15.7188 - val_loss: 19.4798\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 15.7082 - val_loss: 19.4683\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 15.6975 - val_loss: 19.4570\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 15.6869 - val_loss: 19.4456\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 15.6763 - val_loss: 19.4342\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 15.6656 - val_loss: 19.4228\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 15.6550 - val_loss: 19.4114\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 15.6444 - val_loss: 19.4000\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 15.6338 - val_loss: 19.3887\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 15.6231 - val_loss: 19.3774\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 15.6125 - val_loss: 19.3660\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 15.6019 - val_loss: 19.3547\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 15.5912 - val_loss: 19.3435\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 15.5806 - val_loss: 19.3321\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 15.5699 - val_loss: 19.3208\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 15.5593 - val_loss: 19.3095\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 15.5487 - val_loss: 19.2983\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 15.5382 - val_loss: 19.2870\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 15.5275 - val_loss: 19.2757\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 15.5169 - val_loss: 19.2644\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 15.5063 - val_loss: 19.2531\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 15.4956 - val_loss: 19.2417\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 15.4850 - val_loss: 19.2305\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 15.4744 - val_loss: 19.2192\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 15.4638 - val_loss: 19.2079\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 15.4531 - val_loss: 19.1965\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 15.4425 - val_loss: 19.1853\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 15.4319 - val_loss: 19.1739\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 15.4213 - val_loss: 19.1626\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 15.4107 - val_loss: 19.1511\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 15.4001 - val_loss: 19.1397\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 15.3895 - val_loss: 19.1282\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 15.3789 - val_loss: 19.1169\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 15.3683 - val_loss: 19.1056\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 15.3577 - val_loss: 19.0941\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 15.3471 - val_loss: 19.0827\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 15.3365 - val_loss: 19.0713\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 15.3259 - val_loss: 19.0600\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 15.3152 - val_loss: 19.0485\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 15.3046 - val_loss: 19.0371\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 15.2940 - val_loss: 19.0258\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 15.2835 - val_loss: 19.0143\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 15.2729 - val_loss: 19.0030\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 15.2622 - val_loss: 18.9916\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 15.2517 - val_loss: 18.9803\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 15.2410 - val_loss: 18.9691\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 15.2305 - val_loss: 18.9578\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 15.2199 - val_loss: 18.9463\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 15.2093 - val_loss: 18.9351\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 15.1987 - val_loss: 18.9237\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 15.1881 - val_loss: 18.9126\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 15.1775 - val_loss: 18.9012\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 15.1669 - val_loss: 18.8899\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 15.1563 - val_loss: 18.8787\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 15.1458 - val_loss: 18.8673\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 15.1352 - val_loss: 18.8559\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 15.1245 - val_loss: 18.8448\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 15.1140 - val_loss: 18.8334\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 15.1034 - val_loss: 18.8221\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 15.0928 - val_loss: 18.8107\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 15.0822 - val_loss: 18.7994\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 15.0716 - val_loss: 18.7881\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 15.0611 - val_loss: 18.7768\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 15.0505 - val_loss: 18.7655\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 15.0399 - val_loss: 18.7541\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 15.0294 - val_loss: 18.7428\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 15.0188 - val_loss: 18.7317\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 15.0082 - val_loss: 18.7203\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 14.9977 - val_loss: 18.7089\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 14.9871 - val_loss: 18.6976\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 14.9765 - val_loss: 18.6862\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 14.9660 - val_loss: 18.6750\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 14.9554 - val_loss: 18.6639\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 14.9448 - val_loss: 18.6526\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 14.9343 - val_loss: 18.6414\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 14.9238 - val_loss: 18.6301\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 14.9131 - val_loss: 18.6189\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 14.9026 - val_loss: 18.6076\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 14.8920 - val_loss: 18.5963\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 14.8815 - val_loss: 18.5850\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 14.8710 - val_loss: 18.5737\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 14.8604 - val_loss: 18.5624\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 14.8499 - val_loss: 18.5512\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 14.8393 - val_loss: 18.5398\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 14.8288 - val_loss: 18.5285\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 14.8182 - val_loss: 18.5172\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 14.8076 - val_loss: 18.5058\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 14.7971 - val_loss: 18.4945\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 14.7866 - val_loss: 18.4831\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 14.7760 - val_loss: 18.4718\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 14.7655 - val_loss: 18.4605\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 14.7550 - val_loss: 18.4491\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 14.7444 - val_loss: 18.4378\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 14.7339 - val_loss: 18.4265\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 14.7233 - val_loss: 18.4152\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 14.7128 - val_loss: 18.4038\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 14.7023 - val_loss: 18.3926\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 14.6918 - val_loss: 18.3812\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 14.6812 - val_loss: 18.3699\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 14.6707 - val_loss: 18.3586\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 14.6602 - val_loss: 18.3473\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 14.6496 - val_loss: 18.3361\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 14.6391 - val_loss: 18.3248\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 14.6285 - val_loss: 18.3134\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 14.6181 - val_loss: 18.3021\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 14.6076 - val_loss: 18.2909\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 14.5970 - val_loss: 18.2796\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 14.5865 - val_loss: 18.2684\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 14.5760 - val_loss: 18.2571\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 14.5655 - val_loss: 18.2459\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 14.5550 - val_loss: 18.2346\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 14.5445 - val_loss: 18.2235\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 14.5340 - val_loss: 18.2121\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 14.5234 - val_loss: 18.2009\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 14.5130 - val_loss: 18.1897\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 14.5024 - val_loss: 18.1785\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 14.4920 - val_loss: 18.1673\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 14.4815 - val_loss: 18.1559\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 14.4710 - val_loss: 18.1447\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 14.4604 - val_loss: 18.1336\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 14.4500 - val_loss: 18.1223\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 14.4395 - val_loss: 18.1111\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 14.4290 - val_loss: 18.0999\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 14.4184 - val_loss: 18.0886\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 14.4080 - val_loss: 18.0773\n",
            "Epoch 688/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 14.3975 - val_loss: 18.0661\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 14.3870 - val_loss: 18.0549\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 14.3765 - val_loss: 18.0436\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 14.3660 - val_loss: 18.0322\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 14.3556 - val_loss: 18.0211\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 14.3451 - val_loss: 18.0098\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 14.3346 - val_loss: 17.9985\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 14.3241 - val_loss: 17.9872\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 14.3137 - val_loss: 17.9760\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 14.3031 - val_loss: 17.9647\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 14.2927 - val_loss: 17.9534\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 14.2822 - val_loss: 17.9421\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 14.2718 - val_loss: 17.9308\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 14.2613 - val_loss: 17.9195\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 14.2508 - val_loss: 17.9082\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 14.2404 - val_loss: 17.8969\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 14.2299 - val_loss: 17.8855\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 14.2194 - val_loss: 17.8742\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 14.2090 - val_loss: 17.8630\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 14.1985 - val_loss: 17.8517\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 14.1881 - val_loss: 17.8405\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 14.1776 - val_loss: 17.8294\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 14.1672 - val_loss: 17.8181\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 14.1567 - val_loss: 17.8069\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 14.1463 - val_loss: 17.7957\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 14.1358 - val_loss: 17.7846\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 14.1254 - val_loss: 17.7732\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 14.1149 - val_loss: 17.7621\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 14.1045 - val_loss: 17.7509\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 14.0941 - val_loss: 17.7396\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 14.0836 - val_loss: 17.7285\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 14.0732 - val_loss: 17.7172\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 14.0627 - val_loss: 17.7060\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 14.0523 - val_loss: 17.6947\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 14.0419 - val_loss: 17.6836\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 14.0315 - val_loss: 17.6723\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 14.0211 - val_loss: 17.6611\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 14.0106 - val_loss: 17.6499\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 14.0002 - val_loss: 17.6385\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 13.9898 - val_loss: 17.6274\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 13.9793 - val_loss: 17.6160\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 13.9689 - val_loss: 17.6049\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 13.9585 - val_loss: 17.5936\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 13.9481 - val_loss: 17.5823\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 13.9377 - val_loss: 17.5712\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 13.9273 - val_loss: 17.5598\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 13.9168 - val_loss: 17.5486\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 13.9065 - val_loss: 17.5374\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 13.8961 - val_loss: 17.5263\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 13.8857 - val_loss: 17.5152\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 13.8752 - val_loss: 17.5039\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 13.8648 - val_loss: 17.4929\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 13.8544 - val_loss: 17.4817\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 13.8441 - val_loss: 17.4705\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 13.8336 - val_loss: 17.4593\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 13.8233 - val_loss: 17.4482\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 13.8129 - val_loss: 17.4371\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 13.8025 - val_loss: 17.4260\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 13.7921 - val_loss: 17.4147\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 13.7817 - val_loss: 17.4036\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 13.7713 - val_loss: 17.3925\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 13.7609 - val_loss: 17.3814\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 13.7505 - val_loss: 17.3702\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 13.7402 - val_loss: 17.3590\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 13.7298 - val_loss: 17.3478\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 13.7195 - val_loss: 17.3367\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 13.7091 - val_loss: 17.3255\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 13.6987 - val_loss: 17.3143\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 13.6884 - val_loss: 17.3031\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 13.6780 - val_loss: 17.2919\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 13.6677 - val_loss: 17.2806\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 13.6573 - val_loss: 17.2693\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 13.6469 - val_loss: 17.2582\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 13.6366 - val_loss: 17.2469\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 13.6262 - val_loss: 17.2357\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 13.6159 - val_loss: 17.2245\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 13.6055 - val_loss: 17.2133\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 13.5951 - val_loss: 17.2021\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 13.5848 - val_loss: 17.1908\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 13.5744 - val_loss: 17.1797\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 13.5641 - val_loss: 17.1685\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 13.5538 - val_loss: 17.1573\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 13.5434 - val_loss: 17.1461\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 13.5331 - val_loss: 17.1350\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 13.5228 - val_loss: 17.1237\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 13.5124 - val_loss: 17.1125\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 13.5021 - val_loss: 17.1013\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 13.4918 - val_loss: 17.0902\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 13.4814 - val_loss: 17.0790\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 13.4711 - val_loss: 17.0679\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 13.4607 - val_loss: 17.0567\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 13.4505 - val_loss: 17.0457\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 13.4401 - val_loss: 17.0345\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 13.4298 - val_loss: 17.0235\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 13.4195 - val_loss: 17.0123\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 13.4092 - val_loss: 17.0012\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 13.3989 - val_loss: 16.9900\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 13.3886 - val_loss: 16.9791\n",
            "Epoch 786/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 13.3783 - val_loss: 16.9679\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 13.3680 - val_loss: 16.9568\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 13.3577 - val_loss: 16.9458\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 13.3474 - val_loss: 16.9347\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 13.3371 - val_loss: 16.9236\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 13.3268 - val_loss: 16.9125\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 13.3165 - val_loss: 16.9015\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 13.3062 - val_loss: 16.8903\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 13.2959 - val_loss: 16.8793\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 13.2856 - val_loss: 16.8682\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 13.2753 - val_loss: 16.8571\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 13.2651 - val_loss: 16.8460\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 13.2548 - val_loss: 16.8348\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 13.2445 - val_loss: 16.8237\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 13.2342 - val_loss: 16.8126\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 13.2240 - val_loss: 16.8014\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 13.2137 - val_loss: 16.7903\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 13.2034 - val_loss: 16.7792\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 13.1931 - val_loss: 16.7680\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 13.1829 - val_loss: 16.7569\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 13.1726 - val_loss: 16.7458\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 13.1624 - val_loss: 16.7346\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 13.1521 - val_loss: 16.7235\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 13.1419 - val_loss: 16.7123\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 13.1316 - val_loss: 16.7013\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 13.1214 - val_loss: 16.6901\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 13.1111 - val_loss: 16.6790\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 13.1009 - val_loss: 16.6679\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 13.0906 - val_loss: 16.6567\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 13.0804 - val_loss: 16.6457\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 13.0702 - val_loss: 16.6346\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 13.0599 - val_loss: 16.6235\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 13.0497 - val_loss: 16.6125\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 13.0395 - val_loss: 16.6015\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 13.0292 - val_loss: 16.5905\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 13.0190 - val_loss: 16.5794\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 13.0088 - val_loss: 16.5684\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 12.9985 - val_loss: 16.5573\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 12.9883 - val_loss: 16.5463\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 12.9781 - val_loss: 16.5352\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 12.9679 - val_loss: 16.5242\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 12.9577 - val_loss: 16.5131\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 12.9475 - val_loss: 16.5019\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 12.9373 - val_loss: 16.4910\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 12.9270 - val_loss: 16.4798\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 12.9169 - val_loss: 16.4688\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 12.9066 - val_loss: 16.4577\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 12.8965 - val_loss: 16.4466\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 12.8863 - val_loss: 16.4355\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 12.8760 - val_loss: 16.4244\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 12.8658 - val_loss: 16.4133\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 12.8557 - val_loss: 16.4022\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 12.8455 - val_loss: 16.3911\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 12.8353 - val_loss: 16.3800\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 12.8251 - val_loss: 16.3690\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 12.8150 - val_loss: 16.3578\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 12.8048 - val_loss: 16.3468\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 12.7946 - val_loss: 16.3357\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 12.7844 - val_loss: 16.3246\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 12.7742 - val_loss: 16.3136\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 12.7641 - val_loss: 16.3026\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 12.7539 - val_loss: 16.2915\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 12.7438 - val_loss: 16.2806\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 12.7336 - val_loss: 16.2695\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 12.7234 - val_loss: 16.2584\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 12.7133 - val_loss: 16.2476\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 12.7032 - val_loss: 16.2365\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 12.6930 - val_loss: 16.2256\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 12.6828 - val_loss: 16.2146\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 12.6727 - val_loss: 16.2037\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 12.6626 - val_loss: 16.1927\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 12.6525 - val_loss: 16.1817\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 12.6423 - val_loss: 16.1708\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 12.6321 - val_loss: 16.1598\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 12.6220 - val_loss: 16.1489\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 12.6119 - val_loss: 16.1379\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 12.6018 - val_loss: 16.1269\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 12.5917 - val_loss: 16.1160\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 12.5815 - val_loss: 16.1049\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 12.5714 - val_loss: 16.0938\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 12.5613 - val_loss: 16.0828\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 12.5511 - val_loss: 16.0718\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 12.5410 - val_loss: 16.0608\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 12.5309 - val_loss: 16.0497\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 12.5209 - val_loss: 16.0386\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 12.5108 - val_loss: 16.0277\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 12.5006 - val_loss: 16.0166\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 12.4905 - val_loss: 16.0056\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 12.4804 - val_loss: 15.9947\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 12.4703 - val_loss: 15.9836\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 12.4602 - val_loss: 15.9726\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 12.4502 - val_loss: 15.9617\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 12.4401 - val_loss: 15.9507\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 12.4300 - val_loss: 15.9397\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 12.4199 - val_loss: 15.9288\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 12.4099 - val_loss: 15.9178\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 12.3997 - val_loss: 15.9068\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 12.3897 - val_loss: 15.8958\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 12.3796 - val_loss: 15.8848\n",
            "Epoch 885/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 12.3696 - val_loss: 15.8740\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 12.3595 - val_loss: 15.8629\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 12.3494 - val_loss: 15.8519\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 12.3394 - val_loss: 15.8409\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 12.3293 - val_loss: 15.8300\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 12.3193 - val_loss: 15.8190\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 12.3092 - val_loss: 15.8081\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 12.2992 - val_loss: 15.7972\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 12.2891 - val_loss: 15.7862\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 12.2791 - val_loss: 15.7754\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 12.2690 - val_loss: 15.7645\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 12.2590 - val_loss: 15.7536\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 12.2490 - val_loss: 15.7427\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 12.2390 - val_loss: 15.7318\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 12.2290 - val_loss: 15.7210\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 12.2189 - val_loss: 15.7101\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 12.2089 - val_loss: 15.6991\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 12.1988 - val_loss: 15.6883\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 12.1888 - val_loss: 15.6774\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 12.1788 - val_loss: 15.6666\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 12.1688 - val_loss: 15.6557\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 12.1588 - val_loss: 15.6447\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 12.1488 - val_loss: 15.6339\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 12.1388 - val_loss: 15.6230\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 12.1288 - val_loss: 15.6121\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 12.1188 - val_loss: 15.6012\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 12.1088 - val_loss: 15.5903\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 12.0988 - val_loss: 15.5794\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 12.0888 - val_loss: 15.5685\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 12.0788 - val_loss: 15.5576\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 12.0688 - val_loss: 15.5467\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 12.0589 - val_loss: 15.5358\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 12.0489 - val_loss: 15.5249\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 12.0389 - val_loss: 15.5140\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 12.0290 - val_loss: 15.5031\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 12.0190 - val_loss: 15.4921\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 12.0090 - val_loss: 15.4812\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 11.9990 - val_loss: 15.4704\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 11.9891 - val_loss: 15.4594\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 11.9791 - val_loss: 15.4485\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 11.9692 - val_loss: 15.4376\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 11.9593 - val_loss: 15.4268\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 11.9493 - val_loss: 15.4158\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 11.9393 - val_loss: 15.4049\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 11.9294 - val_loss: 15.3939\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 11.9194 - val_loss: 15.3829\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 11.9096 - val_loss: 15.3721\n",
            "Epoch 932/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 11.8996 - val_loss: 15.3612\n",
            "Epoch 933/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 11.8897 - val_loss: 15.3503\n",
            "Epoch 934/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 11.8797 - val_loss: 15.3395\n",
            "Epoch 935/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 11.8698 - val_loss: 15.3287\n",
            "Epoch 936/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 11.8598 - val_loss: 15.3179\n",
            "Epoch 937/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 11.8499 - val_loss: 15.3071\n",
            "Epoch 938/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 11.8400 - val_loss: 15.2963\n",
            "Epoch 939/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 11.8301 - val_loss: 15.2855\n",
            "Epoch 940/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 11.8202 - val_loss: 15.2747\n",
            "Epoch 941/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 11.8103 - val_loss: 15.2639\n",
            "Epoch 942/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 11.8003 - val_loss: 15.2531\n",
            "Epoch 943/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 11.7905 - val_loss: 15.2424\n",
            "Epoch 944/1000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 11.7806 - val_loss: 15.2315\n",
            "Epoch 945/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 11.7707 - val_loss: 15.2207\n",
            "Epoch 946/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 11.7608 - val_loss: 15.2100\n",
            "Epoch 947/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 11.7509 - val_loss: 15.1992\n",
            "Epoch 948/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 11.7410 - val_loss: 15.1883\n",
            "Epoch 949/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 11.7311 - val_loss: 15.1777\n",
            "Epoch 950/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 11.7212 - val_loss: 15.1667\n",
            "Epoch 951/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 11.7113 - val_loss: 15.1560\n",
            "Epoch 952/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 11.7015 - val_loss: 15.1452\n",
            "Epoch 953/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 11.6916 - val_loss: 15.1343\n",
            "Epoch 954/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 11.6817 - val_loss: 15.1235\n",
            "Epoch 955/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 11.6719 - val_loss: 15.1127\n",
            "Epoch 956/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 11.6620 - val_loss: 15.1019\n",
            "Epoch 957/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 11.6522 - val_loss: 15.0911\n",
            "Epoch 958/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 11.6423 - val_loss: 15.0802\n",
            "Epoch 959/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 11.6325 - val_loss: 15.0694\n",
            "Epoch 960/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 11.6226 - val_loss: 15.0586\n",
            "Epoch 961/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 11.6127 - val_loss: 15.0477\n",
            "Epoch 962/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 11.6029 - val_loss: 15.0370\n",
            "Epoch 963/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 11.5930 - val_loss: 15.0261\n",
            "Epoch 964/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 11.5832 - val_loss: 15.0153\n",
            "Epoch 965/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 11.5734 - val_loss: 15.0046\n",
            "Epoch 966/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 11.5635 - val_loss: 14.9937\n",
            "Epoch 967/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 11.5537 - val_loss: 14.9829\n",
            "Epoch 968/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 11.5439 - val_loss: 14.9721\n",
            "Epoch 969/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 11.5341 - val_loss: 14.9614\n",
            "Epoch 970/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 11.5243 - val_loss: 14.9505\n",
            "Epoch 971/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 11.5144 - val_loss: 14.9398\n",
            "Epoch 972/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 11.5046 - val_loss: 14.9291\n",
            "Epoch 973/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 11.4948 - val_loss: 14.9183\n",
            "Epoch 974/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 11.4850 - val_loss: 14.9076\n",
            "Epoch 975/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 11.4752 - val_loss: 14.8968\n",
            "Epoch 976/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 11.4654 - val_loss: 14.8862\n",
            "Epoch 977/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 11.4556 - val_loss: 14.8755\n",
            "Epoch 978/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 11.4458 - val_loss: 14.8648\n",
            "Epoch 979/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 11.4360 - val_loss: 14.8541\n",
            "Epoch 980/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 11.4262 - val_loss: 14.8434\n",
            "Epoch 981/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 11.4164 - val_loss: 14.8327\n",
            "Epoch 982/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 11.4066 - val_loss: 14.8220\n",
            "Epoch 983/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 11.3969 - val_loss: 14.8112\n",
            "Epoch 984/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 11.3871 - val_loss: 14.8006\n",
            "Epoch 985/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 11.3773 - val_loss: 14.7899\n",
            "Epoch 986/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 11.3676 - val_loss: 14.7794\n",
            "Epoch 987/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 11.3578 - val_loss: 14.7685\n",
            "Epoch 988/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 11.3481 - val_loss: 14.7578\n",
            "Epoch 989/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 11.3382 - val_loss: 14.7472\n",
            "Epoch 990/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 11.3285 - val_loss: 14.7364\n",
            "Epoch 991/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 11.3188 - val_loss: 14.7257\n",
            "Epoch 992/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 11.3090 - val_loss: 14.7151\n",
            "Epoch 993/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 11.2992 - val_loss: 14.7042\n",
            "Epoch 994/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 11.2895 - val_loss: 14.6936\n",
            "Epoch 995/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 11.2797 - val_loss: 14.6827\n",
            "Epoch 996/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 11.2700 - val_loss: 14.6720\n",
            "Epoch 997/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 11.2603 - val_loss: 14.6613\n",
            "Epoch 998/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 11.2505 - val_loss: 14.6507\n",
            "Epoch 999/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 11.2408 - val_loss: 14.6400\n",
            "Epoch 1000/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 11.2311 - val_loss: 14.6293\n",
            "Epoch 1/1000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 71.7113 - val_loss: 66.1115\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 68.0924 - val_loss: 61.7353\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 63.3994 - val_loss: 56.8830\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 58.2052 - val_loss: 51.8572\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 52.8368 - val_loss: 46.8538\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 47.5054 - val_loss: 42.0027\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 42.3510 - val_loss: 37.3891\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 37.4644 - val_loss: 33.4379\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 33.5063 - val_loss: 31.2612\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 31.0812 - val_loss: 29.1992\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 28.8961 - val_loss: 27.2544\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 26.8582 - val_loss: 25.4264\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 24.9528 - val_loss: 23.7125\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 23.1721 - val_loss: 22.1086\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 21.5102 - val_loss: 20.6157\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 19.9600 - val_loss: 20.1073\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 19.4837 - val_loss: 20.0349\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 19.3903 - val_loss: 19.9646\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 19.3209 - val_loss: 19.8963\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 19.2575 - val_loss: 19.8297\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 19.1971 - val_loss: 19.7717\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 19.1373 - val_loss: 19.7142\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 19.0779 - val_loss: 19.6571\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 19.0190 - val_loss: 19.6003\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 18.9605 - val_loss: 19.5440\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 18.9023 - val_loss: 19.4880\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 18.8446 - val_loss: 19.4323\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 18.7871 - val_loss: 19.3769\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 18.7300 - val_loss: 19.3218\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 18.6731 - val_loss: 19.2669\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 18.6166 - val_loss: 19.2123\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 18.5603 - val_loss: 19.1579\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 18.5042 - val_loss: 19.1038\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 18.4484 - val_loss: 19.0498\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 18.3928 - val_loss: 18.9961\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 18.3374 - val_loss: 18.9426\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 18.2822 - val_loss: 18.8892\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 18.2273 - val_loss: 18.8361\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 18.1725 - val_loss: 18.7831\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 18.1179 - val_loss: 18.7303\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 18.0635 - val_loss: 18.6776\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 18.0092 - val_loss: 18.6251\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 17.9552 - val_loss: 18.5728\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 17.9013 - val_loss: 18.5206\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 17.8475 - val_loss: 18.4686\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 17.7939 - val_loss: 18.4167\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 17.7405 - val_loss: 18.3649\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 17.6872 - val_loss: 18.3133\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 17.6341 - val_loss: 18.2618\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 17.5811 - val_loss: 18.2104\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 17.5282 - val_loss: 18.1592\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 17.4755 - val_loss: 18.1081\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 17.4230 - val_loss: 18.0572\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 17.3705 - val_loss: 18.0063\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 17.3182 - val_loss: 17.9557\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 17.2661 - val_loss: 17.9051\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 17.2141 - val_loss: 17.8546\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 17.1622 - val_loss: 17.8043\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 17.1104 - val_loss: 17.7541\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 17.0588 - val_loss: 17.7040\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 17.0073 - val_loss: 17.6540\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 16.9559 - val_loss: 17.6042\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 16.9047 - val_loss: 17.5545\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 16.8536 - val_loss: 17.5049\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 16.8026 - val_loss: 17.4554\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 16.7517 - val_loss: 17.4060\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 16.7010 - val_loss: 17.3568\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 16.6504 - val_loss: 17.3076\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 16.5999 - val_loss: 17.2586\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 16.5496 - val_loss: 17.2097\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 16.4993 - val_loss: 17.1609\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 16.4492 - val_loss: 17.1122\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 16.3993 - val_loss: 17.0636\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 16.3494 - val_loss: 17.0152\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 16.2996 - val_loss: 16.9668\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 16.2500 - val_loss: 16.9186\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 16.2005 - val_loss: 16.8705\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 16.1511 - val_loss: 16.8225\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 16.1019 - val_loss: 16.7746\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 16.0528 - val_loss: 16.7269\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 16.0037 - val_loss: 16.6792\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 15.9549 - val_loss: 16.6316\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 15.9061 - val_loss: 16.5842\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 15.8574 - val_loss: 16.5369\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 15.8089 - val_loss: 16.4897\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 15.7605 - val_loss: 16.4426\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 15.7122 - val_loss: 16.3956\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 15.6640 - val_loss: 16.3487\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 15.6159 - val_loss: 16.3019\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 15.5680 - val_loss: 16.2553\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 15.5202 - val_loss: 16.2087\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 15.4725 - val_loss: 16.1623\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 15.4249 - val_loss: 16.1159\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 15.3774 - val_loss: 16.0697\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 15.3301 - val_loss: 16.0236\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 15.2829 - val_loss: 15.9776\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 15.2357 - val_loss: 15.9317\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 15.1887 - val_loss: 15.8859\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 15.1418 - val_loss: 15.8402\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 15.0951 - val_loss: 15.7947\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 15.0484 - val_loss: 15.7492\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 15.0019 - val_loss: 15.7038\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 14.9555 - val_loss: 15.6586\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 14.9091 - val_loss: 15.6135\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 14.8630 - val_loss: 15.5684\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 14.8169 - val_loss: 15.5235\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 14.7709 - val_loss: 15.4787\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 14.7251 - val_loss: 15.4339\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 14.6793 - val_loss: 15.3893\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 14.6337 - val_loss: 15.3448\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 14.5882 - val_loss: 15.3004\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 14.5428 - val_loss: 15.2561\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 14.4975 - val_loss: 15.2120\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 14.4524 - val_loss: 15.1679\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 14.4073 - val_loss: 15.1239\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 14.3624 - val_loss: 15.0801\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 14.3176 - val_loss: 15.0363\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 14.2729 - val_loss: 14.9926\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 14.2282 - val_loss: 14.9491\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 14.1838 - val_loss: 14.9056\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 14.1394 - val_loss: 14.8623\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 14.0951 - val_loss: 14.8191\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 14.0510 - val_loss: 14.7759\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 14.0069 - val_loss: 14.7329\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 13.9630 - val_loss: 14.6900\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 13.9192 - val_loss: 14.6471\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 13.8755 - val_loss: 14.6044\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 13.8319 - val_loss: 14.5618\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 13.7884 - val_loss: 14.5193\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 13.7450 - val_loss: 14.4769\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 13.7017 - val_loss: 14.4346\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 13.6586 - val_loss: 14.3923\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 13.6155 - val_loss: 14.3502\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 13.5726 - val_loss: 14.3082\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 13.5297 - val_loss: 14.2663\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 13.4870 - val_loss: 14.2245\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 13.4444 - val_loss: 14.1828\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 13.4019 - val_loss: 14.1412\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 13.3595 - val_loss: 14.0997\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 13.3172 - val_loss: 14.0584\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 13.2750 - val_loss: 14.0171\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 13.2330 - val_loss: 13.9759\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 13.1910 - val_loss: 13.9348\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 13.1492 - val_loss: 13.8938\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 13.1074 - val_loss: 13.8529\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 13.0658 - val_loss: 13.8121\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 13.0243 - val_loss: 13.7714\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 12.9828 - val_loss: 13.7308\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 12.9415 - val_loss: 13.6903\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 12.9003 - val_loss: 13.6500\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 12.8592 - val_loss: 13.6097\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 12.8182 - val_loss: 13.5695\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 12.7773 - val_loss: 13.5294\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 12.7365 - val_loss: 13.4894\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 12.6958 - val_loss: 13.4495\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 12.6552 - val_loss: 13.4097\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 12.6148 - val_loss: 13.3700\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 12.5744 - val_loss: 13.3304\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 12.5341 - val_loss: 13.2909\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 12.4940 - val_loss: 13.2515\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 12.4539 - val_loss: 13.2122\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 12.4140 - val_loss: 13.1729\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 12.3741 - val_loss: 13.1338\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 12.3344 - val_loss: 13.0948\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 12.2947 - val_loss: 13.0559\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 12.2552 - val_loss: 13.0170\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 12.2158 - val_loss: 12.9783\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 12.1764 - val_loss: 12.9397\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 12.1372 - val_loss: 12.9012\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 12.0981 - val_loss: 12.8627\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 12.0591 - val_loss: 12.8244\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 12.0202 - val_loss: 12.7861\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 11.9813 - val_loss: 12.7480\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 11.9426 - val_loss: 12.7099\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 11.9040 - val_loss: 12.6720\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 11.8655 - val_loss: 12.6341\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 11.8271 - val_loss: 12.5963\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 11.7888 - val_loss: 12.5586\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 11.7506 - val_loss: 12.5211\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 11.7125 - val_loss: 12.4836\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 11.6745 - val_loss: 12.4462\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 11.6366 - val_loss: 12.4089\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 11.5988 - val_loss: 12.3717\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 11.5611 - val_loss: 12.3345\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 11.5234 - val_loss: 12.2975\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 11.4859 - val_loss: 12.2606\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 11.4485 - val_loss: 12.2238\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 11.4112 - val_loss: 12.1870\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 11.3740 - val_loss: 12.1504\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 11.3369 - val_loss: 12.1138\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 11.2999 - val_loss: 12.0773\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 11.2630 - val_loss: 12.0410\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 11.2262 - val_loss: 12.0047\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 11.1894 - val_loss: 11.9685\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 11.1528 - val_loss: 11.9324\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 11.1163 - val_loss: 11.8964\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 11.0799 - val_loss: 11.8605\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 11.0436 - val_loss: 11.8247\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 11.0073 - val_loss: 11.7889\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 10.9712 - val_loss: 11.7533\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 10.9352 - val_loss: 11.7177\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 10.8992 - val_loss: 11.6823\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 10.8634 - val_loss: 11.6469\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 10.8277 - val_loss: 11.6117\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 10.7920 - val_loss: 11.5765\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 10.7565 - val_loss: 11.5414\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 10.7210 - val_loss: 11.5064\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 10.6857 - val_loss: 11.4715\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 10.6504 - val_loss: 11.4366\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 10.6152 - val_loss: 11.4019\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 10.5802 - val_loss: 11.3672\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 10.5452 - val_loss: 11.3327\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 10.5103 - val_loss: 11.2982\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 10.4755 - val_loss: 11.2638\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 10.4408 - val_loss: 11.2295\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 10.4062 - val_loss: 11.1953\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 10.3717 - val_loss: 11.1612\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 10.3373 - val_loss: 11.1272\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 10.3030 - val_loss: 11.0932\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 10.2688 - val_loss: 11.0594\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 10.2346 - val_loss: 11.0256\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 10.2006 - val_loss: 10.9919\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 10.1666 - val_loss: 10.9583\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 10.1328 - val_loss: 10.9248\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 10.0990 - val_loss: 10.8914\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 10.0654 - val_loss: 10.8581\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 10.0318 - val_loss: 10.8248\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 9.9983 - val_loss: 10.7917\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 9.9649 - val_loss: 10.7586\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 9.9316 - val_loss: 10.7256\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 9.8984 - val_loss: 10.6927\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 9.8653 - val_loss: 10.6599\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 9.8322 - val_loss: 10.6271\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 9.7993 - val_loss: 10.5945\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 9.7665 - val_loss: 10.5619\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 9.7337 - val_loss: 10.5295\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 9.7010 - val_loss: 10.4971\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 9.6685 - val_loss: 10.4648\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 9.6360 - val_loss: 10.4325\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 9.6036 - val_loss: 10.4004\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 9.5713 - val_loss: 10.3684\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 9.5391 - val_loss: 10.3364\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 9.5069 - val_loss: 10.3045\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 9.4749 - val_loss: 10.2727\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 9.4430 - val_loss: 10.2410\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 9.4111 - val_loss: 10.2093\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 9.3793 - val_loss: 10.1778\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 9.3477 - val_loss: 10.1463\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 9.3161 - val_loss: 10.1149\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 9.2845 - val_loss: 10.0836\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 9.2531 - val_loss: 10.0524\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 9.2218 - val_loss: 10.0213\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 9.1906 - val_loss: 9.9902\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 9.1594 - val_loss: 9.9592\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 9.1283 - val_loss: 9.9283\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 9.0974 - val_loss: 9.8975\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 9.0665 - val_loss: 9.8668\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 9.0357 - val_loss: 9.8362\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 9.0049 - val_loss: 9.8056\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 8.9743 - val_loss: 9.7751\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 8.9437 - val_loss: 9.7447\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 8.9133 - val_loss: 9.7144\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 8.8829 - val_loss: 9.6841\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 8.8526 - val_loss: 9.6540\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 8.8224 - val_loss: 9.6239\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 8.7923 - val_loss: 9.5939\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 8.7623 - val_loss: 9.5640\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 8.7323 - val_loss: 9.5341\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 8.7024 - val_loss: 9.5044\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 8.6727 - val_loss: 9.4747\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 8.6430 - val_loss: 9.4451\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 8.6134 - val_loss: 9.4156\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 8.5838 - val_loss: 9.3861\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 8.5544 - val_loss: 9.3567\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 8.5250 - val_loss: 9.3275\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 8.4957 - val_loss: 9.2983\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 8.4666 - val_loss: 9.2691\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 8.4374 - val_loss: 9.2401\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 8.4084 - val_loss: 9.2111\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 8.3795 - val_loss: 9.1822\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 8.3506 - val_loss: 9.1534\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 8.3218 - val_loss: 9.1247\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 8.2931 - val_loss: 9.0960\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 8.2645 - val_loss: 9.0674\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 8.2360 - val_loss: 9.0389\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 8.2075 - val_loss: 9.0105\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 8.1792 - val_loss: 8.9821\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 8.1509 - val_loss: 8.9538\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 8.1227 - val_loss: 8.9257\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 8.0946 - val_loss: 8.8975\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 8.0665 - val_loss: 8.8695\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 8.0386 - val_loss: 8.8415\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 8.0107 - val_loss: 8.8136\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 7.9829 - val_loss: 8.7858\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 7.9551 - val_loss: 8.7581\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7.9275 - val_loss: 8.7304\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7.8999 - val_loss: 8.7028\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7.8725 - val_loss: 8.6753\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7.8451 - val_loss: 8.6478\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7.8177 - val_loss: 8.6205\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 7.7905 - val_loss: 8.5932\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7.7633 - val_loss: 8.5660\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7.7362 - val_loss: 8.5388\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7.7092 - val_loss: 8.5118\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7.6823 - val_loss: 8.4848\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7.6555 - val_loss: 8.4578\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7.6287 - val_loss: 8.4310\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7.6020 - val_loss: 8.4042\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.5754 - val_loss: 8.3775\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7.5488 - val_loss: 8.3509\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7.5224 - val_loss: 8.3243\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7.4960 - val_loss: 8.2979\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 7.4697 - val_loss: 8.2714\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 7.4435 - val_loss: 8.2451\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7.4173 - val_loss: 8.2188\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7.3912 - val_loss: 8.1927\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 7.3652 - val_loss: 8.1665\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.3393 - val_loss: 8.1405\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 7.3135 - val_loss: 8.1145\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7.2877 - val_loss: 8.0886\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7.2620 - val_loss: 8.0628\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7.2364 - val_loss: 8.0370\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 7.2108 - val_loss: 8.0113\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7.1854 - val_loss: 7.9857\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 7.1600 - val_loss: 7.9602\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.1347 - val_loss: 7.9347\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 7.1094 - val_loss: 7.9093\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 7.0843 - val_loss: 7.8840\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 7.0592 - val_loss: 7.8587\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.0341 - val_loss: 7.8335\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.0092 - val_loss: 7.8084\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 6.9843 - val_loss: 7.7833\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 6.9595 - val_loss: 7.7584\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 6.9348 - val_loss: 7.7334\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 6.9102 - val_loss: 7.7086\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.8856 - val_loss: 7.6838\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 6.8611 - val_loss: 7.6591\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 6.8367 - val_loss: 7.6345\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6.8123 - val_loss: 7.6099\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6.7880 - val_loss: 7.5854\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.7638 - val_loss: 7.5610\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6.7397 - val_loss: 7.5366\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 6.7156 - val_loss: 7.5124\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 6.6916 - val_loss: 7.4881\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6.6677 - val_loss: 7.4640\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6.6438 - val_loss: 7.4399\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 6.6201 - val_loss: 7.4159\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6.5964 - val_loss: 7.3919\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6.5727 - val_loss: 7.3681\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6.5492 - val_loss: 7.3442\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6.5257 - val_loss: 7.3205\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6.5022 - val_loss: 7.2968\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6.4789 - val_loss: 7.2732\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6.4556 - val_loss: 7.2496\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 6.4324 - val_loss: 7.2262\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.4093 - val_loss: 7.2027\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.3862 - val_loss: 7.1794\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6.3632 - val_loss: 7.1561\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 6.3403 - val_loss: 7.1329\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.3174 - val_loss: 7.1098\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6.2946 - val_loss: 7.0867\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6.2719 - val_loss: 7.0636\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6.2492 - val_loss: 7.0407\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 6.2267 - val_loss: 7.0178\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6.2041 - val_loss: 6.9950\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6.1817 - val_loss: 6.9722\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 6.1593 - val_loss: 6.9495\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 6.1370 - val_loss: 6.9269\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 6.1148 - val_loss: 6.9044\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 6.0926 - val_loss: 6.8819\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6.0705 - val_loss: 6.8594\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 6.0484 - val_loss: 6.8370\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 6.0265 - val_loss: 6.8147\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.0046 - val_loss: 6.7925\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 5.9827 - val_loss: 6.7703\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 5.9610 - val_loss: 6.7482\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 5.9392 - val_loss: 6.7262\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 5.9176 - val_loss: 6.7042\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.8960 - val_loss: 6.6822\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 5.8745 - val_loss: 6.6604\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5.8531 - val_loss: 6.6386\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5.8317 - val_loss: 6.6168\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 5.8104 - val_loss: 6.5952\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5.7892 - val_loss: 6.5736\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 5.7680 - val_loss: 6.5520\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 5.7469 - val_loss: 6.5305\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 5.7259 - val_loss: 6.5091\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.7049 - val_loss: 6.4878\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 5.6840 - val_loss: 6.4665\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5.6631 - val_loss: 6.4452\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.6424 - val_loss: 6.4240\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5.6216 - val_loss: 6.4029\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5.6010 - val_loss: 6.3819\n",
            "Epoch 394/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.5804 - val_loss: 6.3609\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.5599 - val_loss: 6.3399\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 5.5394 - val_loss: 6.3191\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5.5190 - val_loss: 6.2983\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 5.4987 - val_loss: 6.2775\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.4784 - val_loss: 6.2568\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.4582 - val_loss: 6.2362\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.4381 - val_loss: 6.2156\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.4180 - val_loss: 6.1951\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 5.3980 - val_loss: 6.1747\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5.3780 - val_loss: 6.1543\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5.3581 - val_loss: 6.1339\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 5.3383 - val_loss: 6.1137\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 5.3185 - val_loss: 6.0935\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.2988 - val_loss: 6.0733\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5.2792 - val_loss: 6.0532\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 5.2596 - val_loss: 6.0332\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 5.2401 - val_loss: 6.0132\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 5.2206 - val_loss: 5.9933\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5.2012 - val_loss: 5.9734\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 5.1819 - val_loss: 5.9536\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.1626 - val_loss: 5.9339\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.1434 - val_loss: 5.9142\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5.1242 - val_loss: 5.8946\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5.1052 - val_loss: 5.8750\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5.0861 - val_loss: 5.8555\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5.0672 - val_loss: 5.8361\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 5.0482 - val_loss: 5.8167\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 5.0294 - val_loss: 5.7973\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 5.0106 - val_loss: 5.7780\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 4.9919 - val_loss: 5.7588\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 4.9732 - val_loss: 5.7397\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.9546 - val_loss: 5.7205\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.9360 - val_loss: 5.7015\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.9175 - val_loss: 5.6825\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.8991 - val_loss: 5.6636\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 4.8807 - val_loss: 5.6447\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.8624 - val_loss: 5.6258\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.8442 - val_loss: 5.6071\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.8260 - val_loss: 5.5884\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.8078 - val_loss: 5.5697\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.7897 - val_loss: 5.5511\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.7717 - val_loss: 5.5325\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.7538 - val_loss: 5.5141\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 4.7359 - val_loss: 5.4956\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.7180 - val_loss: 5.4772\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.7002 - val_loss: 5.4589\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.6825 - val_loss: 5.4406\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 4.6648 - val_loss: 5.4224\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.6472 - val_loss: 5.4042\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.6296 - val_loss: 5.3861\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 4.6121 - val_loss: 5.3681\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.5946 - val_loss: 5.3501\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 4.5773 - val_loss: 5.3321\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 4.5599 - val_loss: 5.3142\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.5426 - val_loss: 5.2964\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.5254 - val_loss: 5.2786\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.5082 - val_loss: 5.2609\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.4911 - val_loss: 5.2432\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.4741 - val_loss: 5.2256\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.4571 - val_loss: 5.2080\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.4401 - val_loss: 5.1905\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.4232 - val_loss: 5.1730\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.4064 - val_loss: 5.1556\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.3896 - val_loss: 5.1382\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.3729 - val_loss: 5.1209\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.3562 - val_loss: 5.1037\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.3396 - val_loss: 5.0865\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.3230 - val_loss: 5.0693\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.3065 - val_loss: 5.0522\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.2901 - val_loss: 5.0352\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.2737 - val_loss: 5.0182\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 4.2573 - val_loss: 5.0012\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 4.2410 - val_loss: 4.9843\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 4.2248 - val_loss: 4.9675\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.2086 - val_loss: 4.9507\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 4.1925 - val_loss: 4.9340\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.1764 - val_loss: 4.9173\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.1603 - val_loss: 4.9006\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.1444 - val_loss: 4.8840\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 4.1285 - val_loss: 4.8675\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 4.1126 - val_loss: 4.8510\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.0968 - val_loss: 4.8346\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.0810 - val_loss: 4.8182\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.0653 - val_loss: 4.8019\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 4.0496 - val_loss: 4.7856\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 4.0340 - val_loss: 4.7693\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 4.0185 - val_loss: 4.7531\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 4.0030 - val_loss: 4.7370\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.9875 - val_loss: 4.7209\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.9721 - val_loss: 4.7049\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.9567 - val_loss: 4.6889\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.9414 - val_loss: 4.6730\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.9262 - val_loss: 4.6571\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.9110 - val_loss: 4.6412\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.8959 - val_loss: 4.6254\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.8808 - val_loss: 4.6097\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.8657 - val_loss: 4.5940\n",
            "Epoch 492/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.8507 - val_loss: 4.5783\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.8358 - val_loss: 4.5627\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.8209 - val_loss: 4.5472\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.8060 - val_loss: 4.5317\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.7912 - val_loss: 4.5162\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.7765 - val_loss: 4.5008\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.7618 - val_loss: 4.4855\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.7471 - val_loss: 4.4702\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.7326 - val_loss: 4.4549\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.7180 - val_loss: 4.4397\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3.7035 - val_loss: 4.4245\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.6891 - val_loss: 4.4094\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.6747 - val_loss: 4.3943\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.6603 - val_loss: 4.3793\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.6460 - val_loss: 4.3643\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.6317 - val_loss: 4.3494\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 3.6175 - val_loss: 4.3345\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.6034 - val_loss: 4.3196\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3.5893 - val_loss: 4.3048\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.5752 - val_loss: 4.2901\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.5612 - val_loss: 4.2754\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.5472 - val_loss: 4.2607\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 3.5333 - val_loss: 4.2461\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.5194 - val_loss: 4.2315\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.5056 - val_loss: 4.2170\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 3.4918 - val_loss: 4.2025\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.4781 - val_loss: 4.1881\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.4644 - val_loss: 4.1737\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.4508 - val_loss: 4.1594\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.4372 - val_loss: 4.1451\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.4236 - val_loss: 4.1308\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.4101 - val_loss: 4.1166\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.3967 - val_loss: 4.1025\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.3833 - val_loss: 4.0883\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.3699 - val_loss: 4.0743\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3.3566 - val_loss: 4.0602\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3.3433 - val_loss: 4.0463\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.3301 - val_loss: 4.0323\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.3169 - val_loss: 4.0184\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.3038 - val_loss: 4.0046\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.2907 - val_loss: 3.9908\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.2777 - val_loss: 3.9770\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.2647 - val_loss: 3.9633\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.2517 - val_loss: 3.9496\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.2388 - val_loss: 3.9360\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.2259 - val_loss: 3.9224\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.2131 - val_loss: 3.9088\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.2003 - val_loss: 3.8953\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.1876 - val_loss: 3.8819\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3.1749 - val_loss: 3.8684\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.1623 - val_loss: 3.8551\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.1497 - val_loss: 3.8417\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.1371 - val_loss: 3.8284\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.1246 - val_loss: 3.8152\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.1122 - val_loss: 3.8020\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.0997 - val_loss: 3.7888\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.0874 - val_loss: 3.7757\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.0750 - val_loss: 3.7626\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.0627 - val_loss: 3.7496\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.0505 - val_loss: 3.7366\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.0383 - val_loss: 3.7236\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.0261 - val_loss: 3.7107\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.0140 - val_loss: 3.6978\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.0019 - val_loss: 3.6850\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.9899 - val_loss: 3.6722\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.9779 - val_loss: 3.6594\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.9659 - val_loss: 3.6467\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.9540 - val_loss: 3.6341\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.9421 - val_loss: 3.6214\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.9303 - val_loss: 3.6088\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.9185 - val_loss: 3.5963\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.9068 - val_loss: 3.5838\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.8951 - val_loss: 3.5713\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.8834 - val_loss: 3.5589\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.8718 - val_loss: 3.5465\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.8602 - val_loss: 3.5341\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.8487 - val_loss: 3.5218\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.8372 - val_loss: 3.5096\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.8257 - val_loss: 3.4973\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.8143 - val_loss: 3.4852\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.8029 - val_loss: 3.4730\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.7916 - val_loss: 3.4609\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7803 - val_loss: 3.4488\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.7690 - val_loss: 3.4368\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.7578 - val_loss: 3.4248\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.7466 - val_loss: 3.4128\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.7355 - val_loss: 3.4009\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.7244 - val_loss: 3.3890\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.7133 - val_loss: 3.3772\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.7023 - val_loss: 3.3654\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.6913 - val_loss: 3.3536\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.6804 - val_loss: 3.3419\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.6695 - val_loss: 3.3302\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.6586 - val_loss: 3.3186\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.6478 - val_loss: 3.3070\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.6370 - val_loss: 3.2954\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.6263 - val_loss: 3.2839\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.6156 - val_loss: 3.2724\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.6049 - val_loss: 3.2609\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.5943 - val_loss: 3.2495\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.5837 - val_loss: 3.2381\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.5732 - val_loss: 3.2268\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.5626 - val_loss: 3.2154\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.5522 - val_loss: 3.2042\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.5417 - val_loss: 3.1929\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.5313 - val_loss: 3.1817\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.5210 - val_loss: 3.1706\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.5106 - val_loss: 3.1594\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.5003 - val_loss: 3.1483\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.4901 - val_loss: 3.1373\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.4799 - val_loss: 3.1263\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.4697 - val_loss: 3.1153\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.4595 - val_loss: 3.1043\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.4494 - val_loss: 3.0934\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.4394 - val_loss: 3.0826\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.4293 - val_loss: 3.0717\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.4193 - val_loss: 3.0609\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.4094 - val_loss: 3.0501\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.3995 - val_loss: 3.0394\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.3896 - val_loss: 3.0287\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.3797 - val_loss: 3.0181\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.3699 - val_loss: 3.0074\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.3601 - val_loss: 2.9968\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.3504 - val_loss: 2.9863\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.3407 - val_loss: 2.9758\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.3310 - val_loss: 2.9653\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.3214 - val_loss: 2.9548\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.3118 - val_loss: 2.9444\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.3022 - val_loss: 2.9340\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.2927 - val_loss: 2.9237\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.2832 - val_loss: 2.9134\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.2737 - val_loss: 2.9031\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.2643 - val_loss: 2.8928\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.2549 - val_loss: 2.8826\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.2456 - val_loss: 2.8724\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.2362 - val_loss: 2.8623\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.2269 - val_loss: 2.8522\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.2177 - val_loss: 2.8421\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.2085 - val_loss: 2.8321\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.1993 - val_loss: 2.8221\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.1901 - val_loss: 2.8121\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.1810 - val_loss: 2.8022\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.1719 - val_loss: 2.7922\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.1629 - val_loss: 2.7824\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.1539 - val_loss: 2.7725\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.1449 - val_loss: 2.7627\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.1359 - val_loss: 2.7529\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.1270 - val_loss: 2.7432\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.1181 - val_loss: 2.7335\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.1093 - val_loss: 2.7238\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.1005 - val_loss: 2.7141\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.0917 - val_loss: 2.7045\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.0829 - val_loss: 2.6949\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.0742 - val_loss: 2.6854\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.0655 - val_loss: 2.6759\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.0569 - val_loss: 2.6664\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.0483 - val_loss: 2.6569\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.0397 - val_loss: 2.6475\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.0311 - val_loss: 2.6381\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.0226 - val_loss: 2.6288\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.0141 - val_loss: 2.6194\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.0056 - val_loss: 2.6101\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.9972 - val_loss: 2.6009\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.9888 - val_loss: 2.5916\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.9804 - val_loss: 2.5824\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.9721 - val_loss: 2.5733\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.9638 - val_loss: 2.5641\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.9555 - val_loss: 2.5550\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.9473 - val_loss: 2.5459\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.9391 - val_loss: 2.5369\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.9309 - val_loss: 2.5279\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.9228 - val_loss: 2.5189\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.9146 - val_loss: 2.5099\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.9066 - val_loss: 2.5010\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.8985 - val_loss: 2.4921\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.8905 - val_loss: 2.4832\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.8825 - val_loss: 2.4744\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.8745 - val_loss: 2.4656\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.8666 - val_loss: 2.4568\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.8587 - val_loss: 2.4481\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.8508 - val_loss: 2.4394\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.8430 - val_loss: 2.4307\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.8352 - val_loss: 2.4220\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.8274 - val_loss: 2.4134\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.8196 - val_loss: 2.4048\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.8119 - val_loss: 2.3962\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.8042 - val_loss: 2.3877\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.7965 - val_loss: 2.3792\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.7889 - val_loss: 2.3707\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.7813 - val_loss: 2.3622\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.7737 - val_loss: 2.3538\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.7662 - val_loss: 2.3454\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 1.7586 - val_loss: 2.3370\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.7511 - val_loss: 2.3287\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.7437 - val_loss: 2.3204\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.7362 - val_loss: 2.3121\n",
            "Epoch 688/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.7288 - val_loss: 2.3039\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.7215 - val_loss: 2.2956\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.7141 - val_loss: 2.2875\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.7068 - val_loss: 2.2793\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.6995 - val_loss: 2.2711\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.6922 - val_loss: 2.2630\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.6850 - val_loss: 2.2550\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.6778 - val_loss: 2.2469\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.6706 - val_loss: 2.2389\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.6635 - val_loss: 2.2309\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.6563 - val_loss: 2.2229\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.6492 - val_loss: 2.2149\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.6422 - val_loss: 2.2070\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.6351 - val_loss: 2.1991\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.6281 - val_loss: 2.1913\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.6211 - val_loss: 2.1834\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.6142 - val_loss: 2.1756\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.6072 - val_loss: 2.1678\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.6003 - val_loss: 2.1601\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.5935 - val_loss: 2.1524\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.5866 - val_loss: 2.1447\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.5798 - val_loss: 2.1370\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 1.5730 - val_loss: 2.1293\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.5662 - val_loss: 2.1217\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.5595 - val_loss: 2.1141\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.5527 - val_loss: 2.1066\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.5461 - val_loss: 2.0990\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.5394 - val_loss: 2.0915\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.5327 - val_loss: 2.0840\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.5261 - val_loss: 2.0765\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.5195 - val_loss: 2.0691\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.5130 - val_loss: 2.0617\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.5064 - val_loss: 2.0543\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.4999 - val_loss: 2.0469\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.4934 - val_loss: 2.0396\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.4870 - val_loss: 2.0323\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.4805 - val_loss: 2.0250\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 1.4741 - val_loss: 2.0177\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.4678 - val_loss: 2.0105\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.4614 - val_loss: 2.0033\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.4551 - val_loss: 1.9961\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.4488 - val_loss: 1.9890\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.4425 - val_loss: 1.9818\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.4362 - val_loss: 1.9747\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.4300 - val_loss: 1.9676\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.4238 - val_loss: 1.9606\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.4176 - val_loss: 1.9535\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.4114 - val_loss: 1.9465\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.4053 - val_loss: 1.9396\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.3992 - val_loss: 1.9326\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.3931 - val_loss: 1.9257\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.3870 - val_loss: 1.9187\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.3810 - val_loss: 1.9119\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.3750 - val_loss: 1.9050\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.3690 - val_loss: 1.8982\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.3630 - val_loss: 1.8913\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.3571 - val_loss: 1.8846\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.3512 - val_loss: 1.8778\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.3453 - val_loss: 1.8710\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.3394 - val_loss: 1.8643\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.3335 - val_loss: 1.8576\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.3277 - val_loss: 1.8510\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.3219 - val_loss: 1.8443\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.3161 - val_loss: 1.8377\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 1.3104 - val_loss: 1.8311\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.3047 - val_loss: 1.8245\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.2989 - val_loss: 1.8179\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.2933 - val_loss: 1.8114\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.2876 - val_loss: 1.8049\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.2820 - val_loss: 1.7984\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 1.2763 - val_loss: 1.7920\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.2707 - val_loss: 1.7855\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.2652 - val_loss: 1.7791\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.2596 - val_loss: 1.7727\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.2541 - val_loss: 1.7663\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.2486 - val_loss: 1.7600\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.2431 - val_loss: 1.7537\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.2376 - val_loss: 1.7474\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1.2322 - val_loss: 1.7411\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.2268 - val_loss: 1.7348\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.2214 - val_loss: 1.7286\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.2160 - val_loss: 1.7224\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.2107 - val_loss: 1.7162\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.2053 - val_loss: 1.7100\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.2000 - val_loss: 1.7038\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.1948 - val_loss: 1.6977\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.1895 - val_loss: 1.6916\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.1843 - val_loss: 1.6855\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.1790 - val_loss: 1.6795\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.1738 - val_loss: 1.6734\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.1687 - val_loss: 1.6674\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.1635 - val_loss: 1.6614\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.1584 - val_loss: 1.6554\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.1532 - val_loss: 1.6495\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1.1482 - val_loss: 1.6435\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.1431 - val_loss: 1.6376\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.1380 - val_loss: 1.6317\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.1330 - val_loss: 1.6259\n",
            "Epoch 786/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.1280 - val_loss: 1.6200\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.1230 - val_loss: 1.6142\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.1180 - val_loss: 1.6084\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.1131 - val_loss: 1.6026\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.1082 - val_loss: 1.5968\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.1032 - val_loss: 1.5911\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.0984 - val_loss: 1.5854\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.0935 - val_loss: 1.5797\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.0886 - val_loss: 1.5740\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.0838 - val_loss: 1.5683\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.0790 - val_loss: 1.5627\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.0742 - val_loss: 1.5571\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.0694 - val_loss: 1.5515\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.0647 - val_loss: 1.5459\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.0600 - val_loss: 1.5403\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.0553 - val_loss: 1.5348\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.0506 - val_loss: 1.5293\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.0459 - val_loss: 1.5238\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.0413 - val_loss: 1.5183\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.0366 - val_loss: 1.5128\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.0320 - val_loss: 1.5074\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.0274 - val_loss: 1.5020\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.0228 - val_loss: 1.4966\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.0183 - val_loss: 1.4912\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.0138 - val_loss: 1.4858\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.0092 - val_loss: 1.4805\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 1.0047 - val_loss: 1.4751\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.0003 - val_loss: 1.4698\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.9958 - val_loss: 1.4645\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.9914 - val_loss: 1.4593\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.9869 - val_loss: 1.4540\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.9825 - val_loss: 1.4488\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.9782 - val_loss: 1.4436\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.9738 - val_loss: 1.4384\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.9694 - val_loss: 1.4332\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.9651 - val_loss: 1.4281\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.9608 - val_loss: 1.4229\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.9565 - val_loss: 1.4178\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.9522 - val_loss: 1.4127\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.9480 - val_loss: 1.4077\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.9437 - val_loss: 1.4026\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.9395 - val_loss: 1.3976\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.9353 - val_loss: 1.3925\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.9311 - val_loss: 1.3875\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.9269 - val_loss: 1.3825\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.9228 - val_loss: 1.3776\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.9187 - val_loss: 1.3726\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.9145 - val_loss: 1.3677\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.9105 - val_loss: 1.3628\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.9064 - val_loss: 1.3579\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.9023 - val_loss: 1.3530\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.8983 - val_loss: 1.3481\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.8942 - val_loss: 1.3433\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.8902 - val_loss: 1.3385\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.8862 - val_loss: 1.3337\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.8822 - val_loss: 1.3289\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.8783 - val_loss: 1.3241\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.8743 - val_loss: 1.3193\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.8704 - val_loss: 1.3146\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.8665 - val_loss: 1.3099\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.8626 - val_loss: 1.3052\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.8587 - val_loss: 1.3005\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.8549 - val_loss: 1.2958\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.8510 - val_loss: 1.2912\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.8472 - val_loss: 1.2865\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.8434 - val_loss: 1.2819\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.8396 - val_loss: 1.2773\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.8358 - val_loss: 1.2727\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.8321 - val_loss: 1.2682\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.8283 - val_loss: 1.2636\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.8246 - val_loss: 1.2591\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.8209 - val_loss: 1.2546\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.8172 - val_loss: 1.2501\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.8135 - val_loss: 1.2456\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.8098 - val_loss: 1.2411\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.8062 - val_loss: 1.2367\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.8025 - val_loss: 1.2322\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.7989 - val_loss: 1.2278\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.7953 - val_loss: 1.2234\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.7917 - val_loss: 1.2190\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.7882 - val_loss: 1.2147\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.7846 - val_loss: 1.2103\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.7811 - val_loss: 1.2060\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.7775 - val_loss: 1.2017\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.7740 - val_loss: 1.1974\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.7705 - val_loss: 1.1931\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.7670 - val_loss: 1.1888\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.7636 - val_loss: 1.1845\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.7601 - val_loss: 1.1803\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.7567 - val_loss: 1.1761\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.7533 - val_loss: 1.1719\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.7499 - val_loss: 1.1677\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.7465 - val_loss: 1.1635\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.7431 - val_loss: 1.1593\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.7398 - val_loss: 1.1552\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.7364 - val_loss: 1.1511\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.7331 - val_loss: 1.1470\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.7298 - val_loss: 1.1429\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.7265 - val_loss: 1.1388\n",
            "Epoch 885/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.7232 - val_loss: 1.1347\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.7199 - val_loss: 1.1306\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.7166 - val_loss: 1.1266\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.7134 - val_loss: 1.1226\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.7102 - val_loss: 1.1186\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.7070 - val_loss: 1.1146\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.7038 - val_loss: 1.1106\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.7006 - val_loss: 1.1066\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6974 - val_loss: 1.1027\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6942 - val_loss: 1.0987\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6911 - val_loss: 1.0948\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6880 - val_loss: 1.0909\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6849 - val_loss: 1.0870\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6818 - val_loss: 1.0831\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6787 - val_loss: 1.0793\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6756 - val_loss: 1.0754\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6725 - val_loss: 1.0716\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6695 - val_loss: 1.0678\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6664 - val_loss: 1.0640\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6634 - val_loss: 1.0602\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6604 - val_loss: 1.0564\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6574 - val_loss: 1.0526\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6544 - val_loss: 1.0489\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.6515 - val_loss: 1.0452\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6485 - val_loss: 1.0414\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6456 - val_loss: 1.0377\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6426 - val_loss: 1.0340\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6397 - val_loss: 1.0304\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6368 - val_loss: 1.0267\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6339 - val_loss: 1.0230\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6311 - val_loss: 1.0194\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6282 - val_loss: 1.0158\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6253 - val_loss: 1.0122\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6225 - val_loss: 1.0086\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6197 - val_loss: 1.0050\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6169 - val_loss: 1.0014\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6141 - val_loss: 0.9979\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6113 - val_loss: 0.9943\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6085 - val_loss: 0.9908\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6057 - val_loss: 0.9873\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6030 - val_loss: 0.9838\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6003 - val_loss: 0.9803\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5975 - val_loss: 0.9768\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5948 - val_loss: 0.9733\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5921 - val_loss: 0.9699\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5894 - val_loss: 0.9665\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5868 - val_loss: 0.9630\n",
            "Epoch 932/1000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5841 - val_loss: 0.9596\n",
            "Epoch 933/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5814 - val_loss: 0.9562\n",
            "Epoch 934/1000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5788 - val_loss: 0.9528\n",
            "Epoch 935/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5762 - val_loss: 0.9495\n",
            "Epoch 936/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5736 - val_loss: 0.9461\n",
            "Epoch 937/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5710 - val_loss: 0.9428\n",
            "Epoch 938/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5684 - val_loss: 0.9394\n",
            "Epoch 939/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5658 - val_loss: 0.9361\n",
            "Epoch 940/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5632 - val_loss: 0.9328\n",
            "Epoch 941/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5607 - val_loss: 0.9295\n",
            "Epoch 942/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5581 - val_loss: 0.9262\n",
            "Epoch 943/1000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.5556 - val_loss: 0.9229\n",
            "Epoch 944/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5531 - val_loss: 0.9197\n",
            "Epoch 945/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5505 - val_loss: 0.9164\n",
            "Epoch 946/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5480 - val_loss: 0.9132\n",
            "Epoch 947/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5456 - val_loss: 0.9100\n",
            "Epoch 948/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5431 - val_loss: 0.9068\n",
            "Epoch 949/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5406 - val_loss: 0.9036\n",
            "Epoch 950/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5382 - val_loss: 0.9004\n",
            "Epoch 951/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5357 - val_loss: 0.8972\n",
            "Epoch 952/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5333 - val_loss: 0.8941\n",
            "Epoch 953/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5309 - val_loss: 0.8909\n",
            "Epoch 954/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5285 - val_loss: 0.8878\n",
            "Epoch 955/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5261 - val_loss: 0.8846\n",
            "Epoch 956/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5237 - val_loss: 0.8815\n",
            "Epoch 957/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5213 - val_loss: 0.8784\n",
            "Epoch 958/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5189 - val_loss: 0.8753\n",
            "Epoch 959/1000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5166 - val_loss: 0.8723\n",
            "Epoch 960/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5142 - val_loss: 0.8692\n",
            "Epoch 961/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5119 - val_loss: 0.8661\n",
            "Epoch 962/1000\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5096 - val_loss: 0.8631\n",
            "Epoch 963/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5073 - val_loss: 0.8601\n",
            "Epoch 964/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5050 - val_loss: 0.8570\n",
            "Epoch 965/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5027 - val_loss: 0.8540\n",
            "Epoch 966/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5004 - val_loss: 0.8510\n",
            "Epoch 967/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4981 - val_loss: 0.8480\n",
            "Epoch 968/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4959 - val_loss: 0.8451\n",
            "Epoch 969/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.4936 - val_loss: 0.8421\n",
            "Epoch 970/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4914 - val_loss: 0.8392\n",
            "Epoch 971/1000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.4892 - val_loss: 0.8362\n",
            "Epoch 972/1000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4869 - val_loss: 0.8333\n",
            "Epoch 973/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4847 - val_loss: 0.8304\n",
            "Epoch 974/1000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.4825 - val_loss: 0.8275\n",
            "Epoch 975/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.4804 - val_loss: 0.8246\n",
            "Epoch 976/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4782 - val_loss: 0.8217\n",
            "Epoch 977/1000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.4760 - val_loss: 0.8188\n",
            "Epoch 978/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4739 - val_loss: 0.8159\n",
            "Epoch 979/1000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.4717 - val_loss: 0.8131\n",
            "Epoch 980/1000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.4696 - val_loss: 0.8103\n",
            "Epoch 981/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4675 - val_loss: 0.8074\n",
            "Epoch 982/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4653 - val_loss: 0.8046\n",
            "Epoch 983/1000\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4632 - val_loss: 0.8018\n",
            "Epoch 984/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4611 - val_loss: 0.7990\n",
            "Epoch 985/1000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.4591 - val_loss: 0.7962\n",
            "Epoch 986/1000\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4570 - val_loss: 0.7934\n",
            "Epoch 987/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4549 - val_loss: 0.7907\n",
            "Epoch 988/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4529 - val_loss: 0.7879\n",
            "Epoch 989/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.4508 - val_loss: 0.7852\n",
            "Epoch 990/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.4488 - val_loss: 0.7824\n",
            "Epoch 991/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.4467 - val_loss: 0.7797\n",
            "Epoch 992/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4447 - val_loss: 0.7770\n",
            "Epoch 993/1000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4427 - val_loss: 0.7743\n",
            "Epoch 994/1000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.4407 - val_loss: 0.7716\n",
            "Epoch 995/1000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4387 - val_loss: 0.7689\n",
            "Epoch 996/1000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4367 - val_loss: 0.7663\n",
            "Epoch 997/1000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.4348 - val_loss: 0.7636\n",
            "Epoch 998/1000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.4328 - val_loss: 0.7610\n",
            "Epoch 999/1000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4309 - val_loss: 0.7583\n",
            "Epoch 1000/1000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.4289 - val_loss: 0.7557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 926
        },
        "id": "P671j-LR01cQ",
        "outputId": "fc7c9b93-fd82-4538-eb63-131fa8699010"
      },
      "source": [
        "pd.DataFrame(history1.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "pd.DataFrame(history2.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "pd.DataFrame(history3.history).plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUdx4CGIRdPI"
      },
      "source": [
        "# Predicting the strain energy outputs for the I, II inputs\n",
        "results = model.predict([I_ut, II_ut])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OD-WeKFwEq1"
      },
      "source": [
        "#Getting the Stress Values from the Strain Energy Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_78KsoCvz2HM"
      },
      "source": [
        "# Return the Second Piola Kirchhoff Stress\n",
        "batch_size = C_ut.shape[0]\n",
        "S_ut = tf.Variable(tf.zeros([batch_size, 3, 3]))\n",
        "S_ebt = tf.Variable(tf.zeros([batch_size, 3, 3]))\n",
        "S_ps = tf.Variable(tf.zeros([batch_size, 3, 3]))\n",
        "\n",
        "for i in range(0, batch_size):\n",
        "  S_ut[i,:,:].assign(second_Piola_Kirchhoff_stress(psi_ut[i], C_ut[i,:,:]))\n",
        "  S_ebt[i,:,:].assign(second_Piola_Kirchhoff_stress(psi_ebt[i], C_ebt[i,:,:]))\n",
        "  S_ps[i,:,:].assign(second_Piola_Kirchhoff_stress(psi_ebt[i], C_ebt[i,:,:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1lcbD3Ihjtr"
      },
      "source": [
        "# First Piola-Kirchhoff Stress\n",
        "P_ut = first_Piola_Kirchhoff_stress(S_ut, UT)\n",
        "P_ebt = first_Piola_Kirchhoff_stress(S_ebt, EBT)\n",
        "P_ps = first_Piola_Kirchhoff_stress(S_ps, PS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "za0_272LlphX",
        "outputId": "7cb0e7d4-f452-4146-9513-58c0aa81df55"
      },
      "source": [
        "# Getting the values for P11\n",
        "P11_ut = P_ut[:,0,0]\n",
        "P11_ebt = P_ebt[:,0,0]\n",
        "P11_ps = P_ps[:,0,0]\n",
        "print(P11_ut)\n",
        "print(P11_ebt)\n",
        "print(P11_ps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[0.44328484 0.56919366 0.6873499  0.79808    0.9034123  1.007403\n",
            " 1.1164768  1.2397656  1.3894515  1.5811071  1.8340418  2.171641\n",
            " 2.6217077  3.2168105  3.994622  ], shape=(15,), dtype=float32)\n",
            "tf.Tensor(\n",
            "[ 0.45079508  0.63051784  0.8553881   1.1405649   1.5089347   1.989221\n",
            "  2.6153347   3.4256632   4.462188    5.7696085   7.3948627   9.387696\n",
            " 11.8033     14.708329   18.192352  ], shape=(15,), dtype=float32)\n",
            "tf.Tensor(\n",
            "[ 0.45079508  0.63051784  0.8553881   1.1405649   1.5089347   1.989221\n",
            "  2.6153347   3.4256632   4.462188    5.7696085   7.3948627   9.387696\n",
            " 11.8033     14.708329   18.192352  ], shape=(15,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bd-Gob2ipE8F",
        "outputId": "a2a6ca38-9507-41b7-d733-366b216892ff"
      },
      "source": [
        "# Plot P11 vs Stretch for all three types of deformations\n",
        "plt.scatter(stretch, P11_ut, s=15, color=\"blue\", marker=\"s\", label=\"UT\")\n",
        "plt.scatter(stretch, P11_ebt, s=15, color=\"green\", marker=\"o\", label=\"EBT\")\n",
        "plt.scatter(stretch, P11_ps, s=15, color=\"red\", marker=\"x\", label=\"PS\")\n",
        "plt.xlabel(\"Stretch λ\")\n",
        "plt.ylabel(\"P11\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# EBT and PS are almost coinciding in their plots so only one can be seen"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMgAG-3BpHfW"
      },
      "source": [
        "**Predicted Stress Values by Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsH2RHapwoVr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1f0d775-0ad2-4d70-b057-acb56484d2a2"
      },
      "source": [
        "#Predicting the Stress Values on the entire DataSet\n",
        "\n",
        "psi_ut_pred = model.predict([I_ut_scaled, II_ut_scaled]).reshape(batch_size)\n",
        "psi_ebt_pred = model.predict([I_ebt_scaled, II_ebt_scaled]).reshape(batch_size)\n",
        "psi_ps_pred = model.predict([I_ps_scaled, II_ps_scaled]).reshape(batch_size)\n",
        "print(psi_ut_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.19549054 0.2226612  0.29936022 0.42369992 0.60173875 0.8321647\n",
            " 1.114588   1.4486928  1.8342452  2.2710657  2.7968857  3.4582026\n",
            " 4.0352783  4.5428104  5.0931973 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cybNwAUPyzrd"
      },
      "source": [
        "# Getting the stress values for the predicted strain energy values\n",
        "# Return the Second Piola Kirchhoff Stress\n",
        "batch_size = C_ut.shape[0]\n",
        "S_ut_pred = tf.Variable(tf.zeros([batch_size, 3, 3]))\n",
        "S_ebt_pred = tf.Variable(tf.zeros([batch_size, 3, 3]))\n",
        "S_ps_pred = tf.Variable(tf.zeros([batch_size, 3, 3]))\n",
        "\n",
        "for i in range(0, batch_size):\n",
        "  S_ut_pred[i,:,:].assign(second_Piola_Kirchhoff_stress(psi_ut_pred[i], C_ut[i,:,:]))\n",
        "  S_ebt_pred[i,:,:].assign(second_Piola_Kirchhoff_stress(psi_ebt_pred[i], C_ebt[i,:,:]))\n",
        "  S_ps_pred[i,:,:].assign(second_Piola_Kirchhoff_stress(psi_ebt_pred[i], C_ebt[i,:,:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiM5Ukcm1hHU"
      },
      "source": [
        "# Getting the First Piola-Kirchhoff Stress for predicted strain energy values\n",
        "P_ut_pred = first_Piola_Kirchhoff_stress(S_ut_pred, UT)\n",
        "P_ebt_pred = first_Piola_Kirchhoff_stress(S_ebt_pred, EBT)\n",
        "P_ps_pred = first_Piola_Kirchhoff_stress(S_ps_pred, PS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6DhnujwrvC_",
        "outputId": "deab44db-5e57-4f13-ab98-db8d95dc707c"
      },
      "source": [
        "# Getting the values for P11 for generated strain energy values\n",
        "P11_ut_pred = P_ut_pred[:,0,0]\n",
        "P11_ebt_pred = P_ebt_pred[:,0,0]\n",
        "P11_ps_pred = P_ps_pred[:,0,0]\n",
        "print(P11_ut_pred)\n",
        "print(P11_ebt_pred)\n",
        "print(P11_ps_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[0.44328484 0.56919366 0.6873499  0.79808    0.9034123  1.007403\n",
            " 1.1164768  1.2397656  1.3894515  1.5811071  1.8340418  2.171641\n",
            " 2.6217077  3.2168105  3.994622  ], shape=(15,), dtype=float32)\n",
            "tf.Tensor(\n",
            "[ 0.45079508  0.63051784  0.8553881   1.1405649   1.5089347   1.989221\n",
            "  2.6153347   3.4256632   4.462188    5.7696085   7.3948627   9.387696\n",
            " 11.8033     14.708329   18.192352  ], shape=(15,), dtype=float32)\n",
            "tf.Tensor(\n",
            "[ 0.45079508  0.63051784  0.8553881   1.1405649   1.5089347   1.989221\n",
            "  2.6153347   3.4256632   4.462188    5.7696085   7.3948627   9.387696\n",
            " 11.8033     14.708329   18.192352  ], shape=(15,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugC3UMvRr9B6",
        "outputId": "71d704ab-0109-414a-d6d8-6c1cb81f532c"
      },
      "source": [
        "# Plot P11 vs Stretch for all three types of deformations\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(stretch.numpy(), P11_ut_pred.numpy(), color=\"blue\", linestyle=\"solid\", label=\"UT_pred\")\n",
        "plt.plot(stretch.numpy(), P11_ebt_pred.numpy(), color=\"green\", linestyle=\"solid\", label=\"EBT_pred\")\n",
        "plt.plot(stretch.numpy(), P11_ps_pred.numpy(), color=\"red\", linestyle=\"solid\", label=\"PS_pred\")\n",
        "\n",
        "# The previous Graph showing actual values\n",
        "# Plot P11 vs Stretch for all three types of deformations\n",
        "plt.scatter(stretch, P11_ut, s=20, color=\"blue\", marker=\"s\", label=\"UT\")\n",
        "plt.scatter(stretch, P11_ebt, s=20, color=\"green\", marker=\"o\", label=\"EBT\")\n",
        "plt.scatter(stretch, P11_ps, s=20, color=\"red\", marker=\"x\", label=\"PS\")\n",
        "plt.xlabel(\"Stretch λ\")\n",
        "plt.ylabel(\"P11\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    }
  ]
}